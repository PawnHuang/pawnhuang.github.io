<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Condition详解</title>
    <url>/2021/04/14/Condition%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式，但是这两者在使用方式以及功能特性上还是有差别的。</p>
<p>通过对比Object的监视器方法和Condition接口，可以更详细地了解Condition的特性，对比项与结果如下表。<br><img src="https://i.loli.net/2021/04/14/tKrimpjWQZ9lOnu.png" alt="Condition1"></p>
<span id="more"></span>
<h2 id="Condition的使用"><a href="#Condition的使用" class="headerlink" title="Condition的使用"></a>Condition的使用</h2><p>Condition定义了等待/通知两种类型的方法，当前线程调用这些方法时，需要提前获取到Condition对象关联的锁。Condition对象是由Lock对象（调用Lock对象的newCondition()方法）创建出来的，换句话说，Condition是依赖Lock对象的。 Condition的使用方式比较简单，需要注意在调用方法前获取锁。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.joonwhee.five;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Callable;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.LinkedBlockingQueue;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ThreadPoolExecutor;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.locks.Condition;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.locks.Lock;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReentrantLock;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Condition接口与示例</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> JoonWhee</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2018年2月11日</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BoundedQueue</span>&lt;T&gt; &#123;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 线程池</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">ExecutorService</span> <span class="variable">THREAD_POOL</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(<span class="number">2</span>, <span class="number">4</span>, <span class="number">60</span>, TimeUnit.MINUTES,</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">LinkedBlockingQueue</span>&lt;Runnable&gt;(<span class="number">1000</span>), Executors.defaultThreadFactory(),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>.AbortPolicy());</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> Object[] items; <span class="comment">// 对象数组</span></span><br><span class="line">    <span class="comment">// 添加的下标，删除的下标和数组当前数量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> addIndex, removeIndex, count;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Lock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantLock</span>(); <span class="comment">// 定义一个可重入锁</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">Condition</span> <span class="variable">notEmpty</span> <span class="operator">=</span> lock.newCondition(); <span class="comment">// 添加一个Condition</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">Condition</span> <span class="variable">notFull</span> <span class="operator">=</span> lock.newCondition(); <span class="comment">// 添加一个Condition</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">BoundedQueue</span><span class="params">(<span class="type">int</span> size)</span> &#123;</span><br><span class="line">        items = <span class="keyword">new</span> <span class="title class_">Object</span>[size];</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 添加一个元素，如果数组满，则添加线程进入等待状态，直到有&quot;空位&quot;</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> t</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(T t)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        lock.lock(); <span class="comment">// 获取锁</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (count == items.length) &#123; <span class="comment">// 如果数组满了，notFull进入等待</span></span><br><span class="line">                System.out.println(<span class="string">&quot;items满了，add方法进入等待.&quot;</span>);</span><br><span class="line">                notFull.await(); <span class="comment">// 等待remove方法里的notFull.signal()</span></span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            items[addIndex] = t; <span class="comment">// item添加对象</span></span><br><span class="line">            <span class="keyword">if</span> (++addIndex == items.length) <span class="comment">// 调整数组索引，避免越界</span></span><br><span class="line">                addIndex = <span class="number">0</span>;</span><br><span class="line">            ++count; <span class="comment">// count+1，代表添加了一个对象</span></span><br><span class="line">            notEmpty.signal(); <span class="comment">// 走到这里，数组里至少有1个对象，必不为空，因此唤醒notEmpty</span></span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;add: &quot;</span> + t);</span><br><span class="line">            lock.unlock(); <span class="comment">// 释放锁</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 由头部删除一个元素，如果数组空，则删除线程进入等待状态，</span></span><br><span class="line"><span class="comment">     * 直到有新添加元素（注意这里并没有真的删除元素，只是把count-1当作是删除）</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> T <span class="title function_">remove</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        lock.lock(); <span class="comment">// 获取锁</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (count == <span class="number">0</span>) &#123; <span class="comment">// 如果数组为空，notEmpty进入等待</span></span><br><span class="line">                System.out.println(<span class="string">&quot;items为空，remove方法进入等待.&quot;</span>);</span><br><span class="line">                notEmpty.await(); <span class="comment">// 等待add方法里的notEmpty.signal()</span></span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            <span class="type">Object</span> <span class="variable">x</span> <span class="operator">=</span> items[removeIndex]; <span class="comment">// item移除对象（假移除）</span></span><br><span class="line">            <span class="keyword">if</span> (++removeIndex == items.length) <span class="comment">// 调整数组索引，避免越界</span></span><br><span class="line">                removeIndex = <span class="number">0</span>;</span><br><span class="line">            --count; <span class="comment">// count-1，代表移除了一个对象</span></span><br><span class="line">            notFull.signal(); <span class="comment">// 走到这里，数组里至少有1个空位，必不为满，因此唤醒notFull</span></span><br><span class="line">            <span class="keyword">return</span> (T) x;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;remove&quot;</span>);</span><br><span class="line">            lock.unlock(); <span class="comment">// 释放锁</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">3</span>; <span class="comment">// 可以加大数组的size来看更多的过程</span></span><br><span class="line">        BoundedQueue&lt;Integer&gt; bq = <span class="keyword">new</span> <span class="title class_">BoundedQueue</span>&lt;Integer&gt;(count);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 开启一个线程执行添加操作</span></span><br><span class="line">        THREAD_POOL.submit(<span class="keyword">new</span> <span class="title class_">Callable</span>&lt;Object&gt;() &#123;</span><br><span class="line">            <span class="keyword">public</span> Object <span class="title function_">call</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; count * <span class="number">2</span>; i++) &#123;</span><br><span class="line">                    bq.add(i);</span><br><span class="line">                    Thread.sleep(<span class="number">200</span>); <span class="comment">// 通过睡眠来制造添加和移除的速度差</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 开启一个线程执行移除操作</span></span><br><span class="line">        THREAD_POOL.submit(<span class="keyword">new</span> <span class="title class_">Callable</span>&lt;Object&gt;() &#123;</span><br><span class="line">            <span class="keyword">public</span> Object <span class="title function_">call</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; count * <span class="number">2</span>; i++) &#123;</span><br><span class="line">                    bq.remove();</span><br><span class="line">                    Thread.sleep(<span class="number">50</span>); <span class="comment">// 通过睡眠来制造添加和移除的速度差</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出如下，由于调用remove方法的线程先睡眠了1秒，所以，add方法会先将item数组填满，填满后notFull进入等待。之后，remove方法的线程醒来开始进行移除，当移除之后会唤醒notFull，此时add和remove是并发操作的，但是由于remove的速度更快（通过sleep控制，add每次要睡200毫秒，remove只要50毫秒），所以items必然会被移除到为空，此时notEmpty进入等待，直到add方法往item添加了对象，如此反复。<br><img src="https://i.loli.net/2021/04/14/FgyNJLh1jD8CBmO.png" alt="condition2"></p>
<h2 id="重要入口方法"><a href="#重要入口方法" class="headerlink" title="重要入口方法"></a>重要入口方法</h2><p>Condition的实现主要包括：条件队列、等待和通知。其中条件队列放的是AQS里的Node数据结构，使用nextWaiter来维护条件队列。等待和通知共有7个方法。</p>
<blockquote>
<p>signal()：唤醒该条件队列的头节点。<br>  signalAll()：唤醒该条件队列的所有节点。<br>  awaitUninterruptibly()：等待，此方法无法被中断，必须通过唤醒才能解除阻塞。<br>  await()：当前线程进入等待。<br>  awaitNanos(long)：当前线程进入等待，有超时时间，入参的单位为纳秒。<br>  awaitUntil(Date)：当先线程进入等待，直到当前时间超过入参的时间。<br>  await(long, TimeUnit)：当前线程进入等待，有超时时间，入参可以自己设置时间单位。</p>
</blockquote>
<p>这些方法其实大同小异，因此本文只对常用的signal()、signalAll()和await()方法展开详解。搞懂了这3个方法，搞懂其他几个方法也基本没什么阻碍。</p>
<h2 id="基础属性"><a href="#基础属性" class="headerlink" title="基础属性"></a>基础属性</h2><p>Condition的实现是ConditionObject，而ConditionObject是同步器AbstractQueuedSynchronizer的内部类，因为Condition的操作需要获取相关联的锁，所以作为同步器的内部类也较为合理。每个Condition对象都包含着一个队列（以下称为条件队列），该队列是Condition对象实现等待/通知功能的关键。</p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1173984872572414699</span>L;</span><br><span class="line"><span class="comment">/** First node of condition queue. */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> Node firstWaiter; <span class="comment">// 条件队列的头节点</span></span><br><span class="line"><span class="comment">/** Last node of condition queue. */</span>    </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> Node lastWaiter;  <span class="comment">// 条件队列的尾节点</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Creates a new &#123;@code ConditionObject&#125; instance.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> ConditionObject() &#123; &#125;</span><br></pre></td></tr></table></figure>

<p>等待队列是一个FIFO队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。事实上，节点的定义复用了AQS中Node节点的定义，也就是说，同步队列和等待队列中节点类型都是AQS的静态内部类AbstractQueuedSynchronized.Node。</p>
<p>一个Condition包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法之后，将会以当前线程构造节点，并将节点从尾部加入等待队列，等待队列的基本结构如下图所示：<br><img src="https://i.loli.net/2021/04/14/nfVtELIkJPvNTGw.jpg" alt="condition3"></p>
<p>条件队列的基本数据结构如下图中的“条件队列”：<br><img src="https://i.loli.net/2021/04/14/ywxpTuPhnSIqbLU.png" alt="condition4"></p>
<p>在Object的监视器模型上，一个对象拥有一个同步队列和等待队列，而并发包中的Lock（更确切地说是同步器）拥有一个同步队列和多个等待队列，其对应关系如下图所示：<br><img src="https://i.loli.net/2021/04/14/r4XF6o5GpyICRJb.jpg" alt="condition5"></p>
<h2 id="等待"><a href="#等待" class="headerlink" title="等待"></a>等待</h2><p>调用Condition的await()方法会使当前线程进入等待状态，同时线程状态变为等待状态，当从await()方法返回时，当前线程一定获取了Condition相关联的锁。</p>
<p>如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。</p>
<p>Condition的await()方法如下：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="built_in">void</span> await() throws InterruptedException &#123; <span class="comment">// 阻塞当前线程，直接被唤醒或被中断</span></span><br><span class="line">    <span class="keyword">if</span> (Thread.<span class="built_in">int</span>errupted())   <span class="comment">// 如果当前线程被中断过，则抛出中断异常</span></span><br><span class="line">        throw new InterruptedException();</span><br><span class="line">    Node node = addConditionWaiter();   <span class="comment">// 添加一个waitStatus为CONDITION的节点到条件队列尾部</span></span><br><span class="line">    <span class="built_in">int</span> savedState = fullyRelease(node);    <span class="comment">// 释放操作。我们知道只有在拥有锁（acquire成功）的时候才能调用await()方法，因此，调用await()方法的线程的节点必然是同步队列的头节点。所以，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的条件队列中。</span></span><br><span class="line">    <span class="built_in">int</span> <span class="built_in">int</span>erruptMode = <span class="number">0</span>;  <span class="comment">// 0为正常，被中断值为THROW_IE或REINTERRUPT</span></span><br><span class="line">    <span class="keyword">while</span> (!isOnSyncQueue(node)) &#123;  <span class="comment">// isOnSyncQueue：判断node是否在同步队列（注意和条件队列区分。调用signal方法会将节点从条件队列移动到同步队列，因此这边就可以跳出while循环）</span></span><br><span class="line">        LockSupport.park(<span class="keyword">this</span>); <span class="comment">// node如果不在同步队列则进行park（阻塞当前线程）</span></span><br><span class="line">        <span class="keyword">if</span> ((<span class="built_in">int</span>erruptMode = checkInterruptWhileWaiting(node)) != <span class="number">0</span>)    <span class="comment">// 检查线程被唤醒是否是因为被中断，如果是则跳出循环，否则会进行下一次循环，因为被唤醒前提是进入同步队列，所以下一次循环也必然会跳出循环</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (acquireQueued(node, savedState) &amp;&amp; <span class="built_in">int</span>erruptMode != THROW_IE)   <span class="comment">// acquireQueued返回true代表被中断过，如果中断模式不是THROW_IE，则必然为REINTERRUPT（见上面的checkInterruptWhileWaiting方法）</span></span><br><span class="line">        <span class="built_in">int</span>erruptMode = REINTERRUPT;</span><br><span class="line">    <span class="keyword">if</span> (node.nextWaiter != <span class="literal">null</span>) <span class="comment">// clean up if cancelled</span></span><br><span class="line">        unlinkCancelledWaiters();   <span class="comment">// 移除waitStatus为CANCELLED的节点</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">int</span>erruptMode != <span class="number">0</span>) <span class="comment">// 如果跳出while循环是因为被中断</span></span><br><span class="line">        reportInterruptAfterWait(<span class="built_in">int</span>erruptMode);    <span class="comment">// 则根据interruptMode，选择抛出InterruptedException 或 重新中断当前线程</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果当前线程被中断过，则抛出中断异常。<br> 调用addConditionWaiter方法（详解见下文addConditionWaiter方法）添加一个waitStatus为CONDITION的节点到条件队列尾部。<br> 调用fullyRelease方法（详解见下文fullyRelease方法）释放锁。<br> 调用isOnSyncQueue方法（详解见下文isOnSyncQueue方法）来阻塞线程，直到被唤醒或被中断。<br> 调用acquireQueued方法（详解见acquireQueued方法详解）来尝试获取锁，并判断线程跳出while循环是被唤醒还是被中断。<br> 如果跳出while循环是因为被中断，则根据interruptMode，选择抛出InterruptedException 或 重新中断当前线程。</p>
</blockquote>
<p>调用该方法的线程是成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。</p>
<p>加入等待队列是通过addConditionWaiter()方法来完成的：</p>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">private <span class="keyword">Node</span> <span class="title">addConditionWaiter</span>() &#123; // 添加一个waitStatus为CONDITION的节点到条件队列尾部</span><br><span class="line">    <span class="keyword">Node</span> <span class="title">t</span> = lastWaiter;</span><br><span class="line">    // If lastWaiter is cancelled, clean out.</span><br><span class="line">    if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123;</span><br><span class="line">        unlinkCancelledWaiters();   // 移除waitStatus不为CONDITION的节点（条件队列里的节点waitStatus都为CONDITION）</span><br><span class="line">        t = lastWaiter; // 将t赋值为移除了waitStatus不为CONDITION后的尾节点（上面进行了移除操作，因此尾节点可能会发生变化）</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">Node</span> <span class="title">node</span> = new <span class="keyword">Node</span><span class="title">(Thread</span>.currentThread(), Node.CONDITION);   // 以当前线程新建一个waitStatus为CONDITION的节点</span><br><span class="line">    if (t == null)  // t为空，代表条件队列为空</span><br><span class="line">        firstWaiter = <span class="keyword">node</span><span class="title">; // 将头节点赋值为node</span></span><br><span class="line">    else</span><br><span class="line">        t.nextWaiter = <span class="keyword">node</span><span class="title">;    // 否则，队列不为空。将t</span>（原尾节点）的后继节点赋值为<span class="keyword">node</span></span><br><span class="line">    <span class="title">lastWaiter</span> = <span class="keyword">node</span><span class="title">;  // 将node</span>赋值给尾节点，即将<span class="keyword">node</span><span class="title">放到条件队列的尾部。这里没有用CAS</span>来保证原子性，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的</span><br><span class="line">    return <span class="keyword">node</span><span class="title">;</span></span><br><span class="line"><span class="title">&#125;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果条件队列的尾节点不为null并且waitStatus不为CONDITION，则调用unlinkCancelledWaiters方法（详解见下文unlinkCancelledWaiters方法）移除waitStatus不为CONDITION的节点（条件队列里的节点waitStatus都为CONDITION），并将t赋值为移除了waitStatus不为CONDITION后的尾节点（上面进行了移除操作，因此尾节点可能会发生变化）<br> 以当前线程新建一个waitStatus为CONDITION的节点。<br> 如果t为空，代表条件队列为空，将头节点赋值为node；否则，队列不为空。将t（原尾节点）的后继节点赋值为node。<br> 最后将node赋值给尾节点，即将node放到条件队列的尾部。这里没有用CAS来保证原子性，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。</p>
</blockquote>
<p>如果从队列的角度看，当前线程加入到Condition的等待队列，如下图所示：<br><img src="https://i.loli.net/2021/04/14/bdN6ieJUCLrlGAa.png" alt="condition6"></p>
<p>若节点不在同步队列中，则挂起当前线程，若线程在同步队列中，且获取了同步状态，可能会调用unlinkCancelledWaiters()方法来清理等待队列中不为CONDITION 状态的节点：</p>
<figure class="highlight axapta"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> unlinkCancelledWaiters() &#123; <span class="comment">//　从条件队列移除所有waitStatus不为CONDITION的节点</span></span><br><span class="line">    Node t = firstWaiter; <span class="comment">// t赋值为条件队列的尾节点  </span></span><br><span class="line">    Node trail = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">while</span> (t != <span class="literal">null</span>) &#123;</span><br><span class="line">        Node <span class="keyword">next</span> = t.nextWaiter;   <span class="comment">// 向下遍历</span></span><br><span class="line">        <span class="keyword">if</span> (t.waitStatus != Node.CONDITION) &#123;   <span class="comment">// 如果t的waitStatus不为CONDITION</span></span><br><span class="line">            t.nextWaiter = <span class="literal">null</span>;    <span class="comment">// 断开t与t后继节点的关联</span></span><br><span class="line">            <span class="keyword">if</span> (trail == <span class="literal">null</span>)  <span class="comment">// 如果trail为null，则将firstWaiter赋值为next节点，此时还没有遍历到waitStatus为CONDITION的节点，因此直接移动firstWaiter的指针即可移除前面的节点</span></span><br><span class="line">                firstWaiter = <span class="keyword">next</span>; </span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                trail.nextWaiter = <span class="keyword">next</span>;    <span class="comment">// 否则将trail的后继节点设为next节点。此时，trail节点到next节点中的所有节点被移除（包括t节点，但可能不止t节点。因为，trail始终指向遍历过的最后一个waitStatus为CONDITION，因此只需要将trail的后继节点设置为next，即可将trail之后到next之前的所有节点移除）</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">next</span> == <span class="literal">null</span>)</span><br><span class="line">                lastWaiter = trail;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            trail = t;  <span class="comment">// 如果t的waitStatus为CONDITION，则将trail赋值为t，trail始终指向遍历过的最后一个waitStatus为CONDITION</span></span><br><span class="line">        t = <span class="keyword">next</span>;   <span class="comment">// t指向下一个节点</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>整个过程如下图：<br><img src="https://i.loli.net/2021/04/14/4dXtFh9eYypziMw.png" alt="condition7"></p>
<p>将当前线程加入到等待队列之后，需要释放同步状态，该操作通过fullyRelease(Node)方法来完成：</p>
<figure class="highlight aspectj"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="function"><span class="keyword">int</span> <span class="title">fullyRelease</span><span class="params">(Node node)</span> </span>&#123; <span class="comment">// 释放锁</span></span><br><span class="line">    <span class="keyword">boolean</span> failed = <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> savedState = getState();    <span class="comment">// 当前的同步状态</span></span><br><span class="line">        <span class="keyword">if</span> (release(savedState)) &#123;  <span class="comment">// 独占模式下release（一般指释放锁）</span></span><br><span class="line">            failed = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">return</span> savedState;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalMonitorStateException();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (failed)</span><br><span class="line">            node.waitStatus = Node.CANCELLED;   <span class="comment">// 如果release失败则将该节点的waitStatus设置为CANCELLED</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>线程释放锁之后，我们需要通过isOnSyncQueue(Node)方法不断自省地检查其对应节点是否在同步队列中：</p>
<figure class="highlight aspectj"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="function"><span class="keyword">boolean</span> <span class="title">isOnSyncQueue</span><span class="params">(Node node)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 节点状态为CONDITION，或者前驱节点为null，返回false</span></span><br><span class="line">    <span class="keyword">if</span> (node.waitStatus == Node.CONDITION || node.prev == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    <span class="comment">// 后继节点不为null，那么肯定在同步队列中</span></span><br><span class="line">    <span class="keyword">if</span> (node.next != <span class="keyword">null</span>) <span class="comment">// If has successor, it must be on queue</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">return</span> <span class="title">findNodeFromTail</span><span class="params">(node)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="通知"><a href="#通知" class="headerlink" title="通知"></a>通知</h2><p>调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。Condition的signal()方法如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title function_">signal</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 判断是否是当前线程获取了锁</span></span><br><span class="line">    <span class="keyword">if</span> (!isHeldExclusively())</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalMonitorStateException</span>();</span><br><span class="line">    <span class="comment">// 唤醒等待队列的首节点</span></span><br><span class="line">    <span class="type">Node</span> <span class="variable">first</span> <span class="operator">=</span> firstWaiter;</span><br><span class="line">    <span class="keyword">if</span> (first != <span class="literal">null</span>)</span><br><span class="line">        doSignal(first);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法最终调用doSignal(Node)方法来唤醒节点：</p>
<figure class="highlight q"><table><tr><td class="code"><pre><span class="line">private void doSignal(Node <span class="built_in">first</span>) &#123;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="comment">// 把等待队列的首节点移除之后，要修改首结点</span></span><br><span class="line">        if ( (firstWaiter = <span class="built_in">first</span>.nextWaiter) == <span class="built_in">null</span>)</span><br><span class="line">            lastWaiter = <span class="built_in">null</span>;</span><br><span class="line">        <span class="built_in">first</span>.nextWaiter = <span class="built_in">null</span>;</span><br><span class="line">    &#125; <span class="keyword">while</span> (!transferForSignal(<span class="built_in">first</span>) &amp;&amp;</span><br><span class="line">                (<span class="built_in">first</span> = firstWaiter) != <span class="built_in">null</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>检查当前线程是否为独占模式同步器的所有者，在ReentrantLock中即检查当前线程是否为拥有锁的线程。如果不是，则抛IllegalMonitorStateException。<br> 拿到条件队列的头节点，如果不为null，则调用doSignal方法（详解见下文doSignal方法）唤醒头节点。</p>
</blockquote>
<p>将节点移动到同步队列是通过transferForSignal(Node)方法完成的：</p>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">final boolean transferForSignal(<span class="keyword">Node</span> <span class="title">node</span>) &#123;</span><br><span class="line">    // 尝试将该节点的状态从CONDITION修改为<span class="number">0</span></span><br><span class="line">    if (!compareAndSetWaitStatus(<span class="keyword">node</span><span class="title">, Node</span>.CONDITION, <span class="number">0</span>))</span><br><span class="line">        return <span class="literal">false</span>;</span><br><span class="line">    </span><br><span class="line">    // 将节点加入到同步队列尾部，返回该节点的前驱节点</span><br><span class="line">    <span class="keyword">Node</span> <span class="title">p</span> = enq(<span class="keyword">node</span><span class="title">);</span></span><br><span class="line"><span class="title">    int</span> ws = p.waitStatus;</span><br><span class="line">    // 如果前驱节点的状态为CANCEL或者修改waitStatus失败，则直接唤醒当前线程</span><br><span class="line">    if (ws &gt; <span class="number">0</span> || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))</span><br><span class="line">        LockSupport.unpark(node.thread);</span><br><span class="line">    return <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>将first节点赋值为first节点的后继节点（相当于移除first节点），如果first节点的后继节点为空，则将lastWaiter赋值为null。<br> 断开first节点与first节点后继节点的关联。<br> 调用transferForSignal方法（详解见下文transferForSignal方法）将first节点从条件队列移动到同步队列。<br> 如果transferForSignal失败，并且first节点的后继节点（firstWaiter）不为null，则向下遍历条件队列的节点，直到节点成功移动到同步队列 或者 first节点的后继节点为null。</p>
</blockquote>
<p>节点从等待队列移动到同步队列的过程如下图所示：<br><img src="https://i.loli.net/2021/04/14/Kv6MxfDwmegIpoB.png" alt="condition8"><br>被唤醒后的线程，将从await()方法中的while循环中退出（因为此时isOnSyncQueue(Node)方法返回true），进而调用acquireQueued()方法加入到获取同步状态的竞争中。</p>
<p>成功获取了锁之后，被唤醒的线程将从先前调用的await()方法返回，此时，该线程已经成功获取了锁。</p>
<p>Condition的signalAll()方法，相当于对等待队列的每个节点均执行一次signal()方法，效果就是将等待队列中的所有节点移动到同步队列中。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>调用await和signal方法都需要先获得锁，否则会抛异常。<br>调用await方法会新建一个waitStatus为CONDITION、线程为当前线程的节点到条件队列尾部，然后当前线程会释放掉锁，并进入阻塞状态，直到该节点被移到同步队列或者被中断。该节点被移动到同步队列，并不代表该节点线程能立马获得锁，还是需要在同步队列中排队并在必要时候（前驱节点为head）调用tryAcquire方法去获取，如果获取成功则代表获得了锁。<br>调用signal方法会将条件队列的头节点移动到同步队列。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发编程之synchronized详解</title>
    <url>/2021/04/15/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsynchronized%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在Java多线程编程中，synchronized一直是元老级角色，很多人称呼它为重量级锁，但是随着Java SE1.6对其进行了各种优化之后，有些情况下它就不再那么重了，我们先看下利用synchronized实现同步的基础：Java中每一个对象都可以作为锁，具体表现为以下三种：</p>
<p>1、对于普通同步方法，锁是当前实例对象；<br>2、对于静态同步方法，锁是当前类的Class对象；<br>3、对于同步方法块，锁是synchronized括号里配置的对象。</p>
<p>synchronized用的锁是存在Java对象头里的，所以要深入了解synchronizd，需要先了解JVM中的对象头，它是实现synchronized的基础。</p>
<span id="more"></span>

<h2 id="JAVA对象头"><a href="#JAVA对象头" class="headerlink" title="JAVA对象头"></a>JAVA对象头</h2><p>在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。</p>
<p><strong>对象头：</strong> HotSpot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身运行时数据，如哈希吗、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。这部分数据长度在32位和64位虚拟机中分别为32bit和64bit，称为“Mark Word”。对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。<br>Java对象头一般占有两个机器码（在32位虚拟机中，1个机器码等于4字节，也就是32bit），但是如果对象是数组类型，则需要三个机器码，因为JVM可以通过Java对象的元数据信息确定Java对象的大小，但是无法从数组的元数据来确认数组的大小，所以用一块来记录数组长度。</p>
<p><strong>实例数据：</strong> 实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容，无论是从父类集成下来的，还是在子类中定义的，都需要记录下来。</p>
<p><strong>对齐填充：</strong>对齐填充并不是必然存在的，它仅仅起着占位符的作用，由于HotSpot虚拟机的自动内存管理系统要求对象起始地址必须是8字节的整数倍，因此，当实例对象数据部分没有对齐时，就需要通过对齐填充来补全。</p>
<p>Java对象头是实现锁的关键，我们重点分析它。下面是32位HotSpot虚拟机的Mark Word默认存储结构。<br><img src="https://i.loli.net/2021/04/15/HiXUza5R1jWtJAb.png" alt="1"></p>
<p>由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到虚拟机的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便在极小的空间内存储尽量多的信息，它会根据对象本身的状态复用自己的存储空间，如32位HotSpot虚拟机下，除了上述列出的Mark Word默认存储结构外，还有如下可能变化的结构<br><img src="https://i.loli.net/2021/04/15/sJkZDfxPactWqmB.png" alt="2"></p>
<p>其中轻量级锁和偏向锁是Java SE1.6 对 synchronized 锁进行优化后新增加的，稍后我们会简要分析。这里我们主要分析一下重量级锁，即synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个monitor与之关联，对象与其monitor之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，当一个monitor被某个线程持有后，它便处于锁定状态。在HotSpot虚拟机中，monitor是由ObjectMonitor实现的，其主要数据结构如下</p>
<figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line">ObjectMonitor() &#123;</span><br><span class="line">    <span class="variable">_header</span>       = NULL;</span><br><span class="line">    <span class="variable">_count</span>        = <span class="number">0</span>;</span><br><span class="line">    <span class="variable">_waiters</span>      = <span class="number">0</span>,</span><br><span class="line">    <span class="variable">_recursions</span>   = <span class="number">0</span>;</span><br><span class="line">    <span class="variable">_object</span>       = NULL;</span><br><span class="line">    <span class="variable">_owner</span>        = NULL;</span><br><span class="line">    <span class="variable">_WaitSet</span>      = NULL;</span><br><span class="line">    <span class="variable">_WaitSetLock</span>  = <span class="number">0</span> ;</span><br><span class="line">    <span class="variable">_Responsible</span>  = NULL ;</span><br><span class="line">    <span class="variable">_succ</span>         = NULL ;</span><br><span class="line">    <span class="variable">_cxq</span>          = NULL ;</span><br><span class="line">    FreeNext      = NULL ;</span><br><span class="line">    <span class="variable">_EntryList</span>    = NULL ;</span><br><span class="line">    <span class="variable">_SpinFreq</span>     = <span class="number">0</span> ;</span><br><span class="line">    <span class="variable">_SpinClock</span>    = <span class="number">0</span> ;</span><br><span class="line">    OwnerIsThread = <span class="number">0</span> ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>ObjectMonitor对象中有两个队列：</p>
<p>_WaitSet ：处于wait状态的线程，会被加入到wait set。</p>
<p>_EntryList：处于等待锁block状态的线程，会被加入到entry set。</p>
<p>当线程获取到对象的monitor后进入_owner区域并把ObjectMonitor中的_owner变量设置为当前线程，同时ObjectMonitor中的计数器_recursions加1，_recursions初始值为0。若线程调用wait() 方法，将释放当前持有的ObjectMonitor，_owner变量恢复为null，_recursions自减1，同时该线程进入_WaitSet集合中等待被唤醒。若当前线程执行完毕也将释放ObjectMonitor (锁)并复位变量的值，以便其他线程进入获取ObjectMonitor (锁)。如下图所示<br><img src="https://i.loli.net/2021/04/15/ovfFE9J5Kcj2aRM.png" alt="3"></p>
<p>在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高；而且，线程的互斥同步是通过阻塞实现的，挂起线程与恢复线程的操作也都需要转入内核态中完成，给系统的并发性能带来很大压力，这也是为什么早期的synchronized效率低的原因。</p>
<p>Java SE1.6之后，为了减少获得锁和释放锁所带来的性能消耗，虚拟机开发团队对synchronized锁进行了多种优化，接下来我们来了解一下他们在虚拟机层面对synchronized锁的优化。</p>
<h2 id="synchronized锁优化"><a href="#synchronized锁优化" class="headerlink" title="synchronized锁优化"></a>synchronized锁优化</h2><p>高效并发是从JDK1.5到JDK1.6的一个重要改进，HotSpot虚拟机开发团队在这个版本上花费了大量的精力去实现各种锁优化技术。如适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁等，这些技术都是为了在线程之间更高效地共享数据，以及解决竞争问题。Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级。</p>
<h2 id="自旋锁和适应性自旋"><a href="#自旋锁和适应性自旋" class="headerlink" title="自旋锁和适应性自旋"></a>自旋锁和适应性自旋</h2><p>虚拟机开发团队注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得，这时，我们就可以让后面请求锁的线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需要让线程执行一个忙循环（自旋），这就是所谓的自旋锁。</p>
<p>自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果，自旋等待的时间很短，那自旋等待的效果就很好，否则，自旋的线程就只会白白消耗处理器资源，反而会带来性能上的浪费。因此，自旋等待必须要有一定的限度，如果超过限定的自旋次数仍没有成功获取锁，就应当使用传统的方式去挂起线程。</p>
<p>Java SE1.6引入了自适应的自旋锁。自适应意味着自旋的时间不在固定了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定。线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。</p>
<p>有了自适应自旋锁，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测会越来越准确，虚拟机会变得越来越聪明。</p>
<h2 id="消除锁"><a href="#消除锁" class="headerlink" title="消除锁"></a>消除锁</h2><p>锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，自然就不需要同步加锁了。</p>
<p>如下述代码</p>
<figure class="highlight typescript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title class_">String</span> <span class="title function_">concatString</span>(<span class="params"><span class="title class_">String</span> s1, <span class="title class_">String</span> s2, <span class="title class_">String</span> s3</span>) &#123;</span><br><span class="line">    <span class="title class_">StringBuffer</span> stringBuffer = <span class="keyword">new</span> <span class="title class_">StringBuffer</span>();</span><br><span class="line">    stringBuffer.<span class="title function_">append</span>(s1);</span><br><span class="line">    stringBuffer.<span class="title function_">append</span>(s2);</span><br><span class="line">    stringBuffer.<span class="title function_">append</span>(s3);</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> stringBuffer.<span class="title function_">toString</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>每一个StringBuffer.append()方法中都有一个同步块，锁就是stringBuffer对象，虚拟机观察到stringBuffer的作用域被限制在concatString()方法内部。即stringBuffer的所有引用都不会逃逸到该方法之外，其他线程无法访问到它，因此，虽然这里有锁，但是可以被安全的消除掉。</p>
<h2 id="锁粗化"><a href="#锁粗化" class="headerlink" title="锁粗化"></a>锁粗化</h2><p>我们知道在使用同步锁的时候，需要让同步块的作用范围尽可能小，仅在共享数据的实际作用域中才进行同步，这样做的目的是为了使需要同步的操作数量尽可能缩小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。</p>
<p>大部分情况下，上述原则都是正确的，但是如果一系列的连续操作都是对同一个对象反复进行加锁和解锁，即使没有线程竞争，但是频繁的进行互斥同步操作也会带来不必要的性能消耗，所以引入锁粗化的概念，就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。如锁消除中的代码，可以将锁扩展到第一个append()方法之前直至最后一个append()方法之后，这样，只需要加锁一次就可以了。</p>
<h2 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h2><p>引入轻量级锁的主要目的是在多没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁，其步骤如下： </p>
<h3 id="获取锁"><a href="#获取锁" class="headerlink" title="获取锁"></a>获取锁</h3><p>1、在代码进入同步块时，如果此对象没有被锁定（锁标志位为01），则虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方把这份拷贝加了一个Displaced前缀，即Displaced Mark Word）；若此对象已经被锁定，则转至步骤3。</p>
<p>2、虚拟机使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，如果成功表示竞争到锁，则将锁标志位变成00（表示此对象处于轻量级锁状态），执行同步操作；若竞争失败，则转至步骤3。</p>
<p>3、虚拟机检查对象的Mark Word是否指向当前线程的栈帧，如果是则表示当前线程已经持有当前对象的锁，则直接执行同步代码块；否则只能说明该锁对象已经被其他线程抢占了，这时轻量级锁需要膨胀为重量级锁，锁标志位变成10，后面等待的线程将会进入阻塞状态。</p>
<h3 id="释放锁"><a href="#释放锁" class="headerlink" title="释放锁"></a>释放锁</h3><p>它的解锁过程也是通过CAS操作来完成的。</p>
<p>1、用CAS操作将当前对象的Mark Word和线程中的Displaced Mark Word替换回来，若替换成功，则整个同步过程就完成了，否则执行步骤2。</p>
<p>2、如果CAS操作替换失败，说明有其他线程尝试获取该锁，则需要在释放锁的同时需要唤醒被挂起的线程。</p>
<p>对于轻量级锁，其性能提升的依据是“对于绝大部分的锁，在整个生命周期内都是不会存在竞争的”，这只是一个经验数据。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥量的开销；但如果存在锁竞争，除了互斥量的开销，还有额外的CAS操作，因此在有多线程竞争的情况下，轻量级锁比重量级锁更慢。</p>
<p>下图是轻量级锁的获取和释放过程 <br><img src="https://i.loli.net/2021/04/15/8o4eCyKYrQtOL6s.png" alt="4"></p>
<h2 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h2><p>偏向锁的目的是消除数据在无竞争情况下的同步原语，进一步提升程序的运行性能。轻量级锁的加锁解锁操作是需要依赖多次CAS原子操作的，那偏向锁就是在无竞争的条件下，通过减少CAS操作的次数来获取锁。</p>
<h3 id="获取锁-1"><a href="#获取锁-1" class="headerlink" title="获取锁"></a>获取锁</h3><p>1、当锁对象第一次被线程获取时，将锁标志位设为01，即偏向模式。</p>
<p>2、使用CAS操作将线程ID记录到对象的Mark Word中，若CAS操作成功，则持有偏向锁的线程以后每次进入同步块时，虚拟机都不会进行任何同步操作；否则，执行步骤3。</p>
<p>3、通过CAS竞争锁失败，证明当前存在多线程竞争情况，当到达全局安全点，获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码块。</p>
<h3 id="释放锁-1"><a href="#释放锁-1" class="headerlink" title="释放锁"></a>释放锁</h3><p>偏向锁的释放采用了一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线程来竞争。偏向锁的撤销需要等待全局安全点（这个时间点是上没有正在执行的代码）。其步骤如下：</p>
<p>1、暂停拥有偏向锁的线程，判断锁对象是否还处于被锁定状态。</p>
<p>2、撤销偏向锁，恢复到无锁状态（01）或者轻量级锁的状态。</p>
<p>下图是偏向锁的获取和释放流程<br><img src="https://i.loli.net/2021/04/15/pIjkg46uB2Q1c3v.png" alt="5"></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>AbstractQueuedSynchronizer详解（独占模式）</title>
    <url>/2021/04/11/AbstractQueuedSynchronizer%E8%AF%A6%E8%A7%A3%EF%BC%88%E7%8B%AC%E5%8D%A0%E6%A8%A1%E5%BC%8F%EF%BC%89/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>AQS（AbstractQueuedSynchronizer）是一个用于构建锁和同步器的框架，许多同步器都可以通过AQS很容易并且高效地构造出来。不仅ReentrantLock和Semaphore是基于AQS构建的，还包括CountDownLatch、ReentrantReadWriteLock、SynchronousQueue和FutureTask。</p>
<p>AQS解决了在实现同步器时涉及的大量细节问题，例如等待线程采用FIFO队列操作顺序。在不同的同步器中还可以定义一些灵活的标准来判断某个线程是应该通过还是需要等待。基于AQS来构建同步器能带来许多好处。它不仅能极大地减少实现工作，而且也不处理在多个位置上发生的竞争问题（这是在没有使用AQS来构建同步器时的情况）。在 SemaphoreOnLock中，获取许可的操作可能在两个时刻阻塞一一一当锁保护信号量状态时，以及当许可不可用时。在基于AQS构建的同步器中，只可能在一个时刻发生阻塞，从而降低上下文切换的开销，并提高吞吐量。在设计AQS时充分考虑了可伸缩性，因此java.util.concurrent 中所有基于AQS构建的同步器都能获得这个优势。</p>
<span id="more"></span>


<h2 id="AbstractQueuedSynchronizer介绍"><a href="#AbstractQueuedSynchronizer介绍" class="headerlink" title="AbstractQueuedSynchronizer介绍"></a>AbstractQueuedSynchronizer介绍</h2><p>大多数开发者都不会直接使用AQS,标准同步器类的集合能够满足绝大多数情况的需求。但如果能了解标准同步器类的实现方式，那么对于理解它们的工作原理是非常有帮助的。</p>
<p>在基于AQS构建的同步器类中，最基本的操作包括各种形式的获取操作和释放操作。获取操作是一种依赖状态的操作，并且通常会阻塞。当使用锁或信号量时，“获取”操作的含义就很直观，即获取的是锁或者许可，并且调用者可能会一直等待直到同步器类处于可被获取的状态。在使用CountDownLatch时，“获取”操作意味着“等待并直到闭锁到达结束状态”，而在使用FutureTask时，则意味着“等待并直到任务已经完成”。“释放”并不是一个可阻塞的操作，当执行“释放”操作时，所有在请求时被阻塞的线程都会开始执行。</p>
<p>如果一个类想成为状态依赖的类，那么它必须拥有一些状态。AQS负责管理同步器类中的状态，它管理了一个整数状态信息，可以通过getstate，setState以及compareAndSetState等 protected类型方法来进行操作。这个整数可以用于表示任意状态。例如，ReentrantLock用它来表示所有者线程已经重复获取该锁的次数，Semaphore用它来表示剩余的许可数量，FutureTask 用它来表示任务的状态（尚未开始、正在运行、已完成以及已取消）。在同步器类中还可以自行管理一些额外的状态变量，例如，ReentrantLock保存了锁的当前所有者的信息，这样就能区分某个获取操作是重人的还是竞争的。</p>
<p><img src="https://i.loli.net/2021/04/11/i21lhIq7JcHLzMK.jpg" alt="AQS3"></p>
<h2 id="重要入口方法"><a href="#重要入口方法" class="headerlink" title="重要入口方法"></a>重要入口方法</h2><p>AQS里面最重要的就是两个操作和一个状态：获取操作（acquire）、释放操作（release）、同步状态（state）。两个操作通过各种条件限制，总共有8个重要的方法，6个获取方法，2个释放方法，如下：</p>
<blockquote>
<p>1.acquire(int)：独占模式的获取，忽略中断。<br>2.acquireInterruptibly(int)：独占模式的获取，可中断<br>3.tryAcquireNanos(int, long)：独占模式的获取，可中断，并且有超时时间。<br>4.release(int)：独占模式的释放。<br>5.acquireShared(int)：共享模式的获取，忽略中断。<br>6.acquireSharedInterruptibly(int)：共享模式的获取，可中断<br>7.tryAcquireSharedNanos(int, long)：共享模式的获取，可中断，并且有超时时间。<br>8.releaseShared(int)：共享模式的释放。</p>
</blockquote>
<p>而各个获取方法和释放方法其实大同小异，因此本文只对acquire(int)和release(int)方法展开详解（即独占模式下忽略中断的获取和释放），搞懂了这2个方法，读懂其他6个方法也是基本没有什么阻碍。</p>
<h2 id="几个点"><a href="#几个点" class="headerlink" title="几个点"></a>几个点</h2><p>一些比较难理解或者容易搞混的知识点，先在这里介绍一下，有助于阅读本文和源码。</p>
<blockquote>
<p>1.注意区分文中提到的队列是“同步队列”还是“条件队列”。“同步队列”通过prev属性和next属性来维护队列，“条件队列”通过nextWaiter属性来维护队列。另外，有些书将prev属性和next属性维护的队列称为“同步队列”，将nextWaiter维护的队列称为“等待队列”。根据源码的注释，其实两个队列都可以称为“等待队列”，因此特以“同步队列”和“条件队列”来区分，请注意。注：本文讲的内容基本都是“同步队列”，“条件队列”是用于Condition的实现。（参考基础属性中的图）<br> 2.nextWaiter可以分为3种情况：1）共享模式的节点，值固定为源码中的常量SHARED；2）独占模式的普通节点：值固定为源码中的常量EXCLUSIVE，也就是null；3）独占模式的条件队列节点：值指向下一个线程等待在Condition上的节点。如果觉得不好理解，可以参考基础属性下面的图。<br> 3.AQS里的队列是“CLH”锁定队列的变种， CLH通常用于自旋锁。<br> 4.prev属性主要用于处理CANCELLED状态。如果节点被取消，其后继节点会向前遍历重新链接到未被取消的前驱节点。<br> 5.acquire(int) 和 release(int) 方法解释起来比较拗口，正常的语法，动词后面应该带有名词，例如：acquireLock，但是在AQS的源码中并没有这样。因此，在本文中可能会将acquire直接解释成“获取”或直接用“acquire”。<br> 6.在实际的使用中，acquire一般都指获取锁。如ReentrantLock中的实现。<br> 7.文中提到的唤醒后继节点，即对后继节点的线程使用LockSupport.unpark方法，与之前的park方法（阻塞节点线程）对应。<br> 8.head节点（头节点）一般是指当前acquire成功的节点（通常就是当前获取到锁的节点），在设置成头节点后，会将该节点的线程设置为null。<br> 9.waitStatus=CANCELLED的节点是要丢弃（跳过）的节点，在cancelAcquire(Node)方法中，最直接的办法应该是将node节点移除，但是源码中进行了更优的处理，再移除node节点的同时，将node前面和后面的连续节点waitStatus=CANCELLED的也一并移除了。（参考下文cancelAcquire方法的图）</p>
</blockquote>
<h2 id="基础属性"><a href="#基础属性" class="headerlink" title="基础属性"></a>基础属性</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">    <span class="comment">/** Marker to indicate a node is waiting in shared mode */</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Node</span> <span class="variable">SHARED</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Node</span>();  <span class="comment">// 标记节点正在以共享模式等待</span></span><br><span class="line">    <span class="comment">/** Marker to indicate a node is waiting in exclusive mode */</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Node</span> <span class="variable">EXCLUSIVE</span> <span class="operator">=</span> <span class="literal">null</span>; <span class="comment">// 标记节点正在以独占模式等待</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 表示线程已取消：由于在同步队列中等待的线程等待超时或者被中断，</span></span><br><span class="line">    <span class="comment">// 需要从同步队列中取消等待，节点进入该状态将不会变化（即要移除/跳过的节点）</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">CANCELLED</span> <span class="operator">=</span>  <span class="number">1</span>;    </span><br><span class="line">    <span class="comment">// 表示后继节点处于park，需要唤醒：后继节点的线程处于park，而当前节点的线</span></span><br><span class="line">    <span class="comment">// 程如果进行释放操作或者被取消，将会通知后继节点，使后继节点的线程得以运行</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">SIGNAL</span>    <span class="operator">=</span> -<span class="number">1</span>;    </span><br><span class="line">    <span class="comment">// 表示线程正在等待状态：即节点在等待队列中，节点线程等待在Condition上，</span></span><br><span class="line">    <span class="comment">// 当其他线程对Condition调用了signal()方法后，该节点将会从等待队列中转移到同步队列中</span></span><br><span class="line">    <span class="comment">//（即该节点的线程调用了Condition.await()方法，需要先唤醒才能进入同步队列）</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">CONDITION</span> <span class="operator">=</span> -<span class="number">2</span>;</span><br><span class="line">    <span class="comment">// 表示下一次共享模式同步状态获取讲会无条件地被传播下去</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">PROPAGATE</span> <span class="operator">=</span> -<span class="number">3</span>;</span><br><span class="line">    <span class="comment">// 即上面的CANCELLED/SIGNAL/CONDITION/PROPAGATE，初始状态为0</span></span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">int</span> waitStatus;    <span class="comment">// 等待状态</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">volatile</span> Node prev; <span class="comment">// 前驱节点</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">volatile</span> Node next; <span class="comment">// 后继节点</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">volatile</span> Thread thread; <span class="comment">// 节点的线程(获取同步状态的线程)</span></span><br><span class="line">    <span class="comment">// 条件队列（注意和同步队列区分）中的后继节点：参见addConditionWaiter方法，</span></span><br><span class="line">    <span class="comment">// 表示下一个等待Condition的Node，如果当前节点是共享的，那么这个字段将是一个        </span></span><br><span class="line">    <span class="comment">// SHARED常量，也就是说节点类型（独占和共享）和等待队列中的后继节点共用一个字段。</span></span><br><span class="line">    Node nextWaiter; </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">isShared</span><span class="params">()</span> &#123;  <span class="comment">// 如果节点在共享模式下等待，则返回true。</span></span><br><span class="line">        <span class="keyword">return</span> nextWaiter == SHARED;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 返回节点的前驱节点，如果为null，则抛出NullPointerException</span></span><br><span class="line">    <span class="keyword">final</span> Node <span class="title function_">predecessor</span><span class="params">()</span> <span class="keyword">throws</span> NullPointerException &#123;</span><br><span class="line">        <span class="type">Node</span> <span class="variable">p</span> <span class="operator">=</span> prev;</span><br><span class="line">        <span class="keyword">if</span> (p == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">NullPointerException</span>();</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> p;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    Node() &#123;    <span class="comment">// 用于创建头节点或SHARED标记</span></span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    Node(Thread thread, Node mode) &#123;     <span class="comment">// Used by addWaiter</span></span><br><span class="line">        <span class="built_in">this</span>.nextWaiter = mode;</span><br><span class="line">        <span class="built_in">this</span>.thread = thread;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    Node(Thread thread, <span class="type">int</span> waitStatus) &#123; <span class="comment">// Used by Condition</span></span><br><span class="line">        <span class="built_in">this</span>.waitStatus = waitStatus;</span><br><span class="line">        <span class="built_in">this</span>.thread = thread;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 同步队列的头节点，使用懒汉模式初始化。 除了初始化，它只能通过setHead方法修改。 </span></span><br><span class="line"><span class="comment">// 注意：如果头节点存在，其waitStatus保证不是CANCELLED。</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> Node head;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 同步队列的尾节点，使用懒汉模式初始化。仅通过enq方法修改，用于添加新的等待节点。</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> Node tail;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 同步状态, volatile修饰，很多同步类的实现都用到了该变量，</span></span><br><span class="line"><span class="comment">// 例如：ReentrantLock、CountDownLatch等</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">int</span> state;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 返回当前的同步状态</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="type">int</span> <span class="title function_">getState</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> state;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 设置同步状态值</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title function_">setState</span><span class="params">(<span class="type">int</span> newState)</span> &#123;</span><br><span class="line">    state = newState;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 使用CAS修改同步状态值</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">compareAndSetState</span><span class="params">(<span class="type">int</span> expect, <span class="type">int</span> update)</span> &#123;</span><br><span class="line">    <span class="comment">// See below for intrinsics setup to support this</span></span><br><span class="line">    <span class="keyword">return</span> unsafe.compareAndSwapInt(<span class="built_in">this</span>, stateOffset, expect, update);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>AQS中Node是组成队列的数据结构，如下图是队列的数据结构图：<br><img src="https://i.loli.net/2021/04/11/Jm2PvOBgx7k5HZr.png" alt="AQS1"></p>
<h2 id="acquire方法"><a href="#acquire方法" class="headerlink" title="acquire方法"></a>acquire方法</h2><figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">public final void <span class="built_in">acquire</span>(int arg) &#123;</span><br><span class="line">	 <span class="comment">// tryAcquire(arg)方法：提供给子类实现的，主要用于以独占模式尝试acquire</span></span><br><span class="line">    if (!tryAcquire(arg) &amp;&amp;</span><br><span class="line">    	<span class="comment">// addWaiter方法：添加一个独占模式的节点到同步队列的尾部；</span></span><br><span class="line">        <span class="comment">// acquireQueued：该节点尝试acquire</span></span><br><span class="line">        <span class="built_in">acquireQueued</span>(addWaiter(Node.EXCLUSIVE), arg))</span><br><span class="line">        <span class="built_in">selfInterrupt</span>();	<span class="comment">// 中断当前线程</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>首先是调用tryAcquire方法，在AQS中该方法是没有实现的，子类必须实现，主要用于以独占模式尝试acquire。例如在ReentrantLock中的实现逻辑是：先获取当前的同步状态，再使用CAS尝试将同步状态修改成期望值，如果修改成功将拥有独占访问权的线程设置为当前线程。在ReentrantLock中，acquire指的是获取锁，而tryAcquire即为尝试获取锁。<br> 如果tryAcquire返回false，则尝试acquire失败了，则会调用addWaiter方法（详解见下文代码块1），添加一个独占模式的节点到同步队列尾部。 并调用acquireQueued方法（详解见下文代码块3）尝试acquire。<br> 最后，如果acquireQueued返回true，则调用selfInterrupt方法中断当前线程，这是因为acquireQueued返回true就是代表线程被中断。</p>
</blockquote>
<h2 id="tryAcquire"><a href="#tryAcquire" class="headerlink" title="tryAcquire"></a>tryAcquire</h2><p>tryAcquire方法在AQS中并没有直接实现，而是采用模板方法的设计模式，交给子类去实现。我们来看公平锁的实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">tryAcquire</span><span class="params">(<span class="type">int</span> acquires)</span> &#123;</span><br><span class="line">	<span class="comment">// 当前线程</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">Thread</span> <span class="variable">current</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">    <span class="comment">// 获取state状态，0表示未锁定，大于1表示重入</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">c</span> <span class="operator">=</span> getState();</span><br><span class="line">    <span class="keyword">if</span> (c == <span class="number">0</span>) &#123;</span><br><span class="line">    	<span class="comment">// 表示没有线程获取锁</span></span><br><span class="line">        <span class="keyword">if</span> (!hasQueuedPredecessors() &amp;&amp;</span><br><span class="line">            compareAndSetState(<span class="number">0</span>, acquires)) &#123;</span><br><span class="line">            <span class="comment">// 没有比当前线程等待更久的线程了，通过CAS的方式修改state</span></span><br><span class="line">            <span class="comment">// 成功之后，设置当前拥有独占访问权的线程</span></span><br><span class="line">            setExclusiveOwnerThread(current);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">    	<span class="comment">// 独占访问权的线程就是当前线程，重入</span></span><br><span class="line">    	<span class="comment">// 此处就是【可重入性】的实现</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">nextc</span> <span class="operator">=</span> c + acquires;</span><br><span class="line">        <span class="keyword">if</span> (nextc &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Error</span>(<span class="string">&quot;Maximum lock count exceeded&quot;</span>);</span><br><span class="line">        <span class="comment">// 直接修改state</span></span><br><span class="line">        setState(nextc);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到该方法就是以独占的方式获取锁，获取成功后返回true。从这个方法可以看出state变量是实现可重入性的关键。</p>
<p>acquire方法除了调用tryAcquire，还调用了acquireQueued(addWaiter(Node.EXCLUSIVE), arg)，这里分为两步，先看下addWaiter方法。</p>
<h2 id="代码块1：addWaiter方法"><a href="#代码块1：addWaiter方法" class="headerlink" title="代码块1：addWaiter方法"></a>代码块1：addWaiter方法</h2><figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">private <span class="keyword">Node</span> <span class="title">addWaiter</span>(<span class="keyword">Node</span> <span class="title">mode</span>) &#123;</span><br><span class="line">	// 以当前线程和mode为参数，创建一个节点</span><br><span class="line">    <span class="keyword">Node</span> <span class="title">node</span> = new <span class="keyword">Node</span><span class="title">(Thread</span>.currentThread(), mode);</span><br><span class="line">    <span class="keyword">Node</span> <span class="title">pred</span> = tail;   // 将pred赋值为当前尾节点</span><br><span class="line">    if (pred != null) &#123; 	// pred不为空</span><br><span class="line">    	// 将新创建的节点的前驱节点设置为pred，即将刚创建的节点放到尾部</span><br><span class="line">        node.prev = pred;</span><br><span class="line">        // 使用CAS将尾节点修改为新节点</span><br><span class="line">        if (compareAndSetTail(pred, <span class="keyword">node</span><span class="title">)) &#123;</span></span><br><span class="line"><span class="title">        	// 尾节点修改成功后,将pred</span>的后继节点设置为新节点,与上文node.<span class="attr">prev=</span>pred对应</span><br><span class="line">            pred.next = <span class="keyword">node</span><span class="title">; </span></span><br><span class="line"><span class="title">            return</span> <span class="keyword">node</span><span class="title">;</span></span><br><span class="line"><span class="title">        &#125;</span></span><br><span class="line"><span class="title">    &#125;</span></span><br><span class="line"><span class="title">    // 如果pred</span>为空，代表此时同步队列为空，调用enq方法将新节点添加到同步队列</span><br><span class="line">    enq(<span class="keyword">node</span><span class="title">);</span></span><br><span class="line"><span class="title">    return</span> <span class="keyword">node</span><span class="title">;</span></span><br><span class="line"><span class="title">&#125;</span></span><br></pre></td></tr></table></figure>
<p>根据当前线程和入参mode创建一个新的Node，并放到尾部。如果同步队列为空，则调用enq方法（详解见下文代码块2）添加节点。</p>
<h2 id="代码块2：enq方法"><a href="#代码块2：enq方法" class="headerlink" title="代码块2：enq方法"></a>代码块2：enq方法</h2><figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">// 将节点插入队列，如果队列为空则先进行初始化，再插入队列。</span><br><span class="line">private <span class="keyword">Node</span> <span class="title">enq</span>(final <span class="keyword">Node</span> <span class="title">node</span>) &#123;</span><br><span class="line">    for (;;) &#123;</span><br><span class="line">        <span class="keyword">Node</span> <span class="title">t</span> = tail;  // 将t赋值为尾节点</span><br><span class="line">        // 如果尾节点为空，则初始化head和tail节点</span><br><span class="line">        if (t == null) &#123;</span><br><span class="line">        	// 使用CAS将头节点赋值为一个新创建的无状态的节点</span><br><span class="line">            if (compareAndSetHead(new <span class="keyword">Node</span><span class="title">())) </span></span><br><span class="line"><span class="title">                tail</span> = head;    // 初始化尾节点</span><br><span class="line">        &#125; else &#123;    // 如果尾节点不为空，使用CAS将当前<span class="keyword">node</span><span class="title">添加到尾节点</span></span><br><span class="line"><span class="title">            node</span>.prev = t;  // 将<span class="keyword">node</span><span class="title">的前驱节点设置为t</span></span><br><span class="line">            if (compareAndSetTail(t, <span class="keyword">node</span><span class="title">)) &#123;   // 使用CAS</span>将尾节点设置为<span class="keyword">node</span></span><br><span class="line">            	<span class="title">// 成功将尾节点修改为node</span>后,将t的后驱节点设置为<span class="keyword">node</span><span class="title">,与node</span>.<span class="attr">prev=</span>t对应</span><br><span class="line">                t.next = <span class="keyword">node</span><span class="title">;</span></span><br><span class="line"><span class="title">                return</span> t;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果队列为空，则先初始化head和tail节点（介绍属性时说过了，head和tail采用懒汉模式初始化），再使用CAS将node添加到队列尾部。<br> 如果队列不为空，直接使用CAS将node添加到队列尾部。</p>
</blockquote>
<p>该方法和上面的addWaiter方法其实很相似，只是多了一个队列为空时的初始化head和tail操作。<br>需要注意的是，该方法返回的Node节点不是新插入的节点，而是新插入节点的前驱节点。</p>
<h2 id="代码块3：acquireQueued方法"><a href="#代码块3：acquireQueued方法" class="headerlink" title="代码块3：acquireQueued方法"></a>代码块3：acquireQueued方法</h2><figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">// 添加完节点后，立即尝试该节点是否能够成功acquire</span><br><span class="line">final boolean acquireQueued(final <span class="keyword">Node</span> <span class="title">node</span>, int arg) &#123;</span><br><span class="line">    boolean failed = <span class="literal">true</span>;</span><br><span class="line">    try &#123;</span><br><span class="line">        boolean interrupted = <span class="literal">false</span>;    // 用于判断是否被中断过</span><br><span class="line">        for (;;) &#123;  // 自旋过程</span><br><span class="line">            final <span class="keyword">Node</span> <span class="title">p</span> = node.predecessor();  // 将p赋值为<span class="keyword">node</span><span class="title">的前驱节点</span></span><br><span class="line"><span class="title">            // 如果p</span>为头节点，则<span class="keyword">node</span><span class="title">节点尝试以独占模式acquire</span>（acquire一般为获取锁）</span><br><span class="line">            if (p == head &amp;&amp; tryAcquire(arg)) &#123;</span><br><span class="line">            	// <span class="keyword">node</span><span class="title">节点成功以独占模式acquire</span>，调用setHead方法将<span class="keyword">node</span><span class="title">设置为头节点</span></span><br><span class="line"><span class="title">                setHead</span>(<span class="keyword">node</span><span class="title">);</span></span><br><span class="line"><span class="title">                p</span>.next = null; // 断开原头节点与<span class="keyword">node</span><span class="title">节点的关联</span></span><br><span class="line"><span class="title">                failed</span> = <span class="literal">false</span>;</span><br><span class="line">                return interrupted; // 返回<span class="keyword">node</span><span class="title">是否被中断过</span></span><br><span class="line"><span class="title">            &#125;</span></span><br><span class="line"><span class="title">            // shouldParkAfterFailedAcquire</span>: 校验<span class="keyword">node</span><span class="title">是否需要park</span>(park：会将<span class="keyword">node</span><span class="title">的线程阻塞)</span></span><br><span class="line"><span class="title">            // 只有当前驱节点等待状态为SIGNAL</span>，才能将<span class="keyword">node</span><span class="title">进行park</span>，因为当前驱节点为SIGNAL</span><br><span class="line">            // 时，会保证来唤醒自己，因此可以安心park</span><br><span class="line">            if (shouldParkAfterFailedAcquire(p, <span class="keyword">node</span><span class="title">) &amp;&amp;</span></span><br><span class="line"><span class="title">            	// node</span>进入park状态，直到被前驱节点唤醒，被唤醒后返回线程是否为中断状态</span><br><span class="line">                parkAndCheckInterrupt())</span><br><span class="line">                interrupted = <span class="literal">true</span>; // 在等待过程中被中断</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        if (failed)</span><br><span class="line">            cancelAcquire(<span class="keyword">node</span><span class="title">); // 取消正在进行的acquire</span>尝试，走到这边代表出现异常</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>该方法用于添加完节点后调用，首先判断node节点的前驱节点是否为head，如果是，node会尝试acquire，如果node成功acquire，会调用setHead方法，将node设置为head、将node的thread设置为null、将node的prev设置为null，这保证了数据结构中头节点永远是一个不带Thread的空节点。<br> 如果node节点的前驱节点不是head，或者node尝试acquire失败，则会调用shouldParkAfterFailedAcquire方法（详解见下文代码块4）校验node是否需要park（此处park是将node的线程阻塞，LockSupport.park），如果shouldParkAfterFailedAcquire返回true则调用parkAndCheckInterrupt方法（详解见下文代码块5）将node的线程阻塞。<br> 如果走到finally方法时，failed为true，则代表出现了异常，调用cancelAcquire方法（详解见下文代码块6）取消正在进行的acquire尝试。</p>
</blockquote>
<h2 id="代码块4：shouldParkAfterFailedAcquire方法"><a href="#代码块4：shouldParkAfterFailedAcquire方法" class="headerlink" title="代码块4：shouldParkAfterFailedAcquire方法"></a>代码块4：shouldParkAfterFailedAcquire方法</h2><figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 判断节点是否应该park</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="type">static</span> <span class="type">boolean</span> <span class="title">shouldParkAfterFailedAcquire</span><span class="params">(Node pred, Node node)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> ws = pred.waitStatus;   <span class="comment">// 前驱节点的等待状态</span></span><br><span class="line">    <span class="keyword">if</span> (ws == Node.SIGNAL) <span class="comment">// 如果前驱节点节点等待状态为SIGNAL，</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>; <span class="comment">// 返回true，表示node节点应该park，等待它的前驱节点来唤醒</span></span><br><span class="line">    <span class="comment">// 如果前驱节点的等待状态&gt;0，代表该前驱节点为CANCELLED（取消）状态，需要跳过该节点</span></span><br><span class="line">    <span class="keyword">if</span> (ws &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    	<span class="comment">// 从pred节点开始向前寻找，直到找到等待状态不为CANCELLED的，</span></span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            node.prev = pred = pred.prev; <span class="comment">// 将其设置为node的前驱节点</span></span><br><span class="line">        &#125; <span class="keyword">while</span> (pred.waitStatus &gt; <span class="number">0</span>);</span><br><span class="line">        pred.next = node;   <span class="comment">// 与上面对应</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    	<span class="comment">// pred节点使用CAS尝试将等待状态修改为SIGNAL（ws必须为PROPAGATE或0），</span></span><br><span class="line">    	<span class="comment">// 然后返回false（即再尝试一次能否不park直接acquire成功），</span></span><br><span class="line">        <span class="built_in">compareAndSetWaitStatus</span>(pred, ws, Node.SIGNAL);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;	<span class="comment">// 返回false，代表node还不能park</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果前驱节点pred的waitStatus为SIGNAL，返回true，表示node节点应该park，等待它的前驱节点来唤醒。<br> 如果前驱节点pred的waitStatus&gt;0，代表该节点为CANCELLED（取消）状态，需要跳过该节点。从pred节点开始向前寻找，直到找到等待状态不为CANCELLED的，将其设置为node的前驱节点。<br> 否则，使用CAS尝试将pred节点的waitStatus修改为SIGNAL，然后返回false，这里直接返回false是为了再执行一次acquireQueued方法for循环的“if (p == head &amp;&amp; tryAcquire(arg))”代码，因为如果能tryAcquire成功，则避免了当前线程阻塞，也就减少了上下文切换的开销。</p>
</blockquote>
<h2 id="代码块5：parkAndCheckInterrupt方法"><a href="#代码块5：parkAndCheckInterrupt方法" class="headerlink" title="代码块5：parkAndCheckInterrupt方法"></a>代码块5：parkAndCheckInterrupt方法</h2><figure class="highlight aspectj"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="function"><span class="keyword">boolean</span> <span class="title">parkAndCheckInterrupt</span><span class="params">()</span> </span>&#123; <span class="comment">// 等待，然后检查是否被中断</span></span><br><span class="line">    LockSupport.park(<span class="keyword">this</span>); <span class="comment">// 阻塞当前节点的线程</span></span><br><span class="line">    <span class="function"><span class="keyword">return</span> Thread.<span class="title">interrupted</span><span class="params">()</span></span>;    <span class="comment">// 返回当前线程是否为中断状态</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用LockSupport.park方法将当前线程阻塞，并在被唤醒之后，返回当前线程是否为中断状态。</p>
<h2 id="代码块6：cancelAcquire方法"><a href="#代码块6：cancelAcquire方法" class="headerlink" title="代码块6：cancelAcquire方法"></a>代码块6：cancelAcquire方法</h2><figure class="highlight axapta"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> cancelAcquire(Node node) &#123; <span class="comment">// 取消正在进行的acquire尝试</span></span><br><span class="line">    <span class="keyword">if</span> (node == <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"> </span><br><span class="line">    node.thread = <span class="literal">null</span>;</span><br><span class="line"> </span><br><span class="line">    Node pred = node.prev;</span><br><span class="line">    <span class="comment">// node的前驱节点pred的waitStatus如果为CANCELLED，</span></span><br><span class="line">    <span class="comment">// 则向前寻找waitStatus不为CANCELLED的前驱节点pred</span></span><br><span class="line">    <span class="keyword">while</span> (pred.waitStatus &gt; <span class="number">0</span>)</span><br><span class="line">        node.prev = pred = pred.prev;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 拿到pred的后继节点（不一定为node，请注意）</span></span><br><span class="line">    Node predNext = pred.<span class="keyword">next</span>;</span><br><span class="line"> </span><br><span class="line">    node.waitStatus = Node.CANCELLED;   <span class="comment">// 将node的waitStatus设置为CANCELLED</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 如果node为尾节点，则使用CAS将尾节点改为pred节点</span></span><br><span class="line">    <span class="comment">// 即将pred后面的节点全部移除，包括node节点和node前面状态为CANCELLED的节点</span></span><br><span class="line">    <span class="keyword">if</span> (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123;</span><br><span class="line">        <span class="comment">// 将pred的后继节点设置为null，与上面对应</span></span><br><span class="line">        compareAndSetNext(pred, predNext, <span class="literal">null</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">    	<span class="comment">// 否则，node不是尾节点，即node有后继节点，移除了node节点需要保证node</span></span><br><span class="line">    	<span class="comment">// 的后继节点不会受到影响，因此会根据情况决定是否需要唤醒node的后继节点</span></span><br><span class="line">        <span class="built_in">int</span> ws;</span><br><span class="line">        <span class="comment">// 如果后继节点需要唤醒信号，并且pred可以提供给它,则将pred.next设置为node的后继节点，</span></span><br><span class="line">        <span class="comment">// 这样在pred释放的时候就会提供一个信号给node的后继节点，从而保证node的后继节点不受影响</span></span><br><span class="line">        <span class="keyword">if</span> (pred != head &amp;&amp;</span><br><span class="line">            ((ws = pred.waitStatus) == Node.SIGNAL ||</span><br><span class="line">             (ws &lt;= <span class="number">0</span> &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp;</span><br><span class="line">            pred.thread != <span class="literal">null</span>) &#123;</span><br><span class="line">            Node <span class="keyword">next</span> = node.<span class="keyword">next</span>;  <span class="comment">// 拿到node的后继节点next</span></span><br><span class="line">            <span class="comment">// 如果next不为null并且等待状态不为CANCELLED</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">next</span> != <span class="literal">null</span> &amp;&amp; <span class="keyword">next</span>.waitStatus &lt;= <span class="number">0</span>)</span><br><span class="line">            	<span class="comment">// 则使用CAS将pred的后继节点修改为next，</span></span><br><span class="line">            	<span class="comment">// 因为只有pred的waitStatus为SIGNAL时才能走到这边，因此next节点无需唤醒</span></span><br><span class="line">                compareAndSetNext(pred, predNext, <span class="keyword">next</span>); </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// 否则，如果pred节点无法提供给node的后继节点信号，则直接唤醒node的后继节点</span></span><br><span class="line">            unparkSuccessor(node);  <span class="comment">// 唤醒node节点的后继节点</span></span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        node.<span class="keyword">next</span> = node; <span class="comment">// help GC</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果node为空，直接返回。<br> 如果node的前驱节点pred的waitStatus为CANCELLED，则向前寻找等待状态不为CANCELLED的前驱节点pred。<br> 将predNext赋值为pred节点的后继节点。<br> 将node的waitStatus设置为CANCELLED。<br> 如果node为尾节点，则使用CAS将尾节点改为pred节点（即将pred后面的节点全部移除，包括node节点和node前面状态为CANCELLED的节点），如果修改尾节点成功，则使用CAS将pred节点的后继节点设置为null。<br> 否则，node不是尾节点。判断pred节点是否可以提供给node后继节点唤醒信号。（pred可以提供唤醒信号：即pred满足以下条件：pred不为头节点 &amp;&amp; (pred的等待状态为SIGNAL 或 pred的等待状态使用CAS成功修改为SIGNAL) &amp;&amp; pred节点的线程不为null）如果可以，则将pred.next设置为node的后继节点，这样在pred释放的时候就会提供一个信号给node的后继节点，从而保证node的后继节点不受影响；如果pred节点无法提供给node的后继节点唤醒信号，则直接调用unparkSuccessor方法（详解见下文代码块7）唤醒node的后继节点。</p>
</blockquote>
<p>cancelAcquire(Node)方法涉及的移除节点过程如下图例子：<br><img src="https://i.loli.net/2021/04/11/vctDPk35lCsLrxN.png" alt="AQS2"></p>
<h2 id="代码块7：unparkSuccessor方法"><a href="#代码块7：unparkSuccessor方法" class="headerlink" title="代码块7：unparkSuccessor方法"></a>代码块7：unparkSuccessor方法</h2><figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">private void unparkSuccessor(<span class="keyword">Node</span> <span class="title">node</span>) &#123;   // 唤醒<span class="keyword">node</span><span class="title">节点的后继节点</span></span><br><span class="line"><span class="title"> </span></span><br><span class="line"><span class="title">    int</span> ws = node.waitStatus;</span><br><span class="line">    // 如果<span class="keyword">node</span><span class="title">的waitStatus</span><span class="tag">&lt;0（即node的waitStatus不为CANCELLED），</span></span><br><span class="line"><span class="tag">    // 则使用CAS将等待状态改为0，即初始状态（因为下面马上要将node的后继节点唤醒）</span></span><br><span class="line"><span class="tag">    if (ws &lt; 0)</span></span><br><span class="line"><span class="tag">        compareAndSetWaitStatus(node, ws, 0);</span></span><br><span class="line"><span class="tag"> </span></span><br><span class="line"><span class="tag">    Node s = node.next; // 定义s为node的后继节点</span></span><br><span class="line"><span class="tag">    // 如果s为null或者waitStatus为CANCELLED</span></span><br><span class="line"><span class="tag">    if (s == null || s.waitStatus &gt;</span> <span class="number">0</span>) &#123; </span><br><span class="line">        s = null;   // 直接将s赋值为null</span><br><span class="line">        // 并从尾部向前遍历以找到实际未取消的后继节点（离<span class="keyword">node</span><span class="title">最近），</span></span><br><span class="line"><span class="title">        // 这里的意思是将node</span>之后的空节点或<span class="attr">waitStatus=</span>CANCELLED的节点也</span><br><span class="line">        // 一并去掉，直接唤醒<span class="keyword">node</span><span class="title">之后waitStatus</span>不为CANCELLED的节点</span><br><span class="line">        for (<span class="keyword">Node</span> <span class="title">t</span> = tail; t != null &amp;&amp; t != <span class="keyword">node</span><span class="title">; t</span> = t.prev)</span><br><span class="line">            if (t.waitStatus <span class="tag">&lt;= 0)</span></span><br><span class="line"><span class="tag">                s = t;</span></span><br><span class="line"><span class="tag">    &#125;</span></span><br><span class="line"><span class="tag">    if (s != null)</span></span><br><span class="line"><span class="tag">        LockSupport.unpark(s.thread);   // 如果s不为null，则唤醒s节点</span></span><br><span class="line"><span class="tag">&#125;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>1.如果node的waitStatus&lt;0（即node的后继节点可能需要信号），则使用CAS将等待状态改为0，即初始状态（因为下面马上要将node的后继节点唤醒）。<br> 2.定义s为node的后继节点，如果s为null或者waitStatus为CANCELLED，则从同步队列尾部向前遍历以找到实际未取消的后继节点（离node最近），这里的意思是将node之后的空节点或waitStatus=CANCELLED的节点也一并去掉，直接唤醒node之后waitStatus不为CANCELLED的节点。<br> 3.最后，如果s不为null，则使用LockSupport.unpark哈un型s节点。</p>
</blockquote>
<h2 id="release方法"><a href="#release方法" class="headerlink" title="release方法"></a>release方法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">release</span><span class="params">(<span class="type">int</span> arg)</span> &#123;</span><br><span class="line">	<span class="comment">// tryRelease：提供给子类实现的，主要用于以独占模式尝试release（release通常指释放锁）</span></span><br><span class="line">    <span class="keyword">if</span> (tryRelease(arg)) &#123;</span><br><span class="line">        <span class="type">Node</span> <span class="variable">h</span> <span class="operator">=</span> head;  </span><br><span class="line">        <span class="keyword">if</span> (h != <span class="literal">null</span> &amp;&amp; h.waitStatus != <span class="number">0</span>)</span><br><span class="line">            unparkSuccessor(h); <span class="comment">// 唤醒头节点的后继节点线程</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>1.首先是调用tryRelease方法，跟上文的tryAcquire一样，在AQS中该方法是没有实现的，子类必须实现。一般是用于解锁，例如再ReentrantLock中：tryRelease方法会将同步状态值（state）减去入参中要释放的值，如果减完的同步状态值为0，则将独占模式同步器的当前所有者设为null，即代表了解锁的意思。<br> 2.如果tryRelease成功，并且head节点不为空，且状态不为初始状态，则调用unparkSuccessor方法（详解见上文的代码块7）唤醒head节点的后继节点。</p>
</blockquote>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发：Java内存模型（JMM）与线程</title>
    <url>/2021/04/22/Java%E5%B9%B6%E5%8F%91%EF%BC%9AJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88JMM%EF%BC%89%E4%B8%8E%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>多任务处理在现代计算机操作系统中几乎已是一项必备的功能了。在许多情况下，让计算机同时去做几件事情，不仅是因为计算机的运算能力强大了，还有一个很重要的原因是计算机的运算速度与它的存储和通信子系统速度的差距太大，大量的时间都花费在磁盘I/O、网络通信或者数据库访问上。如果不希望处理器在大部分时间里都处于等待其他资源的状态，就必须使用一些手段去把处理器的运算能力“压榨”出来，否则就会造成很大的浪费，而让计算机同时处理几项任务则是最容易想到、也被证明是非常有效的“压榨”手段。</p>
<p>除了充分利用计算机处理器的能力外，一个服务端同时对多个客户端提供服务则是另一个更具体的并发应用场景。衡量一个服务性能的高低好坏，每秒事务处理数（Transactions Per Second,TPS）是最重要的指标之一，它代表着一秒内服务端平均能响应的请求总数，而TPS值与程序的并发能力又有非常密切的关系。对于计算量相同的任务，程序线程并发协调得越有条不紊，效率自然就会越高;反之，线程之间频繁阻塞甚至死锁，将会大大降低程序的并发能力。</p>
<span id="more"></span>

<h2 id="硬件的效率与一致性"><a href="#硬件的效率与一致性" class="headerlink" title="硬件的效率与一致性"></a>硬件的效率与一致性</h2><p>“让计算机并发执行若干个运算任务”与“更充分地利用计算机处理器的效能”之间的因果关系，看起来顺理成章，实际上它们之间的关系并没有想象中的那么简单，其中一个重要的复杂性来源是绝大多数的运算任务都不可能只靠处理器“计算”就能完成，处理器至少要与内存交互，如读取运算数据、存储运算结果等，这个I/O操作是很难消除的（无法仅靠寄存器来完成所有运算任务）。由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。</p>
<p> 基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统带来更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main Memory），如下图所示。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及 Dragon Protocol等。在本文中将会多次提到的“内存模型”一词，可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。不同架构的物理机器可以拥有不一样的内存模型，而Java虚拟机也有自己的内存模型，并且这里介绍的内存访问操作与硬件的缓存访问操作具有很高的可比性。<br><img src="https://i.loli.net/2021/04/22/l5DpVy2ht1djubY.png" alt="1"></p>
<p>除了增加高速缓存之外，为了使得处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此，如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Reorder）优化。</p>
<h2 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h2><p>Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model,JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。在此之前，主流程序语言（如C/C++等）直接使用物理硬件和操作系统的内存模型，因此，会由于不同平台上内存模型的差异，有可能导致程序在一套平台上并发完全正常，而在另外一套平台上并发访问却经常出错，因此在某些场景就必须针对不同的平台来编写程序。</p>
<p>定义Java内存模型并非一件容易的事情，这个模型必须定义得足够严谨，才能让Java的并发内存访问操作不会产生歧义;但是，也必须定义得足够宽松，使得虚拟机的实现有足够的自由空间去利用硬件的各种特性（寄存器、高速缓存和指令集中某些特有的指令）来获取更好的执行速度。经过长时间的验证和修补，在JDK 1.5（实现了JSR-133）发布后，Java内存模型已经成熟和完善起来了。</p>
<h3 id="主内存和工作内存"><a href="#主内存和工作内存" class="headerlink" title="主内存和工作内存"></a>主内存和工作内存</h3><p>Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。此处的变量（Variables）与Java编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。为了获得较好的执行效能，Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施。</p>
<p>Java内存模型规定了所有的变量都存储在主内存（Main Memory）中（此处的主内存与介绍物理硬件时的主内存名字一样，两者也可以互相类比，但此处仅是虚拟机内存的一部分）。每条线程还有自己的工作内存（Working Memory，可与前面讲的处理器高速缓存类比），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如图所示。<br><img src="https://i.loli.net/2021/04/22/v8lZIVn1hKwWjaT.png" alt="2"></p>
<p>主内存就直接对应于物理硬件的内存，而为了获取更好的运行速度，虚拟机（甚至是硬件系统本身的优化措施）可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问读写的是工作内存。</p>
<h3 id="内存间交互操作"><a href="#内存间交互操作" class="headerlink" title="内存间交互操作"></a>内存间交互操作</h3><p>关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的（对于double和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外）。</p>
<blockquote>
<p>lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。<br> unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。<br> read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。<br> load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。<br> use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。<br> assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。<br> store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。<br> write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。</p>
</blockquote>
<p>如果要把一个变量从主内存复制到工作内存，那就要顺序地执行read和load操作，如果要把变量从工作内存同步回主内存，就要顺序地执行store和write操作。注意，Java内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行。也就是说，read与load之间、store与write之间是可插入其他指令的，如对主内存中的变量a、b进行访问时，一种可能出现顺序是read a、read b、load b、load a。除此之外，Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则：</p>
<blockquote>
<p>不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现。<br> 不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。<br> 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。<br>  一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说，就是对一个变量实施use、store操作之前，必须先执行过了assign和load操作。<br> 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。<br> 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。<br> 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定住的变量。<br> 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）。</p>
</blockquote>
<p>这8种内存访问操作以及上述规则限定，再加上稍后介绍的对volatile的一些特殊规定，就已经完全确定了Java程序中哪些内存访问操作在并发下是安全的。由于这种定义相当严谨但又十分烦琐，实践起来很麻烦，所以在下文将介绍这种定义的一个等效判断原则——先行发生原则，用来确定一个访问在并发环境下是否安全。</p>
<h3 id="对于volatile型变量的特殊规则"><a href="#对于volatile型变量的特殊规则" class="headerlink" title="对于volatile型变量的特殊规则"></a>对于volatile型变量的特殊规则</h3><p>关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制，但是它并不容易完全被正确、完整地理解，以至于许多程序员都习惯不去使用它，遇到需要处理多线程数据竞争问题的时候一律使用synchronized来进行同步。了解volatile变量的语义对后面了解多线程操作的其他特性很有意义，在本节中我们将多花费一些时间去弄清楚volatile的语义到底是什么。</p>
<p>Java内存模型对volatile专门定义了一些特殊的访问规则，当一个变量定义为volatile之后，它将具备两种特性，第一是保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。而普通变量不能做到这一点，普通变量的值在线程间传递均需要通过主内存来完成，例如，线程A修改一个普通变量的值，然后向主内存进行回写，另外一条线程B在线程A回写完成了之后再从主内存进行读取操作，新变量值才会对线程B可见。</p>
<p>关于volatile变量的可见性，经常会被开发人员误解，认为以下描述成立：“volatile变量对所有线程是立即可见的，对volatile变量所有的写操作都能立刻反应到其他线程之中，换句话说，volatile变量在各个线程中是一致的，所以基于volatile变量的运算在并发下是安全的”。这句话的论据部分并没有错，但是其论据并不能得出“基于volatile变量的运算在并发下是安全的”这个结论。volatile变量在各个线程的工作内存中不存在一致性问题（在各个线程的工作内存中，volatile变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执行引擎看不到不一致的情况，因此可以认为不存在一致性问题），但是Java里面的运算并非原子操作，导致volatile变量的运算在并发下一样是不安全的，我们可以通过一段简单的演示来说明原因，请看下面的例子。<br><img src="https://i.loli.net/2021/04/22/8v6S5ANZuDIdzwf.png" alt="3"></p>
<p>这段代码发起了20个线程，每个线程对race变量进行10000次自增操作，如果这段代码能够正确并发的话，最后输出的结果应该是200000。读者运行完这段代码之后，并不会获得期望的结果，而且会发现每次运行程序，输出的结果都不一样，都是一个小于200000的数字，这是为什么呢？</p>
<p>问题就出现在自增运算“race++”之中，我们用Javap反编译这段代码后会得到下面代码清单，发现只有一行代码的increase（）方法在Class文件中是由4条字节码指令构成的（return指令不是由race++产生的，这条指令可以不计算），从字节码层面上很容易就分析出并发失败的原因了：当getstatic指令把race的值取到操作栈顶时，volatile关键字保证了race的值在此时是正确的，但是在执行iconst_1、iadd这些指令的时候，其他线程可能已经把race的值加大了，而在操作栈顶的值就变成了过期的数据，所以putstatic指令执行后就可能把较小的race值同步回主内存之中。 </p>
<p>由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通过加锁（使用synchronized或java.util.concurrent中的原子类）来保证原子性。</p>
<blockquote>
<p>运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。<br> 变量不需要与其他的状态变量共同参与不变约束。</p>
</blockquote>
<p>使用volatile变量的第二个语义是禁止指令重排序优化，普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。因为在一个线程的方法执行过程中无法感知到这点，这也就是Java内存模型中描述的所谓的“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics）。我们通过一个常见的例子来看看为何指令重排序会干扰程序的并发执行。</p>
<p>例子：双重检测机制实现单例<br><img src="https://i.loli.net/2021/04/22/OBoDqWhVlEt9FM3.png" alt="4"><br>这段代码是单例的双重检测机制实现，相信很多人都用过，并且觉得这个代码是没问题的。在大多数情况，这段代码确实没问题，但在极端的情况下，有个隐藏的问题。</p>
<p><strong>例子分析：</strong><br>假设有两个线程同时访问这段代码，此时线程A走到18行开始初始化对象，线程B则刚走到15行进行第一次检测。这时要介绍下18行初始化这行代码，这行代码虽然只有一句话，但是被编译后会变成以下3条指令：</p>
<figure class="highlight smali"><table><tr><td class="code"><pre><span class="line">memory = allocate（）;	// 1.分配对象的内存空间</span><br><span class="line">ctorInstance（memory）;	// 2.初始化对象<span class="built_in"></span></span><br><span class="line"><span class="built_in">instance </span>= memory;	// 3.设置instance指向刚才分配的内存地址</span><br></pre></td></tr></table></figure>
<p>正常情况下，这3条执行时按顺序执行，双重检测机制就没有问题。但是CPU内部会在保证不影响最终结果的前提下对指令进行重新排序，指令重排的主要目的是为了提高效率。在本例中，如果这3条指令被重排成以下顺序：</p>
<figure class="highlight smali"><table><tr><td class="code"><pre><span class="line">memory = allocate（）;	// 1.分配对象的内存空间<span class="built_in"></span></span><br><span class="line"><span class="built_in">instance </span>= memory;	// 3.设置instance指向刚才分配的内存地址</span><br><span class="line">ctorInstance（memory）;	// 2.初始化对象</span><br></pre></td></tr></table></figure>
<p>如果线程A执行完1和3，instance对象还未完成初始化，但是已经不再指向null。此时线程B抢占到CPU资源，执行第15行的检测结果为false，从而返回一个还未初始化完成的instance对象，从而出导致问题出现。要解决这个问题，只需要使用volatile关键字修饰instance对象即可。</p>
<h3 id="原子性、可见性与有序性"><a href="#原子性、可见性与有序性" class="headerlink" title="原子性、可见性与有序性"></a>原子性、可见性与有序性</h3><p><strong>原子性：</strong>由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write，我们大致可以认为基本数据类型的访问读写是具备原子性的（例外就是long和double的非原子性协定，读者只要知道这件事情就可以了，无须太过在意这些几乎不会发生的例外情况）。</p>
<p>如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块之间的操作也具备原子性。</p>
<p><strong>可见性：</strong>可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。上文在讲解volatile变量的时候我们已详细讨论过这一点。Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通变量还是volatile变量都是如此，普通变量与volatile变量的区别是，volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。因此，可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。</p>
<p>除了volatile之外，Java还有两个关键字能实现可见性，即synchronized和final。同步块的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）”这条规则获得的，而final关键字的可见性是指：被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那在其他线程中就能看见final字段的值。如代码清单12-7所示，变量i与j都具备可见性，它们无须同步就能被其他线程正确访问。</p>
<p><strong>有序性：</strong>Java内存模型的有序性在前面讲解volatile时也详细地讨论过了，Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的;如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics），后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。</p>
<p>Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这条规则决定了持有同一个锁的两个同步块只能串行地进入。</p>
<p>介绍完并发中3种重要的特性后，读者有没有发现synchronized关键字在需要这3种特性的时候都可以作为其中一种的解决方案？看起来很“万能”吧。的确，大部分的并发控制操作都能使用synchronized来完成。synchronized的“万能”也间接造就了它被程序员滥用的局面，越“万能”的并发控制，通常会伴随着越大的性能影响。</p>
<h3 id="先行发生原则"><a href="#先行发生原则" class="headerlink" title="先行发生原则"></a>先行发生原则</h3><p>如果Java内存模型中所有的有序性都仅仅靠volatile和synchronized来完成，那么有一些操作将会变得很烦琐，但是我们在编写Java并发代码的时候并没有感觉到这一点，这是因为Java语言中有一个“先行发生”（happens-before）的原则。这个原则非常重要，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则一揽子地解决并发环境下两个操作之间是否可能存在冲突的所有问题。</p>
<p>现在就来看看“先行发生”原则指的是什么。先行发生是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。这句话不难理解，但它意味着什么呢？我们可以举个例子来说明一下，如代码清单12-8中所示的这3句伪代码。</p>
<figure class="highlight abnf"><table><tr><td class="code"><pre><span class="line">//以下操作在线程A中执行</span><br><span class="line"><span class="attribute">i</span><span class="operator">=</span><span class="number">1</span><span class="comment">;</span></span><br><span class="line">//以下操作在线程B中执行</span><br><span class="line"><span class="attribute">j</span><span class="operator">=</span>i<span class="comment">;</span></span><br><span class="line">//以下操作在线程C中执行</span><br><span class="line"><span class="attribute">i</span><span class="operator">=</span><span class="number">2</span><span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>假设线程A中的操作“i=1”先行发生于线程B的操作“j=i”，那么可以确定在线程B的操作执行后，变量j的值一定等于1，得出这个结论的依据有两个：一是根据先行发生原则，“i=1”的结果可以被观察到;二是线程C还没“登场”，线程A操作结束之后没有其他线程会修改变量i的值。现在再来考虑线程C，我们依然保持线程A和线程B之间的先行发生关系，而线程C出现在线程A和线程B的操作之间，但是线程C与线程B没有先行发生关系，那j的值会是多少呢？答案是不确定！1和2都有可能，因为线程C对变量i的影响可能会被线程B观察到，也可能不会，这时候线程B就存在读取到过期数据的风险，不具备多线程安全性。</p>
<p>下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。</p>
<blockquote>
<p>程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。<br> 管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。<br> volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。<br> 线程启动规则（Thread Start Rule）：Thread对象的start（）方法先行发生于此线程的每一个动作。<br> 线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的<br> 终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。<br> 线程中断规则（Thread Interruption Rule）：对线程interrupt（）方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted（）方法检测到是否有中断发生。<br> 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize（）方法的开始。<br> 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。</p>
</blockquote>
<p>Java语言无须任何同步手段保障就能成立的先行发生规则就只有上面这些了，下面演示一下如何使用这些规则去判定操作间是否具备顺序性，对于读写共享变量的操作来说，就是线程是否安全，读者还可以从下面这个例子中感受一下“时间上的先后顺序”与“先行发生”之间有什么不同。</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="built_in">int</span> <span class="keyword">value</span>=<span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line"><span class="function">pubilc <span class="keyword">void</span> <span class="title">setValue</span>(<span class="params"><span class="built_in">int</span> <span class="keyword">value</span></span>)</span>&#123; </span><br><span class="line">    <span class="keyword">this</span>.<span class="keyword">value</span>=<span class="keyword">value</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="built_in">int</span> <span class="title">getValue</span>()</span>&#123; </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">value</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码时一组再普通不过的getter/setter方法，假设存在线程A和B，线程A先（时间上的先后）调用了“setValue(1)”，然后线程B调用了同一个对象的“getValue()”，那么线程B收到的返回值是什么？</p>
<p>我们依次分析一下先行发生原则中的各项规则，由于两个方法分别由线程A和线程B调用，不在一个线程中，所以程序次序规则在这里不适用;由于没有同步块，自然就不会发生lock和unlock操作，所以管程锁定规则不适用;由于value变量没有被volatile关键字修饰，所以volatile变量规则不适用;后面的线程启动、终止、中断规则和对象终结规则也和这里完全没有关系。因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起，因此我们可以判定尽管线程A在操作时间上先于线程B，但是无法确定线程B中“getValue()”方法的返回结果，换句话说，这里面的操作不是线程安全的。</p>
<p>那怎么修复这个问题呢？我们至少有两种比较简单的方案可以选择：要么把getter/setter方法都定义为synchronized方法，这样就可以套用管程锁定规则;要么把value定义为volatile变量，由于setter方法对value的修改不依赖value的原值，满足volatile关键字使用场景，这样就可以套用volatile变量规则来实现先行发生关系。</p>
<p>通过上面的例子，我们可以得出结论：一个操作“时间上的先发生”不代表这个操作会是“先行发生”，那如果一个操作“先行发生”是否就能推导出这个操作必定是“时间上的先发生”呢？很遗憾，这个推论也是不成立的，一个典型的例子就是多次提到的“指令重排序”，演示例子如下代码所示。</p>
<blockquote>
<p>//以下操作在同一个线程中执行<br> int i=1;<br> int j=2;</p>
</blockquote>
<p>代码清单的两条赋值语句在同一个线程之中，根据程序次序规则，“int i=1”的操作先行发生于“int j=2”，但是“int j=2”的代码完全可能先被处理器执行，这并不影响先行发生原则的正确性，因为我们在这条线程之中没有办法感知到这点。</p>
<p>上面两个例子综合起来证明了一个结论：时间先后顺序与先行发生原则之间基本没有太大的关系，所以我们衡量并发安全问题的时候不要受到时间顺序的干扰，一切必须以先行发生原则为准。</p>
<h2 id="Java与线程"><a href="#Java与线程" class="headerlink" title="Java与线程"></a>Java与线程</h2><p>并发不一定要依赖多线程（如PHP中很常见的多进程并发），但是在Java里面谈论并发，大多数都与线程脱不开关系。</p>
<h3 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h3><p>我们知道，线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、文件I/O等），又可以独立调度（线程是CPU调度的基本单位）。</p>
<p>主流的操作系统都提供了线程实现，Java语言则提供了在不同硬件和操作系统平台下对线程操作的统一处理，每个已经执行start()且还未结束的java.lang.Thread类的实例就代表了一个线程。我们注意到Thread类与大部分的Java API有显著的差别，它的所有关键方法都是声明为Native的。在Java API中，一个Native方法往往意味着这个方法没有使用或无法使用平台无关的手段来实现（当然也可能是为了执行效率而使用Native方法，不过，通常最高效率的手段也就是平台相关的手段）。</p>
<p>实现线程主要有3种方式：使用内核线程实现、使用用户线程实现和使用用户线程加轻量级进程混合实现。</p>
<h4 id="使用内核线程实现"><a href="#使用内核线程实现" class="headerlink" title="使用内核线程实现"></a>使用内核线程实现</h4><p>内核线程（Kernel-Level Thread,KLT）就是直接由操作系统内核（Kernel，下称内核）支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核（Multi-Threads Kernel）。</p>
<p>程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Light Weight Process,LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程之间1:1的关系称为一对一的线程模型<br><img src="https://i.loli.net/2021/04/23/IDRPhBUwYFf3c82.png" alt="5"></p>
<p>由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即使有一个轻量级进程在系统调用中阻塞了，也不会影响整个进程继续工作，但是轻量级进程具有它的局限性：首先，由于是基于内核线程实现的，所以各种线程操作，如创建、析构及同步，都需要进行系统调用。而系统调用的代价相对较高，需要在用户态（User Mode）和内核态（Kernel Mode）中来回切换。其次，每个轻量级进程都需要有一个内核线程的支持，因此轻量级进程要消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是有限的。</p>
<h4 id="使用用户线程实现"><a href="#使用用户线程实现" class="headerlink" title="使用用户线程实现"></a>使用用户线程实现</h4><p>从广义上来讲，一个线程只要不是内核线程，就可以认为是用户线程（User Thread,UT），因此，从这个定义上来讲，轻量级进程也属于用户线程，但轻量级进程的实现始终是建立在内核之上的，许多操作都要进行系统调用，效率会受到限制。</p>
<p>而狭义上的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1：N的关系称为一对多的线程模型，如图所示。 <br><img src="https://i.loli.net/2021/04/23/hDzKk7IuToJEncY.png" alt="6"><br>使用用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理。线程的创建、切换和调度都是需要考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”、“多处理器系统中如何将线程映射到其他处理器上”这类问题解决起来将会异常困难，甚至不可能完成。因而使用用户线程实现的程序一般都比较复杂，除了以前在不支持多线程的操作系统中（如DOS）的多线程程序与少数有特殊需求的程序外，现在使用用户线程的程序越来越少了，Java、Ruby等语言都曾经使用过用户线程，最终又都放弃使用它。</p>
<h4 id="使用用户线程加轻量级进程混合实现"><a href="#使用用户线程加轻量级进程混合实现" class="headerlink" title="使用用户线程加轻量级进程混合实现"></a>使用用户线程加轻量级进程混合实现</h4><p>线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用户线程一起使用的实现方式。在这种混合实现下，既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级线程来完成，大大降低了整个进程被完全阻塞的风险。在这种混合模式中，用户线程与轻量级进程的数量比是不定的，即为N：M的关系，如图所示，这种就是多对多的线程模型。</p>
<p>许多UNIX系列的操作系统，如Solaris、HP-UX等都提供了N：M的线程模型实现。 <br><img src="https://i.loli.net/2021/04/23/hkoC2sFYd9VSgP7.png" alt="7"></p>
<h3 id="Java线程的实现"><a href="#Java线程的实现" class="headerlink" title="Java线程的实现"></a>Java线程的实现</h3><p>Java线程在JDK 1.2之前，是基于称为“绿色线程”（Green Threads）的用户线程实现的，而在JDK 1.2中，线程模型替换为基于操作系统原生线程模型来实现。因此，在目前的JDK版本中，操作系统支持怎样的线程模型，在很大程度上决定了Java虚拟机的线程是怎样映射的，这点在不同的平台上没有办法达成一致，虚拟机规范中也并未限定Java线程需要使用哪种线程模型来实现。线程模型只对线程的并发规模和操作成本产生影响，对Java程序的编码和运行过程来说，这些差异都是透明的。 </p>
<p>对于Sun JDK来说，它的Windows版与Linux版都是使用一对一的线程模型实现的，一条Java线程就映射到一条轻量级进程之中，因为Windows和Linux系统提供的线程模型就是一对一的。</p>
<p>而在Solaris平台中，由于操作系统的线程特性可以同时支持一对一（通过Bound  Threads或Alternate Libthread实现）及多对多（通过LWP/Thread Based Synchronization实现）的线程模型，因此在Solaris版的JDK中也对应提供了两个平台专有的虚拟机参数：-XX：+UseLWPSynchronization（默认值）和-XX：+UseBoundThreads来明确指定虚拟机使用哪种线程模型。</p>
<h2 id="Java线程调度"><a href="#Java线程调度" class="headerlink" title="Java线程调度"></a>Java线程调度</h2><p>线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，分别是协同式线程调度（Cooperative Threads-Scheduling）和抢占式线程调度（Preemptive Threads-Scheduling）。</p>
<p>如果使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上。协同式多线程的最大好处是实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以没有什么线程同步的问题。Lua语言中的“协同例程”就是这类实现。它的坏处也很明显：线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。很久以前的Windows 3.x系统就是使用协同式来实现多进程多任务的，相当不稳定，一个进程坚持不让出CPU执行时间就可能会导致整个系统崩溃。</p>
<p>如果使用抢占式调度的多线程系统，那么每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定（在Java中，Thread.yield()可以让出执行时间，但是要获取执行时间的话，线程本身是没有什么办法的）。在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度。与前面所说的Windows 3.x的例子相对，在Windows 9x/NT内核中就是使用抢占式来实现多进程的，当一个进程出了问题，我们还可以使用任务管理器把这个进程“杀掉”，而不至于导致系统崩溃。</p>
<p>虽然Java线程调度是系统自动完成的，但是我们还是可以“建议”系统给某些线程多分配一点执行时间，另外的一些线程则可以少分配一点——这项操作可以通过设置线程优先级来完成。Java语言一共设置了10个级别的线程优先级（Thread.MIN_PRIORITY至Thread.MAX_PRIORITY），在两个线程同时处于Ready状态时，优先级越高的线程越容易被系统选择执行。</p>
<p>不过，线程优先级并不是太靠谱，原因是Java的线程是通过映射到系统的原生线程上来实现的，所以线程调度最终还是取决于操作系统。</p>
<h2 id="状态转换"><a href="#状态转换" class="headerlink" title="状态转换"></a>状态转换</h2><p>Java语言定义了5种线程状态，在任意一个时间点，一个线程只能有且只有其中的一种状态，这5种状态分别如下。</p>
<p><strong>新建（New）：</strong>创建后尚未启动的线程处于这种状态。</p>
<p><strong>运行（Runable）：</strong>Runable包括了操作系统线程状态中的Running和Ready，也就是处于此状态的线程有可能正在执行，也有可能正在等待着CPU为它分配执行时间。</p>
<p><strong>无限期等待（Waiting）：</strong>处于这种状态的线程不会被分配CPU执行时间，它们要等待被其他线程显式地唤醒。以下方法会让线程陷入无限期的等待状态：</p>
<blockquote>
<p>没有设置Timeout参数的Object.wait（）方法。<br> 没有设置Timeout参数的Thread.join（）方法。<br> LockSupport.park（）方法。</p>
</blockquote>
<p><strong>限期等待（Timed Waiting）：</strong>处于这种状态的线程也不会被分配CPU执行时间，不过无须等待被其他线程显式地唤醒，在一定时间之后它们会由系统自动唤醒。以下方法会让线程进入限期等待状态：</p>
<blockquote>
<p>Thread.sleep（）方法。<br>设置了Timeout参数的Object.wait（）方法。<br>设置了Timeout参数的Thread.join（）方法。<br>LockSupport.parkNanos（）方法。<br>LockSupport.parkUntil（）方法。</p>
</blockquote>
<p><strong>阻塞（Blocked）：</strong>线程被阻塞了，“阻塞状态”与“等待状态”的区别是：“阻塞状态”在等待着获取到一个排他锁，这个事件将在另外一个线程放弃这个锁的时候发生;而“等待状态”则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将进入这种状态。</p>
<p><strong>结束（Terminated）：</strong>已终止线程的线程状态，线程已经结束执行。</p>
<p>上述5种状态在遇到特定事件发生的时候将会互相转换，它们的转换关系如图示。<br><img src="https://i.loli.net/2021/04/23/zkUjNLwB5IDalE6.png" alt="8"></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发：线程安全与锁优化</title>
    <url>/2021/04/21/Java%E5%B9%B6%E5%8F%91%EF%BC%9A%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E9%94%81%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>人们很难想象现实中的对象在一项工作进行期间，会被不停地中断和切换，对象的属性（数据）可能会在中断期间被修改和变“脏”，而这些事情在计算机世界中则是很正常的事情。有时候，良好的设计原则不得不向现实做出一些让步，我们必须让程序在计算机中正确无误地运行，然后再考虑如何将代码组织得更好，让程序运行更快。对于“高效并发”来说，首先需要保证并发的正确性，然后在此基础上实现高效。</p>
<span id="more"></span>

<h2 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h2><p>《Java Concurrency In Practice》的作者Brian Goetz对“线程安全”有一个比较恰当的定义：“当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的”。</p>
<p>这个定义比较严谨，它要求线程安全的代码都必须具备一个特征：代码本身封装了所有必要的正确性保障手段（如互斥同步等），令调用者无须关心多线程的问题，更无须自己采取任何措施来保证多线程的正确调用。这点听起来简单，但其实并不容易做到，在大多数场景中，我们都会将这个定义弱化一些，如果把“调用这个对象的行为”限定为“单次调用”，这个定义的其他描述也能够成立的话，我们就可以称它是线程安全了。</p>
<h3 id="Java语言中的线程安全"><a href="#Java语言中的线程安全" class="headerlink" title="Java语言中的线程安全"></a>Java语言中的线程安全</h3><p>按照线程安全的“安全程度”由强至弱来排序，我们可以将Java语言中各种操作共享的数据分为以下5类：不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。</p>
<h4 id="不可变"><a href="#不可变" class="headerlink" title="不可变"></a>不可变</h4><p>在Java语言中（特指JDK 1.5以后，即Java内存模型被修正之后的Java语言），不可变（Immutable）的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要再采取任何的线程安全保障措施，我们谈到final关键字带来的可见性时曾经提到过这一点，只要一个不可变的对象被正确地构建出来（没有发生this引用逃逸的情况），那其外部的可见状态永远也不会改变，永远也不会看到它在多个线程之中处于不一致的状态。“不可变”带来的安全性是最简单和最纯粹的。</p>
<p>Java语言中，如果共享数据是一个基本数据类型，那么只要在定义时使用final关键字修饰它就可以保证它是不可变的。如果共享数据是一个对象，那就需要保证对象的行为不会对其状态产生任何影响才行，不妨想一想java.lang.String类的对象，它是一个典型的不可变对象，我们调用它的substring()、replace()和concat()这些方法都不会影响它原来的值，只会返回一个新构造的字符串对象。</p>
<p>保证对象行为不影响自己状态的途径有很多种，其中最简单的就是把对象中带有状态的变量都声明为final，这样在构造函数结束之后，它就是不可变的。</p>
<p>在Java API中符合不可变要求的类型，除了上面提到的String之外，常用的还有枚举类型，以及java.lang.Number的部分子类，如Long和Double等数值包装类型，BigInteger和BigDecimal等大数据类型。</p>
<h4 id="绝对线程安全"><a href="#绝对线程安全" class="headerlink" title="绝对线程安全"></a>绝对线程安全</h4><p>绝对的线程安全完全满足Brian Goetz给出的线程安全的定义，这个定义其实是很严格的，一个类要达到“不管运行时环境如何，调用者都不需要任何额外的同步措施”通常需要付出很大的，甚至有时候是不切实际的代价。在Java API中标注自己是线程安全的类，大多数都不是绝对的线程安全。我们可以通过Java API中一个不是“绝对线程安全”的线程安全类来看看这里的“绝对”是什么意思。</p>
<p>如果说java.util.Vector是一个线程安全的容器，相信所有的Java程序员对此都不会有异议，因为它的add()、get()和size()这类方法都是被synchronized修饰的，尽管这样效率很低，但确实是安全的。但是，即使它所有的方法都被修饰成同步，也不意味着调用它的时候永远都不再需要同步手段了，请看下面的测试代码。<br><img src="https://i.loli.net/2021/04/21/WDxGVIn7y3e85gY.png" alt="1"></p>
<p>很明显，尽管这里使用到的Vector的get()、remove()和size()方法都是同步的，但是在多线程的环境中，如果不在方法调用端做额外的同步措施的话，使用这段代码仍然是不安全的，因为如果另一个线程恰好在错误的时间里删除了一个元素，导致序号i已经不再可用的话，再用i访问数组就会抛出一个ArrayIndexOutOfBoundsException。</p>
<h4 id="相对线程安全"><a href="#相对线程安全" class="headerlink" title="相对线程安全"></a>相对线程安全</h4><p>相对的线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单独的操作是线程安全的，我们在调用的时候不需要做额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。上面Vector的测试代码就是相对线程安全的明显的案例。</p>
<p>在Java语言中，大部分的线程安全类都属于这种类型，例如Vector、HashTable、Collections的synchronizedCollection()方法包装的集合等。</p>
<h4 id="线程兼容"><a href="#线程兼容" class="headerlink" title="线程兼容"></a>线程兼容</h4><p>线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用，我们平常说一个类不是线程安全的，绝大多数时候指的是这一种情况。Java API中大部分的类都是属于线程兼容的，如与前面的Vector和HashTable相对应的集合类ArrayList和HashMap等。</p>
<h4 id="线程对立"><a href="#线程对立" class="headerlink" title="线程对立"></a>线程对立</h4><p>线程对立是指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码。由于Java语言天生就具备多线程特性，线程对立这种排斥多线程的代码是很少出现的，而且通常都是有害的，应当尽量避免。</p>
<p>一个线程对立的例子是Thread类的suspend()和resume()方法，如果有两个线程同时持有一个线程对象，一个尝试去中断线程，另一个尝试去恢复线程，如果并发进行的话，无论调用时是否进行了同步，目标线程都是存在死锁风险的，如果suspend()中断的线程就是即将要执行resume()的那个线程，那就肯定要产生死锁了。也正是由于这个原因，suspend()和resume()方法已经被JDK声明废弃（@Deprecated）了。常见的线程对立的操作还有System.setIn()、Sytem.setOut()和System.runFinalizersOnExit()等。</p>
<h3 id="线程安全的实现方法"><a href="#线程安全的实现方法" class="headerlink" title="线程安全的实现方法"></a>线程安全的实现方法</h3><h4 id="互斥同步"><a href="#互斥同步" class="headerlink" title="互斥同步"></a>互斥同步</h4><p>互斥同步（Mutual Exclusion＆Synchronization）是常见的一种并发正确性保障手段。同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个（或者是一些，使用信号量的时候）线程使用。而互斥是实现同步的一种手段，临界区（Critical Section）、互斥量（Mutex）和信号量（Semaphore）都是主要的互斥实现方式。因此，在这4个字里面，互斥是因，同步是果;互斥是方法，同步是目的。</p>
<p>在Java中，最基本的互斥同步手段就是synchronized关键字，synchronized关键字经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java程序中的synchronized明确指定了对象参数，那就是这个对象的reference;如果没有明确指定，那就根据synchronized修饰的是实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。</p>
<p>根据虚拟机规范的要求，在执行monitorenter指令时，首先要尝试获取对象的锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1，相应的，在执行monitorexit指令时会将锁计数器减1，当计数器为0时，锁就被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。</p>
<p>在虚拟机规范对monitorenter和monitorexit的行为描述中，有两点是需要特别注意的。首先，synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。其次，同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入。Java的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来帮忙完成，这就需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间。对于代码简单的同步块（如被synchronized修饰的getter()或setter()方法），状态转换消耗的时间有可能比用户代码执行的时间还要长。所以synchronized是Java语言中一个重量级（Heavyweight）的操作，有经验的程序员都会在确实必要的情况下才使用这种操作。而虚拟机本身也会进行一些优化，譬如在通知操作系统阻塞线程之前加入一段自旋等待过程，避免频繁地切入到核心态之中。</p>
<p>除了synchronized之外，我们还可以使用java.util.concurrent（下文称J.U.C）包中的重入锁（ReentrantLock）来实现同步，在基本用法上，ReentrantLock与synchronized很相似，他们都具备一样的线程重入特性，只是代码写法上有点区别，一个表现为API层面的互斥锁（lock()和unlock()方法配合try/finally语句块来完成），另一个表现为原生语法层面的互斥锁。不过，相比synchronized,ReentrantLock增加了一些高级功能，主要有以下3项：等待可中断、可实现公平锁，以及锁可以绑定多个条件。</p>
<p>等待可中断是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。</p>
<p>公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁;而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。</p>
<p>锁绑定多个条件是指一个ReentrantLock对象可以同时绑定多个Condition对象，而在synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock则无须这样做，只需要多次调用newCondition()方法即可。</p>
<h4 id="非阻塞同步"><a href="#非阻塞同步" class="headerlink" title="非阻塞同步"></a>非阻塞同步</h4><p>互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步（Blocking Synchronization）。从处理问题的方式上说，互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施（例如加锁），那就肯定会出现问题，无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。随着硬件指令集的发展，我们有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说，就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了;如果共享数据有争用，产生了冲突，那就再采取其他的补偿措施（最常见的补偿措施就是不断地重试，直到成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为非阻塞同步（Non-Blocking Synchronization）。</p>
<p>为什么说使用乐观并发策略需要“硬件指令集的发展”才能进行呢？因为我们需要操作和冲突检测这两个步骤具备原子性，靠什么来保证呢？如果这里再使用互斥同步来保证就失去意义了，所以我们只能靠硬件来完成这件事情，硬件保证一个从语义上看起来需要多次操作的行为只通过一条处理器指令就能完成，这类指令常用的有：</p>
<blockquote>
<p>测试并设置（Test-and-Set）。<br> 获取并增加（Fetch-and-Increment）。<br> 交换（Swap）。<br> 比较并交换（Compare-and-Swap，下文称CAS）。<br> 加载链接/条件存储（Load-Linked/Store-Conditional，下文称LL/SC）。</p>
</blockquote>
<p>其中，前面的3条是20世纪就已经存在于大多数指令集之中的处理器指令，后面的两条是现代处理器新增的，而且这两条指令的目的和功能是类似的。在IA64、x86指令集中有cmpxchg指令完成CAS功能，在sparc-TSO也有casa指令实现，而在ARM和PowerPC架构下，则需要使用一对ldrex/strex指令来完成LL/SC的功能。</p>
<p>CAS指令需要有3个操作数，分别是内存位置（在Java中可以简单理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和新值（用B表示）。CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作。</p>
<p>在JDK 1.5之后，Java程序中才可以使用CAS操作，该操作由sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供，虚拟机在内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，或者可以认为是无条件内联进去了。</p>
<p>由于Unsafe类不是提供给用户程序调用的类（Unsafe.getUnsafe()的代码中限制了只有启动类加载器（Bootstrap ClassLoader）加载的Class才能访问它），因此，如果不采用反射手段，我们只能通过其他的Java API来间接使用它，如J.U.C包里面的整数原子类，其中的compareAndSet()和getAndIncrement()等方法都使用了Unsafe类的CAS操作。</p>
<p>在JVM学习笔记（四）：Java内存模型（JMM）与线程中我们曾经通过这段20个线程自增10000次的代码来证明volatile变量不具备原子性，那么如何才能让它具备原子性呢？把“race++”操作或increase()方法用同步块包裹起来当然是一个办法，但是如果改成下代码，那效率将会提高许多。<br><img src="https://i.loli.net/2021/04/21/qvxzE7ZDWymjCnY.png" alt="2"></p>
<p>使用AtomicInteger代替int后，程序输出了正确的结果，一切都要归功于incrementAndGet()方法的原子性。它的实现其实非常简单，如下所示（JDK1.8之后此功能被被写到了Unsafe类里，AtomicInteger类只剩一行unsafe.getAndAddInt(this, valueOffset, 1) + 1;，但是实现的逻辑是没变的）：<br><img src="https://i.loli.net/2021/04/21/fZwgpRG6FiUt3bv.png" alt="3"><br>incrementAndGet()方法在一个无限循环中，不断尝试将一个比当前值大1的新值赋给自己。如果失败了，那说明在执行“获取-设置”操作的时候值已经有了修改，于是再次循环进行下一次操作，直到设置成功为止。</p>
<p>尽管CAS看起来很美，但显然这种操作无法涵盖互斥同步的所有使用场景，并且CAS从语义上来说并不是完美的，存在这样的一个逻辑漏洞：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然为A值，那我们就能说它的值没有被其他线程改变过了吗？如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。这个漏洞称为CAS操作的“ABA”问题。J.U.C包为了解决这个问题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。不过目前来说这个类比较“鸡肋”，大部分情况下ABA问题不会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。</p>
<h4 id="无同步方案"><a href="#无同步方案" class="headerlink" title="无同步方案"></a>无同步方案</h4><p>要保证线程安全，并不是一定就要进行同步，两者没有因果关系。同步只是保证共享数据争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性，因此会有一些代码天生就是线程安全的，下面简单地介绍其中的两类。</p>
<p><strong>可重入代码（Reentrant Code）：</strong>这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。相对线程安全来说，可重入性是更基本的特性，它可以保证线程安全，即所有的可重入的代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。</p>
<p>可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。我们可以通过一个简单的原则来判断代码是否具备可重入性：如果一个方法，它的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。</p>
<p><strong>线程本地存储（Thread Local Storage）：</strong>如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。</p>
<p>符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完，其中最重要的一个应用实例就是经典Web交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程安全问题。</p>
<p>Java语言中，如果一个变量要被多线程访问，可以使用volatile关键字声明它为“易变的”;如果一个变量要被某个线程独享，Java中就没有类似C++中__declspec（thread）这样的关键字，不过还是可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。每一个线程的Thread对象中都有一个ThreadLocalMap对象，这个对象存储了一组以TreadLocal.threadLocalHashCode为键，以本地线程变量为值的K-V值对，ThreadLocal对象就是当前线程的ThreadLocalMap的访问入口，每一个ThreadLocal对象都包含了一个独一无二的threadLocalHashCode值，使用这个值就可以在线程K-V值对中找回对应的本地线程变量。</p>
<h2 id="优化锁"><a href="#优化锁" class="headerlink" title="优化锁"></a>优化锁</h2><h3 id="自旋锁与自适应自旋"><a href="#自旋锁与自适应自旋" class="headerlink" title="自旋锁与自适应自旋"></a>自旋锁与自适应自旋</h3><p>前面我们讨论互斥同步的时候，提到了互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力。同时，虚拟机的开发团队也注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。</p>
<p>自旋锁在JDK 1.4.2中就已经引入，只不过默认是关闭的，可以使用-XX：+UseSpinning参数来开启，在JDK 1.6中就已经改为默认开启了。自旋等待不能代替阻塞，且先不说对处理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时间很长，那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性能上的浪费。因此，自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋次数的默认值是10次，用户可以使用参数-XX：PreBlockSpin来更改。</p>
<p>在JDK 1.6中引入了自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个循环。另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越准确，虚拟机就会变得越来越“聪明”了。</p>
<h3 id="锁消除"><a href="#锁消除" class="headerlink" title="锁消除"></a>锁消除</h3><p>锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行。</p>
<h3 id="锁粗化"><a href="#锁粗化" class="headerlink" title="锁粗化"></a>锁粗化</h3><p>原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。</p>
<p>大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。</p>
<p>如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部，这样只需要加锁一次就可以了。</p>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>轻量级锁是JDK 1.6之中加入的新型锁机制，它名字中的“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的，因此传统的锁机制就称为“重量级”锁。首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。</p>
<p>要理解轻量级锁，以及后面会讲到的偏向锁的原理和运作过程，必须从HotSpot虚拟机的对象（对象头部分）的内存布局开始介绍。HotSpot虚拟机的对象头（Object Header）分为两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄（Generational GC Age）等，这部分数据的长度在32位和64位的虚拟机中分别为32bit和64bit，官方称它为“Mark Word”，它是实现轻量级锁和偏向锁的关键。另外一部分用于存储指向方法区对象类型数据的指针，如果是数组对象的话，还会有一个额外的部分用于存储数组长度。</p>
<p>对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如，在32位的HotSpot虚拟机中对象未被锁定的状态下，Mark Word的32bit空间中的25bit用于存储对象哈希码（HashCode），4bit用于存储对象分代年龄，2bit用于存储锁标志位，1bit固定为0，在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容见表13-1。<br><img src="https://i.loli.net/2021/04/21/c3agB17wJGoLUdY.png" alt="4"></p>
<p>简单地介绍了对象的内存布局后，我们把话题返回到轻量级锁的执行过程上。在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方把这份拷贝加了一个Displaced前缀，即Displaced Mark Word），这时候线程堆栈与对象头的状态如图所示。<br><img src="https://i.loli.net/2021/04/21/9bNFixmjzWARGdO.png" alt="5"></p>
<p>然后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位（Mark Word的最后2bit）将转变为“00”，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如图所示。<br><img src="https://i.loli.net/2021/04/21/lYFnsXu9xAe2aB1.png" alt="6"></p>
<p>如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果只说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。</p>
<p>上面描述的是轻量级锁的加锁过程，它的解锁过程也是通过CAS操作来进行的，如果对象的Mark Word仍然指向着线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来，如果替换成功，整个同步过程就完成了。如果替换失败，说明有其他线程尝试过获取该锁，那就要在释放锁的同时，唤醒被挂起的线程。</p>
<p>轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥量的开销，但如果存在锁竞争，除了互斥量的开销外，还额外发生了CAS操作，因此在有竞争的情况下，轻量级锁会比传统的重量级锁更慢。</p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>偏向锁也是JDK 1.6中引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不做了。</p>
<p>偏向锁的“偏”，就是偏心的“偏”、偏袒的“偏”，它的意思是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。</p>
<p>如果读者读懂了前面轻量级锁中关于对象头Mark Word与线程之间的操作过程，那偏向锁的原理理解起来就会很简单。假设当前虚拟机启用了偏向锁（启用参数-XX：+UseBiasedLocking，这是JDK 1.6的默认值），那么，当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为“01”，即偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中，如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作（例如Locking、Unlocking及对Mark Word的Update等）。</p>
<p>当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。根据锁对象目前是否处于被锁定的状态，撤销偏向（Revoke Bias）后恢复到未锁定（标志位为“01”）或轻量级锁定（标志位为“00”）的状态，后续的同步操作就如上面介绍的轻量级锁那样执行。偏向锁、轻量级锁的状态转化及对象Mark Word的关系如图所示。<br><img src="https://i.loli.net/2021/04/21/eUGNtswPpQBfiug.png" alt="7"></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>Java虚拟机：内存分配与回收策略</title>
    <url>/2021/04/20/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%9A%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Java技术体系中所提倡的自动内存管理最终可以归结为自动化地解决了两个问题：给对象分配内存以及回收分配给对象的内存。关于回收内存这一点，我们已经使用了大量篇幅去介绍虚拟机中的垃圾收集器体系以及运作原理，现在我们再一起来探讨一下给对象分配内存的那点事儿。</p>
<p>对象的内存分配，往大方向讲，就是在堆上分配（但也可能经过JIT编译后被拆散为标量类型并间接地栈上分配），对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，将按线程优先在TLAB上分配。少数情况下也可能会直接分配在老年代中，分配的规则并不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。</p>
<p>接下来我们将会讲解几条最普遍的内存分配规则，并通过代码去验证这些规则。由于条件因素，只能在Client模式下测试，因此CMS和G1并未提及。</p>
<span id="more"></span>

<h2 id="对象优先在Eden分配"><a href="#对象优先在Eden分配" class="headerlink" title="对象优先在Eden分配"></a>对象优先在Eden分配</h2><p>大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。</p>
<p>例子1：</p>
<p>Serial + Serial Old（UseSerialGC） 或者 ParNew + Serial Old（UseParNewGC）</p>
<p>GC环境：垃圾收集器为Serial + Serial Old（ParNew + Serial Old），年轻代大小为100M，Eden：Survivor = 8 ：1，所以Eden为80M，两个Survivor各10M，老年代为100M。</p>
<p>GC分析：当要分配allocation5时，Eden空间不足，进行Minor GC，此时年轻代空间从76595K降低到698K。这是由于allocation1、allocation2、allocation3、allocation4对象的大小皆超过Survivor空间大小（10M），因此allocation1、allocation2、allocation3、allocation4对象皆通过分配担保机制提前转移到老年代，年轻代剩余的698k为JVM的内部对象，进行Minor GC后进入了Survivor区。</p>
<p>例子2：</p>
<p>Parallel Scavenge + Parallel Old</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title>Java虚拟机：Java内存区域</title>
    <url>/2021/04/16/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%9AJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近一段时间组内进行知识分享，于是打算把分享的主题就定为JVM方面的，由于自己的水平有限加上为了保证内容的准确性，因此文章大部分内容取自《深入理解Java虚拟机》此书的原内容，少部分内容为从知乎R大和其他对JVM有深入理解的人学习而来。</p>
<span id="more"></span>

<h2 id="运行时数据区"><a href="#运行时数据区" class="headerlink" title="运行时数据区"></a>运行时数据区</h2><p>Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。根据《Java虚拟机规范（Java SE 7版）》的规定，Java虚拟机所管理的内存将会包括以下几个运行时数据区域，如图所示。<br><img src="https://i.loli.net/2021/04/16/4D6pdMzNGPEZ8bF.png" alt="1"></p>
<h3 id="程序计数器（Program-Counter-Register）"><a href="#程序计数器（Program-Counter-Register）" class="headerlink" title="程序计数器（Program Counter Register）"></a>程序计数器（Program Counter Register）</h3><p>一块较小的内存空间，可以看作当前线程所执行的字节码的行号指示器。如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址;如果正在执行的是Native方法，这个计数器值则为空。此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。</p>
<h3 id="Java虚拟机（Java-Virtual-Machine-Stacks）"><a href="#Java虚拟机（Java-Virtual-Machine-Stacks）" class="headerlink" title="Java虚拟机（Java Virtual Machine Stacks）"></a>Java虚拟机（Java Virtual Machine Stacks）</h3><p>与程序计算器一样，Java虚拟机栈也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。</p>
<p>局部变量表存放了编译期可知的各种基本数据类型、对象引用（reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置)和returnAddress类型（指向了一条字节码指令的地址）。</p>
<p>其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。</p>
<p>在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常;如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。</p>
<h3 id="本地方法栈（Native-Method-Stack）："><a href="#本地方法栈（Native-Method-Stack）：" class="headerlink" title="本地方法栈（Native Method Stack）："></a>本地方法栈（Native Method Stack）：</h3><p>本地方法栈与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。</p>
<h3 id="Java堆（Java-Heap）："><a href="#Java堆（Java-Heap）：" class="headerlink" title="Java堆（Java Heap）："></a>Java堆（Java Heap）：</h3><p>对大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。</p>
<p>Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。从内存回收的角度来看，由于现在收集器基本都采用分代收集算法，所以Java堆中还可以细分为：新生代和老年代;再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。从内存分配的角度来看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer,TLAB）。不过无论如何划分，都与存放内容无关，无论哪个区域，存储的都仍然是对象实例，进一步划分的目的是为了更好地回收内存，或者更快地分配内存。</p>
<p>根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。</p>
<h3 id="方法区（Method-Area）："><a href="#方法区（Method-Area）：" class="headerlink" title="方法区（Method Area）："></a>方法区（Method Area）：</h3><p>与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区是JVM规范中定义的一个概念，具体放在哪里，不同的实现可以放在不同的地方。</p>
<p>对于习惯在HotSpot虚拟机上开发、部署程序的开发者来说，很多人都更愿意把方法区称为“永久代”，本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已，这样HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存，能够省去专门为方法区编写内存管理代码的工作。对于其他虚拟机（如BEA JRockit、IBM J9等）来说是不存在永久代的概念的。原则上，如何实现方法区属于虚拟机实现细节，不受虚拟机规范约束，但使用永久代来实现方法区，现在看来并不是一个好主意，因为这样更容易遇到内存溢出问题（永久代有-XX：MaxPermSize的上限，J9和JRockit只要没有触碰到进程可用内存的上限，例如32位系统中的4GB，就不会出现问题），而且有极少数方法（例如String.intern()）会因这个原因导致不同虚拟机下有不同的表现。因此，HotSpot虚拟机在JDK1.8放弃永久代并改为采用Native Memory来实现方法区（详情见下文永久代的移除）。</p>
<p>根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。</p>
<h3 id="运行时常量池（Runtime-Constant-Pool）："><a href="#运行时常量池（Runtime-Constant-Pool）：" class="headerlink" title="运行时常量池（Runtime Constant Pool）："></a>运行时常量池（Runtime Constant Pool）：</h3><p>运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。</p>
<p>一般来说，除了保存Class文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。</p>
<p>既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。</p>
<h3 id="永久代的移除："><a href="#永久代的移除：" class="headerlink" title="永久代的移除："></a>永久代的移除：</h3><p>在Java 6中：方法区中包含的数据，除了JIT（Just In Time）编译生成的代码存放在native memory的CodeCache区域，其他都存放在永久代。</p>
<p>在Java 7中：符号引用（Symbolic References）转移到了native memory；字面量（Literal）转移到了java heap；类的静态变量（class statics）转移到了java heap。</p>
<p>在Java 8中：永久代被彻底移除，取而代之的是另一块与堆不相连的本地内存——元空间（Metaspace）,‑XX:MaxPermSize 参数失去了意义，取而代之的是-XX:MaxMetaspaceSize。</p>
<h3 id="移除永久代的主要原因："><a href="#移除永久代的主要原因：" class="headerlink" title="移除永久代的主要原因："></a>移除永久代的主要原因：</h3><p>为了HotSpot与JRockit的融合。HotSpot所属于Sun公司，JRockit所属于BEA公司，两者分别与2008和2009年被Oracle收购，Oracle选择将两个优秀的虚拟机融合到一起，主要应该是以HotSpot为主，这个融合在JDK1.8完成。<br>永久代大小不容易确定，PermSize指定太小容易造成永久代OOM。</p>
<h3 id="Metaspace（元空间）："><a href="#Metaspace（元空间）：" class="headerlink" title="Metaspace（元空间）："></a>Metaspace（元空间）：</h3><p>元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存（native memory）。<br>元空间主要用来储存类的元数据，元数据包括类、字段、方法定义及其他信息。类和它的元数据的生命周期是和它的类加载器的生命周期一致的。也就是说，只要类的类加载器是存活的，在Metaspace中的类元数据也是存活的，不能被释放。</p>
<h2 id="HotSpot虚拟机对象探秘"><a href="#HotSpot虚拟机对象探秘" class="headerlink" title="HotSpot虚拟机对象探秘"></a>HotSpot虚拟机对象探秘</h2><h3 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h3><p>Java是一门面向对象的编程语言，在Java程序运行过程中无时无刻都有对象被创建出来。在语言层面上，创建对象（例如克隆、反序列化）通常仅仅是一个new关键字而已，而在虚拟机中，对象（文中讨论的对象限于普通Java对象，不包括数组和Class对象等）的创建又是怎样一个过程呢？</p>
<p>虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。</p>
<p>在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump the Pointer）。如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”（Free List）。选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。因此，在使用Serial、ParNew等带Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器时，通常采用空闲列表。</p>
<p>除如何划分可用空间之外，还有另外一个需要考虑的问题是对象创建在虚拟机中是非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。解决这个问题有两种方案，一种是对分配内存空间的动作进行同步处理——实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性;另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）。哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完并分配新的TLAB时，才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX：+/-UseTLAB参数来设定。</p>
<p>内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。</p>
<p>接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头（Object Header）之中。根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。关于对象头的具体内容，稍后再做详细介绍。</p>
<p>在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚刚开始——<init>方法还没有执行，所有的字段都还为零。所以，一般来说（由字节码中是否跟随invokespecial指令所决定），执行new指令之后会接着执行<init>方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。</p>
<h3 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h3><p>在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。</p>
<h4 id="对象头（Header）"><a href="#对象头（Header）" class="headerlink" title="对象头（Header）"></a>对象头（Header）</h4><p>HotSpot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，官方称它为“Mark Word”。对象需要存储的运行时数据很多，其实已经超出了32位、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下表所示（无锁状态）。<br><img src="https://i.loli.net/2021/04/17/TLe54rMtSDJuvlz.png" alt="2"></p>
<p>在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据，如下表所示。<br><img src="https://i.loli.net/2021/04/17/3K2UsEaqNhzTcOe.png" alt="3"></p>
<p>在64位虚拟机下，Mark Word是64bit大小的，其存储结构如下表所示。<br><img src="https://i.loli.net/2021/04/17/yUvdHRPrX8mw3pg.png" alt="4"></p>
<p>对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身。另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中却无法确定数组的大小。</p>
<h4 id="实例数据（Instance-Data）"><a href="#实例数据（Instance-Data）" class="headerlink" title="实例数据（Instance Data）"></a>实例数据（Instance Data）</h4><p>接下来的实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。这部分的存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在Java源码中定义顺序的影响。HotSpot虚拟机默认的分配策略为longs/doubles、ints、shorts/chars、bytes/booleans、oops（Ordinary Object Pointers），从分配策略中可以看出，相同宽度的字段总是被分配到一起。在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前。如果CompactFields参数值为true（默认为true），那么子类之中较窄的变量也可能会插入到父类变量的空隙之中。</p>
<h4 id="对齐填充（Padding）"><a href="#对齐填充（Padding）" class="headerlink" title="对齐填充（Padding）"></a>对齐填充（Padding）</h4><p>第三部分对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或者2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。</p>
<h3 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h3><p>建立对象是为了使用对象，我们的Java程序需要通过栈上的reference数据来操作堆上的具体对象。由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，所以对象访问方式也是取决于虚拟机实现而定的。目前主流的访问方式有使用句柄和直接指针两种。</p>
<p>如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息.<br><img src="https://i.loli.net/2021/04/17/gxTUV7zkfNJ6nOH.png" alt="5"></p>
<p>如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象地址<br><img src="https://i.loli.net/2021/04/17/6XeQjMEfs8xOy2N.png" alt="6"></p>
<p>这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。</p>
<p>使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。就本书讨论的主要虚拟机Sun HotSpot而言，它是使用第二种方式进行对象访问的，但从整个软件开发的范围来看，各种语言和框架使用句柄来访问的情况也十分常见。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring IoC 核心流程介绍</title>
    <url>/2021/04/23/Spring-IoC-%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文将用最通俗易懂的文字介绍 Spring IoC 中的核心流程，主要用于帮助初学者快速了解 IoC 的核心流程，也可以用作之前源码分析文章的总结。本着简单的初衷，本文会省略掉大量流程，只介绍最重要的步骤。</p>
<span id="more"></span>

<h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><h3 id="IoC-和-DI"><a href="#IoC-和-DI" class="headerlink" title="IoC 和 DI"></a>IoC 和 DI</h3><p>IoC （Inversion of Control），即控制反转。这不是一种新的技术，而是 Spring 的一种设计思想。</p>
<p>在传统的程序设计，我们直接在对象内部通过 new 来创建对象，是程序主动去创建依赖对象；而在 Spring 中有专门的一个容器来创建和管理这些对象，并将对象依赖的其他对象注入到该对象中，这个容器我们一般称为 IoC 容器。</p>
<p>所有的类的创建、销毁都由 Spring 来控制，也就是说控制对象生存周期的不再是引用它的对象，而是 Spring。对于某个具体的对象而言，以前是它控制其他对象，现在是所有对象都被 Spring 控制，所以这叫控制反转。</p>
<p>DI（Dependency Injection），即依赖注入，由 Martin Fowler 提出。可以认为 IoC 和 DI 其实是同一个概念的不同角度描述。</p>
<p>依赖注入是指组件之间的依赖关系由容器在运行期决定，形象的说，即由容器动态的将某个依赖关系注入到组件之中。依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。</p>
<p>通过依赖注入机制，我们只需要通过简单的配置，而无需任何代码就可指定目标需要的资源，完成自身的业务逻辑，而不需要关心具体的资源来自何处，由谁实现。</p>
<h3 id="bean"><a href="#bean" class="headerlink" title="bean"></a>bean</h3><p>官方概念：在 Spring 中，构成应用程序主干并由 Spring IoC 容器管理的对象称为 bean。 bean 是一个由 Spring IoC 容器实例化，组装和管理的对象。</p>
<p>大白话：bean 可以认为是那些我们想注入到 Spring IoC 容器的 Java 对象实例的抽象。</p>
<p>我们经常会在 Service 上使用 @Service 注解，然后在要使用该 Service 的类中通过 @Autowire 注解来注入，这个 Service 就是一个 bean。在这个地方，@Service 注解相当于告诉 IoC 容器：这个类你需要帮我创建和管理；而 @Autowire 注解相当于告诉 IoC 容器：我需要依赖这个类，你需要帮我注入进来。</p>
<h3 id="BeanDefinition"><a href="#BeanDefinition" class="headerlink" title="BeanDefinition"></a>BeanDefinition</h3><p>理解了 bean，BeanDefinition 就好理解了。BeanDefinition 是 bean 的定义，用来存储 bean 的所有属性方法定义。</p>
<h3 id="BeanFactory-和-ApplicationContext"><a href="#BeanFactory-和-ApplicationContext" class="headerlink" title="BeanFactory 和 ApplicationContext"></a>BeanFactory 和 ApplicationContext</h3><p>BeanFactory：基础类型 IoC 容器，提供完整的 IoC 服务支持。</p>
<p>ApplicationContext：BeanFactory 的子接口，在 BeanFactory 的基础上构建，是相对比较高级的 IoC 容器实现。包含 BeanFactory 的所有功能，还提供了其他高级的特性，比如：事件发布、国际化信息支持、统一资源加载策略等。正常情况下，我们都是使用的 ApplicationContext。</p>
<p>以电话来举例：</p>
<p>我们家里使用的 “座机” 就类似于 BeanFactory，可以进行电话通讯，满足了最基本的需求。</p>
<p>而现在非常普及的智能手机，iPhone、小米等，就类似于 ApplicationContext，除了能进行电话通讯，还有其他很多功能：拍照、地图导航、听歌等。</p>
<h3 id="FactoryBean"><a href="#FactoryBean" class="headerlink" title="FactoryBean"></a>FactoryBean</h3><p>一般情况下，我们将 bean 的创建和管理都交给 Spring IoC 容器，Spring 会利用 bean 的 class 属性指定的类来实例化 bean。</p>
<p>但是如果我们想自己实现 bean 的创建操作，可以实现吗？答案是可以的，FactoryBean 就可以实现这个需求。</p>
<p>FactoryBean 是一种特殊的 bean，它是个工厂 bean，可以自己创建 bean 实例，如果一个类实现了 FactoryBean 接口，则该类可以自己定义创建实例对象的方法，只需要实现它的 getObject() 方法即可。</p>
<p>FactoryBean 可能对于普通开发来说基本用不到也没去注意过，但是它其实应用的非常广，特别是在中间件中，如果你看过一些中间件的源码，一定会看到 FactoryBean 的身影。</p>
<p>介绍了几个基础的类后，接下来将介绍 Spring IoC 的核心流程。</p>
<h2 id="核心流程"><a href="#核心流程" class="headerlink" title="核心流程"></a>核心流程</h2><h3 id="容器构建入口"><a href="#容器构建入口" class="headerlink" title="容器构建入口"></a>容器构建入口</h3><p>容器构建启动的入口有多种多样，这边以常用的 web.xml 配置的方式来说。</p>
<p>首先，我们会在 web.xml 中配置 ContextLoaderListener 监听器，当 Tomcat 启动时，会触发 ContextLoaderListener 的 contextInitialized 方法，从而开始 IoC 的构建流程。</p>
<p>另一个常用的参数是 contextConfigLocation，用于指定 Spring 配置文件的路径。</p>
<h3 id="ApplicationContext-刷新前配置"><a href="#ApplicationContext-刷新前配置" class="headerlink" title="ApplicationContext 刷新前配置"></a>ApplicationContext 刷新前配置</h3><p>在正式进入容器的刷新前，会进行一些前置操作。</p>
<p>1、确认要使用的容器，通常使用的是：XmlWebApplicationContext，如果是用 Spring Boot，一般是 AnnotationConfigApplicationContext，但其实都差别不大，最终都会继承 AbstractApplicationContext，核心逻辑也都是在 AbstractApplicationContext 中实现。</p>
<p>2、提供一个给开发者初始化 ApplicationContext 的机会，具体的使用如下。</p>
<p>例子：ApplicationContextInitializer 扩展使用<br>1）创建一个 ApplicationContextInitializer 接口的实现类，例如下面的 SpringApplicationContextInitializer，并在 initialize 方法中进行自己的逻辑操作，例如：添加监听器、添加 BeanFactoryPostProcessor。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.joonwhee.open.spring;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> com.joonwhee.open.listener.EarlyListener;</span><br><span class="line"><span class="keyword">import</span> com.joonwhee.open.processor.MyBeanFactoryPostProcessor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationContextInitializer;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ConfigurableApplicationContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SpringApplicationContextInitializer</span> <span class="keyword">implements</span></span><br><span class="line">        <span class="title class_">ApplicationContextInitializer</span>&lt;ConfigurableApplicationContext&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initialize</span><span class="params">(ConfigurableApplicationContext applicationContext)</span> &#123;</span><br><span class="line">        <span class="comment">// 自己的逻辑实现</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 例子1：通过硬编码的方式添加监听器</span></span><br><span class="line">        <span class="type">EarlyListener</span> <span class="variable">earlyListener</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">EarlyListener</span>();</span><br><span class="line">        applicationContext.addApplicationListener(earlyListener);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 例子2：通过硬编码的方式添加BeanFactoryPostProcessor</span></span><br><span class="line">        <span class="type">MyBeanFactoryPostProcessor</span> <span class="variable">myBeanFactoryPostProcessor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyBeanFactoryPostProcessor</span>();</span><br><span class="line">        applicationContext.addBeanFactoryPostProcessor(myBeanFactoryPostProcessor);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2）在web.xml中，定义 contextInitializerClasses 或 globalInitializerClasses 参数，参数值为 SpringApplicationContextInitializer 的全路径。<br><img src="https://i.loli.net/2021/04/23/kA7MUcJ3optqyGZ.png" alt="1"></p>
<h3 id="初始化-BeanFactory、加载-Bean-定义"><a href="#初始化-BeanFactory、加载-Bean-定义" class="headerlink" title="初始化 BeanFactory、加载 Bean 定义"></a>初始化 BeanFactory、加载 Bean 定义</h3><p>1、创建一个新的 BeanFactory，默认为 DefaultListableBeanFactory。</p>
<p>2、根据 web.xml 中 contextConfigLocation 配置的路径，读取 Spring 配置文件，并封装成 Resource。</p>
<p>3、根据 Resource 加载 XML 配置文件，并解析成 Document 对象 。</p>
<p>4、从根节点开始，遍历解析 Document 中的节点。</p>
<p>4.1、对于默认命名空间的节点：先将 bean 节点内容解析封装成 BeanDefinition，然后将 beanName、BeanDefinition 放到 BeanFactory 的缓存中，用于后续创建 bean 实例时使用。</p>
<p>默认命名空间：<a href="http://www.springframework.org/schema/beans%EF%BC%8C%E5%8F%AF%E8%83%BD%E5%AD%98%E5%9C%A8%E7%9A%84%E8%8A%82%E7%82%B9%E5%A6%82%E4%B8%8B%EF%BC%9A">http://www.springframework.org/schema/beans，可能存在的节点如下：</a><br><img src="https://i.loli.net/2021/04/23/87R5qZS3VawiUY1.png" alt="2"></p>
<p>4.2、对于自定义命名空间的节点：会拿到自定义命名空间对应的解析器，对节点进行解析处理。</p>
<p>例如：&lt;context:component-scan base-package=”com.joonwhee” /&gt; ，该节点对应的解析器会扫描 base-package 指定路径下的所有类，将使用了 @Component（@Controller、@Service、@Repository）注解的类封装成 BeanDefinition，然后将 beanName、BeanDefinition 放到 BeanFactory 的缓存中，用于后续创建 Bean 实例时使用。</p>
<h3 id="触发-BeanFactoryPostProcessor"><a href="#触发-BeanFactoryPostProcessor" class="headerlink" title="触发 BeanFactoryPostProcessor"></a>触发 BeanFactoryPostProcessor</h3><p>实例化和调用所有 BeanFactoryPostProcessor，包括其子类 BeanDefinitionRegistryPostProcessor。</p>
<p>BeanFactoryPostProcessor 接口是 Spring 初始化 BeanFactory 时对外暴露的扩展点，Spring IoC 容器允许 BeanFactoryPostProcessor 在容器实例化任何 bean 之前读取 bean 的定义，并可以修改它。</p>
<p>BeanDefinitionRegistryPostProcessor 继承自 BeanFactoryPostProcessor，比 BeanFactoryPostProcessor 具有更高的优先级，主要用来在常规的 BeanFactoryPostProcessor 激活之前注册一些 bean 定义。特别是，你可以通过 BeanDefinitionRegistryPostProcessor 来注册一些常规的 BeanFactoryPostProcessor，因为此时所有常规的 BeanFactoryPostProcessor 都还没开始被处理。 </p>
<p>注：这边的 “常规 BeanFactoryPostProcessor” 主要用来跟 BeanDefinitionRegistryPostProcessor 区分。</p>
<p>例子：BeanFactoryPostProcessor 扩展使用</p>
<p>1）创建一个 BeanFactoryPostProcessor 接口的实现类，例如下面的 MyBeanFactoryPostProcessor，并在 postProcessBeanFactory 方法中进行自己的逻辑操作。例如：扫描某个包路径，将该包路径下使用了某个注解的类全部注册到 Spring 中。</p>
<p>2）将该实现类注册到 Spring 容器中，例如使用 @Component 注解</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.joonwhee.open.demo.spring;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.BeansException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.config.BeanFactoryPostProcessor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.config.ConfigurableListableBeanFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyBeanFactoryPostProcessor</span> <span class="keyword">implements</span> <span class="title class_">BeanFactoryPostProcessor</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">postProcessBeanFactory</span><span class="params">(ConfigurableListableBeanFactory beanFactory)</span> <span class="keyword">throws</span> BeansException &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;MyBeanFactoryPostProcessor#postProcessBeanFactory&quot;</span>);</span><br><span class="line">        <span class="comment">// 自己的逻辑处理</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另外，Mybatis 中的 MapperScannerConfigurer 是一个典型的 BeanDefinitionRegistryPostProcessor 的扩展使用，有兴趣的可以看看这个类的源码。</p>
<h3 id="注册-BeanPostProcessor"><a href="#注册-BeanPostProcessor" class="headerlink" title="注册 BeanPostProcessor"></a>注册 BeanPostProcessor</h3><p>注册所有的 BeanPostProcessor，将所有实现了 BeanPostProcessor 接口的类加载到 BeanFactory 中。</p>
<p>BeanPostProcessor 接口是 Spring 初始化 bean 时对外暴露的扩展点，Spring IoC 容器允许 BeanPostProcessor 在容器初始化 bean 的前后，添加自己的逻辑处理。在这边只是注册到 BeanFactory 中，具体调用是在 bean 初始化的时候。</p>
<p>例子：BeanPostProcessor 扩展使用</p>
<p>1）创建一个 BeanPostProcessor 接口的实现类，例如下面的 MyBeanPostProcessor，并在方法中进行自己的逻辑操作。</p>
<p>2）将该实现类注册到 Spring 容器中，例如使用 @Component 注解。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.joonwhee.open.processor;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.BeansException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.config.BeanPostProcessor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyBeanPostProcessor</span> <span class="keyword">implements</span> <span class="title class_">BeanPostProcessor</span> &#123;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">postProcessBeforeInitialization</span><span class="params">(Object bean, String beanName)</span> <span class="keyword">throws</span> BeansException &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;MyBeanPostProcessor#postProcessBeforeInitialization&quot;</span>);</span><br><span class="line">        <span class="comment">// 自己的逻辑</span></span><br><span class="line">        <span class="keyword">return</span> bean;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">postProcessAfterInitialization</span><span class="params">(Object bean, String beanName)</span> <span class="keyword">throws</span> BeansException &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;MyBeanPostProcessor#postProcessAfterInitialization&quot;</span>);</span><br><span class="line">        <span class="comment">// 自己的逻辑</span></span><br><span class="line">        <span class="keyword">return</span> bean;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="实例化所有剩余的非懒加载单例-bean"><a href="#实例化所有剩余的非懒加载单例-bean" class="headerlink" title="实例化所有剩余的非懒加载单例 bean"></a>实例化所有剩余的非懒加载单例 bean</h3><p>1、遍历所有被加载到缓存中的 beanName，触发所有剩余的非懒加载单例 bean 的实例化。</p>
<p>2、首先通过 beanName 尝试从缓存中获取，如果存在则跳过实例化过程；否则，进行 bean 的实例化。</p>
<p>3、根据 BeanDefinition，使用构造函数创建 bean 实例。</p>
<p>4、根据 BeanDefinition，进行 bean 实例属性填充。</p>
<p>5、执行 bean 实例的初始化。</p>
<p>5.1、触发 Aware 方法。</p>
<p>5.2、触发 BeanPostProcessor 的 postProcessBeforeInitialization 方法。</p>
<p>5.3、如果 bean 实现了 InitializingBean 接口，则触发 afterPropertiesSet() 方法。</p>
<p>5.4、如果 bean 设置了 init-method 属性，则触发 init-method 指定的方法。</p>
<p>5.5、触发 BeanPostProcessor 的 postProcessAfterInitialization 方法。</p>
<p>6、将创建好的 bean 实例放到缓存中，用于之后使用。</p>
<h3 id="完成上下文的刷新"><a href="#完成上下文的刷新" class="headerlink" title="完成上下文的刷新"></a>完成上下文的刷新</h3><p>使用应用事件广播器推送上下文刷新完毕事件（ContextRefreshedEvent ）到相应的监听器。</p>
<p>例子：监听器扩展使用</p>
<p>1）创建一个自定义监听器，实现 ApplicationListener 接口，监听 ContextRefreshedEvent（上下文刷新完毕事件）。</p>
<p>2）将该监听器注册到 Spring IoC 容器即可。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationListener;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.event.ContextRefreshedEvent;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyRefreshedListener</span> <span class="keyword">implements</span> <span class="title class_">ApplicationListener</span>&lt;ContextRefreshedEvent&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onApplicationEvent</span><span class="params">(ContextRefreshedEvent event)</span> &#123;</span><br><span class="line">        <span class="comment">// 自己的逻辑处理</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>至此，整个 IoC 的核心流程介绍完毕。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文只是以简单的介绍了 IoC 中的重要步骤，如果想详细了解 IoC 的完整流程，可以查看之前的源码解析文章。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Spring-ioc</tag>
      </tags>
  </entry>
  <entry>
    <title>ThreadPoolExecutor</title>
    <url>/2021/04/05/ThreadPoolExecutor/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>现在在实现异步时，基本都是使用线程池来实现，线程池在工作应用的还是比较频繁的，本文将就线程池的使用、相关原理和主要方法源码进行深入讲解学习。</p>
<span id="more"></span>

<h2 id="线程池的基本使用"><a href="#线程池的基本使用" class="headerlink" title="线程池的基本使用"></a>线程池的基本使用</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.joonwhee.concurrent;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Callable;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Future;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.FutureTask;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.LinkedBlockingQueue;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ScheduledExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ThreadPoolExecutor;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 线程池的基本使用</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> JoonWhee</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2018年1月21日</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadPoolExecutorTest</span> &#123;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建一个线程池(完整入参): </span></span><br><span class="line"><span class="comment">     * 核心线程数为5 (corePoolSize), </span></span><br><span class="line"><span class="comment">     * 最大线程数为10 (maximumPoolSize), </span></span><br><span class="line"><span class="comment">     * 存活时间为60分钟(keepAliveTime), </span></span><br><span class="line"><span class="comment">     * 工作队列为LinkedBlockingQueue (workQueue),</span></span><br><span class="line"><span class="comment">     * 线程工厂为默认的DefaultThreadFactory (threadFactory), </span></span><br><span class="line"><span class="comment">     * 饱和策略(拒绝策略)为AbortPolicy: 抛出异常(handler).</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">ExecutorService</span> <span class="variable">THREAD_POOL</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(<span class="number">5</span>, <span class="number">10</span>, <span class="number">60</span>, TimeUnit.MINUTES,</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">LinkedBlockingQueue</span>&lt;Runnable&gt;(), Executors.defaultThreadFactory(),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>.AbortPolicy());</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 只有一个线程的线程池 没有超时时间, 工作队列使用无界的LinkedBlockingQueue</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">ExecutorService</span> <span class="variable">singleThreadExecutor</span> <span class="operator">=</span> Executors.newSingleThreadExecutor();</span><br><span class="line">    <span class="comment">// private static ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor(Executors.defaultThreadFactory());</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 有固定线程的线程池(即corePoolSize = maximumPoolSize) 没有超时时间,</span></span><br><span class="line"><span class="comment">     * 工作队列使用无界的LinkedBlockingQueue</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">ExecutorService</span> <span class="variable">fixedThreadPool</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">5</span>);</span><br><span class="line">    <span class="comment">// private static ExecutorService fixedThreadPool = Executors.newFixedThreadPool(5, Executors.defaultThreadFactory());</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 大小不限的线程池 核心线程数为0, 最大线程数为Integer.MAX_VALUE, 存活时间为60秒 该线程池可以无限扩展,</span></span><br><span class="line"><span class="comment">     * 并且当需求降低时会自动收缩, 工作队列使用同步移交SynchronousQueue.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">ExecutorService</span> <span class="variable">cachedThreadPool</span> <span class="operator">=</span> Executors.newCachedThreadPool();</span><br><span class="line">    <span class="comment">// private static ExecutorService cachedThreadPool = Executors.newCachedThreadPool(Executors.defaultThreadFactory());</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 给定的延迟之后运行任务, 或者定期执行任务的线程池</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">ScheduledExecutorService</span> <span class="variable">scheduledThreadPool</span> <span class="operator">=</span> Executors.newScheduledThreadPool(<span class="number">5</span>);</span><br><span class="line">    <span class="comment">// private static ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5, Executors.defaultThreadFactory());</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 例子1: 没有返回结果的异步任务</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        THREAD_POOL.submit(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="comment">// do something</span></span><br><span class="line">                System.out.println(<span class="string">&quot;没有返回结果的异步任务&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 例子2: 有返回结果的异步任务</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        Future&lt;List&lt;String&gt;&gt; future = THREAD_POOL.submit(<span class="keyword">new</span> <span class="title class_">Callable</span>&lt;List&lt;String&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> List&lt;String&gt; <span class="title function_">call</span><span class="params">()</span> &#123;</span><br><span class="line">                List&lt;String&gt; result = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                result.add(<span class="string">&quot;JoonWhee&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span> result;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        List&lt;String&gt; result = future.get(); <span class="comment">// 获取返回结果</span></span><br><span class="line">        System.out.println(<span class="string">&quot;有返回结果的异步任务: &quot;</span> + result);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 例子3: </span></span><br><span class="line"><span class="comment">         * 有延迟的, 周期性执行异步任务</span></span><br><span class="line"><span class="comment">         * 本例子为: 延迟1秒, 每2秒执行1次</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        scheduledThreadPool.scheduleAtFixedRate(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;this is &quot;</span> + Thread.currentThread().getName());</span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">        &#125;, <span class="number">1</span>, <span class="number">2</span>, TimeUnit.SECONDS);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 例子4: FutureTask的使用</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        Callable&lt;String&gt; task = <span class="keyword">new</span> <span class="title class_">Callable</span>&lt;String&gt;() &#123;</span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">call</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&quot;JoonWhee&quot;</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;      </span><br><span class="line">        FutureTask&lt;String&gt; futureTo = <span class="keyword">new</span> <span class="title class_">FutureTask</span>&lt;String&gt;(task);</span><br><span class="line">        THREAD_POOL.submit(futureTo);</span><br><span class="line">        System.out.println(futureTo.get()); <span class="comment">// 获取返回结果</span></span><br><span class="line"><span class="comment">//        System.out.println(futureTo.get(3, TimeUnit.SECONDS));  // 超时时间为3秒</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<h2 id="线程池的定义和优点"><a href="#线程池的定义和优点" class="headerlink" title="线程池的定义和优点"></a>线程池的定义和优点</h2><p>线程池，从字面含义来看，是指管理一组同构工作线程的资源池。线程池是与工作队列密切相关的，其中在工作队列中保存了所有等待执行的任务。工作者线程的任务很简单：从工作队列中获取一个任务，执行任务，然后返回线程池并等待下一个任务。</p>
<p>“在线程池中执行任务“”比“为每个线程分配一个任务”优势更多。通过重用现有的线程而不是创建线程，可以在处理多个请求时分摊在线程创建和销毁过程中产生的巨大开销。另一个额外的好处是，当请求到达时，工作线程通常已经存在，因此不会由于等待创建线程而延迟任务的执行，从而提高了响应性。通过适当的调整线程池的大小，可以创建足够的线程以便使处理器保持忙碌状态，同时还可以防止过多线程相互竞争资源而使应用程序耗尽内存或失败。</p>
<h2 id="线程池工作流程"><a href="#线程池工作流程" class="headerlink" title="线程池工作流程"></a>线程池工作流程</h2><blockquote>
<p>默认情况下，创建完线程池后并不会立即创建线程, 而是等到有任务提交时才会创建线程来进行处理。（除非调用prestartCoreThread或prestartAllCoreThreads方法） <br>当线程数小于核心线程数时，每提交一个任务就创建一个线程来执行，即使当前有线程处于空闲状态，直到当前线程数达到核心线程数。  <br>当前线程数达到核心线程数时，如果这个时候还提交任务，这些任务会被放到队列里，等到线程处理完了手头的任务后，会来队列中取任务处理。  <br>当前线程数达到核心线程数并且队列也满了，如果这个时候还提交任务，则会继续创建线程来处理，直到线程数达到最大线程数。<br>当前线程数达到最大线程数并且队列也满了，如果这个时候还提交任务，则会触发饱和策略。 <br>如果某个线程的控线时间超过了keepAliveTime，那么将被标记为可回收的，并且当前线程池的当前大小超过了核心线程数时，这个线程将被终止。</p>
</blockquote>
<h2 id="工作队列"><a href="#工作队列" class="headerlink" title="工作队列"></a>工作队列</h2><p>如果新请求的到达速率超过了线程池的处理速率，那么新到来的请求将累积起来。在线程池中，这些请求会在一个由Executor管理的Runnable队列中等待，而不会像线程那样去竞争CPU资源。常见的工作队列有以下几种，前三种用的最多。</p>
<blockquote>
<p>ArrayBlockingQueue：列表形式的工作队列，必须要有初始队列大小，有界队列，先进先出。<br> LinkedBlockingQueue：链表形式的工作队列，可以选择设置初始队列大小，有界/无界队列，先进先出。<br> SynchronousQueue：SynchronousQueue不是一个真正的队列，而是一种在线程之间移交的机制。要将一个元素放入SynchronousQueue中, 必须有另一个线程正在等待接受这个元素. 如果没有线程等待，并且线程池的当前大小小于最大值，那么ThreadPoolExecutor将创建 一个线程, 否则根据饱和策略，这个任务将被拒绝。使用直接移交将更高效，因为任务会直接移交 给执行它的线程，而不是被首先放在队列中, 然后由工作者线程从队列中提取任务. 只有当线程池是无界的或者可以拒绝任务时，SynchronousQueue才有实际价值.<br> PriorityBlockingQueue：优先级队列，无界队列，根据优先级来安排任务，任务的优先级是通过自然顺序或Comparator（如果任务实现了Comparator）来定义的。<br> DelayedWorkQueue：延迟的工作队列，无界队列。</p>
</blockquote>
<h2 id="拒绝策略"><a href="#拒绝策略" class="headerlink" title="拒绝策略"></a>拒绝策略</h2><p>当有界队列被填满后，饱和策略开始发挥作用。ThreadPoolExecutor的饱和策略可以通过调用setRejectedExecutionHandler来修改。（如果某个任务被提交到一个已被关闭的Executor时，也会用到饱和策略）。饱和策略有以下四种，一般使用默认的AbortPolicy。</p>
<blockquote>
<p>AbortPolicy：中止策略。默认的饱和策略，抛出未检查的RejectedExecutionException。调用者可以捕获这个异常，然后根据需求编写自己的处理代码。<br> DiscardPolicy：抛弃策略。当新提交的任务无法保存到队列中等待执行时，该策略会悄悄抛弃该任务。<br> DiscardOldestPolicy：抛弃最旧的策略。当新提交的任务无法保存到队列中等待执行时，则会抛弃下一个将被执行的任务，然后尝试重新提交新的任务。（如果工作队列是一个优先队列，那么“抛弃最旧的”策略将导致抛弃优先级最高的任务，因此最好不要将“抛弃最旧的”策略和优先级队列放在一起使用）。<br> CallerRunsPolicy：调用者运行策略。该策略实现了一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者（调用线程池执行任务的主线程），从而降低新任务的流程。它不会在线程池的某个线程中执行新提交的任务，而是在一个调用了execute的线程中执行该任务。当线程池的所有线程都被占用，并且工作队列被填满后，下一个任务会在调用execute时在主线程中执行（调用线程池执行任务的主线程）。由于执行任务需要一定时间，因此主线程至少在一段时间内不能提交任务，从而使得工作者线程有时间来处理完正在执行的任务。在这期间，主线程不会调用accept，因此到达的请求将被保存在TCP层的队列中。如果持续过载，那么TCP层将最终发现它的请求队列被填满，因此同样会开始抛弃请求。当服务器过载后，这种过载情况会逐渐向外蔓延开来——从线程池到工作队列到应用程序再到TCP层，最终达到客户端，导致服务器在高负载下实现一种平缓的性能降低。</p>
</blockquote>
<h2 id="线程工厂"><a href="#线程工厂" class="headerlink" title="线程工厂"></a>线程工厂</h2><p>每当线程池需要创建一个线程时，都是通过线程工厂方法来完成的。在ThreadFactory中只定义了一个方法newThread，每当线程池需要创建一个新线程时都会调用这个方法。Executors提供的线程工厂有两种，一般使用默认的，当然如果有特殊需求，也可以自己定制。</p>
<blockquote>
<p>DefaultThreadFactory：默认线程工厂，创建一个新的、非守护的线程，并且不包含特殊的配置信息。<br> PrivilegedThreadFactory：通过这种方式创建出来的线程，将与创建privilegedThreadFactory的线程拥有相同的访问权限、 AccessControlContext、ContextClassLoader。如果不使用privilegedThreadFactory， 线程池创建的线程将从在需要新线程时调用execute或submit的客户程序中继承访问权限。<br> 自定义线程工厂：可以自己实现ThreadFactory接口来定制自己的线程工厂方法。</p>
</blockquote>
<h2 id="ThreadPoolExecutor源码解析"><a href="#ThreadPoolExecutor源码解析" class="headerlink" title="ThreadPoolExecutor源码解析"></a>ThreadPoolExecutor源码解析</h2><h3 id="几个点"><a href="#几个点" class="headerlink" title="几个点"></a>几个点</h3><p>了解这几个点，有助于你阅读下面的源码解释。</p>
<blockquote>
<p>下面的源码解读中提到的运行状态就是runState，有效的线程数就是workerCount，内容比较多，所以可能两种写法都用到。<br> 运行状态的一些定义：RUNNING：接受新任务并处理排队任务； SHUTDOWN：不接受新任务，但处理排队任务； STOP：不接受新任务，不处理排队任务，并中断正在进行的任务；TIDYING：所有任务已经终止，workerCount为零，线程转换到状态TIDYING将运行terminate()钩子方法；TERMINATED：terminated()已经完成，该方法执行完毕代表线程池已经完全终止。<br> 运行状态之间并不是随意转换的，大多数状态都只能由固定的状态转换而来，转换关系见下。<br> RUNNING - &gt; SHUTDOWN：在调用shutdown()时，可能隐含在finalize()。<br> (RUNNING or SHUTDOWN) -&gt; STOP：调用shutdownNow()。<br> SHUTDOWN - &gt; TIDYING：当队列和线程池都是空的时。<br> STOP - &gt; TIDYING：当线程池为空时。<br> TIDYING - &gt; TERMINATED：当terminate()方法完成时。</p>
</blockquote>
<h3 id="基础属性（很重要）"><a href="#基础属性（很重要）" class="headerlink" title="基础属性（很重要）"></a>基础属性（很重要）</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 主池控制状态ctl是包含两个概念字段的原子整数: workerCount：指有效的线程数量；</span></span><br><span class="line"><span class="comment"> * runState：指运行状态，运行，关闭等。为了将workerCount和runState用1个int来表示，</span></span><br><span class="line"><span class="comment"> * 我们限制workerCount范围为(2 ^ 29) - 1，即用int的低29位用来表示workerCount，</span></span><br><span class="line"><span class="comment"> * 用int的高3位用来表示runState，这样workerCount和runState刚好用int可以完整表示。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">// 初始化时有效的线程数为0, 此时ctl为: 1010 0000 0000 0000 0000 0000 0000 0000 </span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">AtomicInteger</span> <span class="variable">ctl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(ctlOf(RUNNING, <span class="number">0</span>)); </span><br><span class="line"><span class="comment">// 高3位用来表示运行状态，此值用于运行状态向左移动的位数，即29位</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">COUNT_BITS</span> <span class="operator">=</span> Integer.SIZE - <span class="number">3</span>;     </span><br><span class="line"><span class="comment">// 线程数容量，低29位表示有效的线程数, 0001 1111 1111 1111 1111 1111 1111 1111</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">CAPACITY</span>   <span class="operator">=</span> (<span class="number">1</span> &lt;&lt; COUNT_BITS) - <span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 大小关系：RUNNING &lt; SHUTDOWN &lt; STOP &lt; TIDYING &lt; TERMINATED，</span></span><br><span class="line"><span class="comment"> * 源码中频繁使用大小关系来作为条件判断。</span></span><br><span class="line"><span class="comment"> * 1110 0000 0000 0000 0000 0000 0000 0000 运行</span></span><br><span class="line"><span class="comment"> * 0000 0000 0000 0000 0000 0000 0000 0000 关闭</span></span><br><span class="line"><span class="comment"> * 0010 0000 0000 0000 0000 0000 0000 0000 停止</span></span><br><span class="line"><span class="comment"> * 0100 0000 0000 0000 0000 0000 0000 0000 整理</span></span><br><span class="line"><span class="comment"> * 0110 0000 0000 0000 0000 0000 0000 0000 终止</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">RUNNING</span>    <span class="operator">=</span> -<span class="number">1</span> &lt;&lt; COUNT_BITS; <span class="comment">// 运行</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">SHUTDOWN</span>   <span class="operator">=</span>  <span class="number">0</span> &lt;&lt; COUNT_BITS; <span class="comment">// 关闭</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">STOP</span>       <span class="operator">=</span>  <span class="number">1</span> &lt;&lt; COUNT_BITS; <span class="comment">// 停止</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">TIDYING</span>    <span class="operator">=</span>  <span class="number">2</span> &lt;&lt; COUNT_BITS; <span class="comment">// 整理</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">TERMINATED</span> <span class="operator">=</span>  <span class="number">3</span> &lt;&lt; COUNT_BITS; <span class="comment">// 终止</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 得到运行状态:入参c为ctl的值，~CAPACITY高3位为1低29位全为0, </span></span><br><span class="line"><span class="comment"> * 因此运算结果为ctl的高3位, 也就是运行状态</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">runStateOf</span><span class="params">(<span class="type">int</span> c)</span>     &#123; <span class="keyword">return</span> c &amp; ~CAPACITY; &#125;  </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 得到有效的线程数:入参c为ctl的值, CAPACITY高3为为0, </span></span><br><span class="line"><span class="comment"> * 低29位全为1, 因此运算结果为ctl的低29位, 也就是有效的线程数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">workerCountOf</span><span class="params">(<span class="type">int</span> c)</span>  &#123; <span class="keyword">return</span> c &amp; CAPACITY; &#125;   </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 得到ctl的值：高3位的运行状态和低29位的有效线程数进行或运算, </span></span><br><span class="line"><span class="comment"> * 组合成一个完成的32位数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">ctlOf</span><span class="params">(<span class="type">int</span> rs, <span class="type">int</span> wc)</span> &#123; <span class="keyword">return</span> rs | wc; &#125;    </span><br><span class="line"> </span><br><span class="line"><span class="comment">// 状态c是否小于s</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">runStateLessThan</span><span class="params">(<span class="type">int</span> c, <span class="type">int</span> s)</span> &#123; </span><br><span class="line">    <span class="keyword">return</span> c &lt; s;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 状态c是否大于等于s</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">runStateAtLeast</span><span class="params">(<span class="type">int</span> c, <span class="type">int</span> s)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> c &gt;= s;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 状态c是否为RUNNING（小于SHUTDOWN的状态只有RUNNING）</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">isRunning</span><span class="params">(<span class="type">int</span> c)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> c &lt; SHUTDOWN;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 使用CAS增加一个有效的线程</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">compareAndIncrementWorkerCount</span><span class="params">(<span class="type">int</span> expect)</span> &#123;    </span><br><span class="line">    <span class="keyword">return</span> ctl.compareAndSet(expect, expect + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 使用CAS减少一个有效的线程</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">compareAndDecrementWorkerCount</span><span class="params">(<span class="type">int</span> expect)</span> &#123;    </span><br><span class="line">    <span class="keyword">return</span> ctl.compareAndSet(expect, expect - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 减少一个有效的线程</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">decrementWorkerCount</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">do</span> &#123;&#125; <span class="keyword">while</span> (! compareAndDecrementWorkerCount(ctl.get()));</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 工作队列</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> BlockingQueue&lt;Runnable&gt; workQueue;    </span><br><span class="line"> </span><br><span class="line"><span class="comment">// 锁</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">ReentrantLock</span> <span class="variable">mainLock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantLock</span>(); </span><br><span class="line"> </span><br><span class="line"><span class="comment">// 包含线程池中的所有工作线程,只有在mainLock的情况下才能访问,Worker集合</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> HashSet&lt;Worker&gt; workers = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;Worker&gt;();</span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">Condition</span> <span class="variable">termination</span> <span class="operator">=</span> mainLock.newCondition();</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 跟踪线程池的最大到达大小，仅在mainLock下访问</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">int</span> largestPoolSize;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 总的完成的任务数</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">long</span> completedTaskCount;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 线程工厂，用于创建线程</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> ThreadFactory threadFactory;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 拒绝策略</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> RejectedExecutionHandler handler;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 线程超时时间，当线程数超过corePoolSize时生效, </span></span><br><span class="line"><span class="comment"> * 如果有线程空闲时间超过keepAliveTime, 则会被终止</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">long</span> keepAliveTime;    </span><br><span class="line"> </span><br><span class="line"><span class="comment">// 是否允许核心线程超时，默认false，false情况下核心线程会一直存活。</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">boolean</span> allowCoreThreadTimeOut;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 核心线程数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">int</span> corePoolSize;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 最大线程数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">int</span> maximumPoolSize;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 默认饱和策略（拒绝策略）, 抛异常</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">RejectedExecutionHandler</span> <span class="variable">defaultHandler</span> <span class="operator">=</span> </span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">AbortPolicy</span>();</span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">RuntimePermission</span> <span class="variable">shutdownPerm</span> <span class="operator">=</span></span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">RuntimePermission</span>(<span class="string">&quot;modifyThread&quot;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Worker类，每个Worker包含一个线程、一个初始任务、一个任务计算器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">Worker</span>   </span><br><span class="line">    <span class="keyword">extends</span> <span class="title class_">AbstractQueuedSynchronizer</span></span><br><span class="line">    <span class="keyword">implements</span> <span class="title class_">Runnable</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">6138294804551838833L</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">final</span> Thread thread;    <span class="comment">// Worker对应的线程</span></span><br><span class="line">    Runnable firstTask; <span class="comment">// 运行的初始任务。</span></span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">long</span> completedTasks;   <span class="comment">// 每个线程的任务计数器</span></span><br><span class="line"> </span><br><span class="line">    Worker(Runnable firstTask) &#123;</span><br><span class="line">        setState(-<span class="number">1</span>); <span class="comment">// 禁止中断，直到runWorker</span></span><br><span class="line">        <span class="built_in">this</span>.firstTask = firstTask; <span class="comment">// 设置为初始任务</span></span><br><span class="line">        <span class="comment">// 使用当前线程池的线程工厂创建一个线程</span></span><br><span class="line">        <span class="built_in">this</span>.thread = getThreadFactory().newThread(<span class="built_in">this</span>);  </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 将主运行循环委托给外部runWorker</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        runWorker(<span class="built_in">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// Lock methods</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// The value 0 represents the unlocked state.</span></span><br><span class="line">    <span class="comment">// The value 1 represents the locked state.</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过AQS的同步状态来实现锁机制。state为0时代表锁未被获取（解锁状态），</span></span><br><span class="line"><span class="comment">     * state为1时代表锁已经被获取（加锁状态）。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="type">boolean</span> <span class="title function_">isHeldExclusively</span><span class="params">()</span> &#123; <span class="comment">// </span></span><br><span class="line">        <span class="keyword">return</span> getState() != <span class="number">0</span>; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">protected</span> <span class="type">boolean</span> <span class="title function_">tryAcquire</span><span class="params">(<span class="type">int</span> unused)</span> &#123;  <span class="comment">// 尝试获取锁</span></span><br><span class="line">        <span class="keyword">if</span> (compareAndSetState(<span class="number">0</span>, <span class="number">1</span>)) &#123; <span class="comment">// 使用CAS尝试将state设置为1，即尝试获取锁</span></span><br><span class="line">            <span class="comment">// 成功将state设置为1，则当前线程拥有独占访问权</span></span><br><span class="line">            setExclusiveOwnerThread(Thread.currentThread());    </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">protected</span> <span class="type">boolean</span> <span class="title function_">tryRelease</span><span class="params">(<span class="type">int</span> unused)</span> &#123;  <span class="comment">// 尝试释放锁</span></span><br><span class="line">        setExclusiveOwnerThread(<span class="literal">null</span>);  <span class="comment">// 释放独占访问权：即将独占访问线程设为null</span></span><br><span class="line">        setState(<span class="number">0</span>);    <span class="comment">// 解锁：将state设置为0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">lock</span><span class="params">()</span>        &#123; acquire(<span class="number">1</span>); &#125;   <span class="comment">// 加锁</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">tryLock</span><span class="params">()</span>  &#123; <span class="keyword">return</span> tryAcquire(<span class="number">1</span>); &#125; <span class="comment">// 尝试加锁</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">unlock</span><span class="params">()</span>      &#123; release(<span class="number">1</span>); &#125;   <span class="comment">// 解锁</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isLocked</span><span class="params">()</span> &#123; <span class="keyword">return</span> isHeldExclusively(); &#125;  <span class="comment">// 是否为加锁状态 </span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">interruptIfStarted</span><span class="params">()</span> &#123; <span class="comment">// 如果线程启动了，则进行中断</span></span><br><span class="line">        Thread t;</span><br><span class="line">        <span class="keyword">if</span> (getState() &gt;= <span class="number">0</span> &amp;&amp; (t = thread) != <span class="literal">null</span> &amp;&amp; !t.isInterrupted()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                t.interrupt();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (SecurityException ignore) &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="execute方法"><a href="#execute方法" class="headerlink" title="execute方法"></a>execute方法</h3><p>使用线程池的submit方法提交任务时，会走到该方法，该方法也是线程池最重要的方法。</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span>(<span class="params">Runnable command</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (command == <span class="literal">null</span>)    <span class="comment">// 为空校验</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">int</span> c = ctl.<span class="keyword">get</span>();  <span class="comment">// 拿到当前的ctl值</span></span><br><span class="line">    <span class="keyword">if</span> (workerCountOf(c) &lt; corePoolSize) &#123;  <span class="comment">// 如果有效的线程数小于核心线程数</span></span><br><span class="line">        <span class="keyword">if</span> (addWorker(command, <span class="literal">true</span>))   <span class="comment">// 则新建一个线程来处理任务（核心线程）</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        c = ctl.<span class="keyword">get</span>();  <span class="comment">// 拿到当前的ctl值</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 走到这里说明有效的线程数已经 &gt;= 核心线程数</span></span><br><span class="line">    <span class="keyword">if</span> (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;<span class="comment">// 如果当前状态是运行, 尝试将任务放入工作队列</span></span><br><span class="line">        <span class="built_in">int</span> recheck = ctl.<span class="keyword">get</span>();    <span class="comment">// 再次拿到当前的ctl值</span></span><br><span class="line">        <span class="comment">// 如果再次检查状态不是运行, 则将刚才添加到工作队列的任务移除</span></span><br><span class="line">        <span class="keyword">if</span> (! isRunning(recheck) &amp;&amp; <span class="keyword">remove</span>(command)) </span><br><span class="line">            reject(command);    <span class="comment">// 并调用拒绝策略</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (workerCountOf(recheck) == <span class="number">0</span>) <span class="comment">// 如果再次检查时,有效的线程数为0, </span></span><br><span class="line">            addWorker(<span class="literal">null</span>, <span class="literal">false</span>); <span class="comment">// 则新建一个线程(非核心线程)</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 走到这里说明工作队列已满</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (!addWorker(command, <span class="literal">false</span>))<span class="comment">//尝试新建一个线程来处理任务(非核心)</span></span><br><span class="line">        reject(command);    <span class="comment">// 如果失败则调用拒绝策略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法就是对应上文的线程池的工作流程。主要调用到的方法为addWorker（见下文addWorker方法解读）。</p>
<h3 id="addWorker方法"><a href="#addWorker方法" class="headerlink" title="addWorker方法"></a>addWorker方法</h3><figure class="highlight axapta"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 添加一个Worker，Worker包含一个线程和一个任务，由这个线程来执行该任务。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="built_in">boolean</span> addWorker(Runnable firstTask, <span class="built_in">boolean</span> core) &#123;   </span><br><span class="line">    <span class="keyword">retry</span>:</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="built_in">int</span> c = ctl.get();  <span class="comment">// c赋值为ctl</span></span><br><span class="line">        <span class="built_in">int</span> rs = runStateOf(c); <span class="comment">// rs赋值为运行状态</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 1.如果池停止或有资格关闭，则此方法返回false；</span></span><br><span class="line"><span class="comment">         * 如果线程工厂在被询问时未能创建线程，它也返回false。 </span></span><br><span class="line"><span class="comment">         * 包括以下5种情况：</span></span><br><span class="line"><span class="comment">         * 1).rs为RUNNING，通过校验。</span></span><br><span class="line"><span class="comment">         * 2).rs为STOP或TIDYING或TERMINATED，返回false。</span></span><br><span class="line"><span class="comment">         * （STOP、TIDYING、TERMINATED：已经停止进入最后清理终止，不接受任务不处理队列任务）</span></span><br><span class="line"><span class="comment">         * 3).rs为SHUTDOWN，提交的任务不为空，返回false。</span></span><br><span class="line"><span class="comment">         * （SHUTDOWN：不接受任务但是处理队列任务，因此任务不为空返回false）</span></span><br><span class="line"><span class="comment">         * 4).rs为SHUTDOWN，提交的任务为空，并且工作队列为空，返回false。</span></span><br><span class="line"><span class="comment">         * （状态为SHUTDOWN、提交的任务为空、工作队列为空，则线程池有资格关闭，直接返回false）</span></span><br><span class="line"><span class="comment">         * 5).rs为SHUTDOWN，提交的任务为空，并且工作队列不为空，通过校验。</span></span><br><span class="line"><span class="comment">         * （因为SHUTDOWN状态下刚好可以处理队列任务）</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (rs &gt;= SHUTDOWN &amp;&amp;</span><br><span class="line">            ! (rs == SHUTDOWN &amp;&amp;</span><br><span class="line">               firstTask == <span class="literal">null</span> &amp;&amp;</span><br><span class="line">               ! workQueue.isEmpty()))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">            <span class="built_in">int</span> wc = workerCountOf(c);  <span class="comment">// 拿到有效的线程数</span></span><br><span class="line">            <span class="comment">// 校验有效的线程数是否超过阈值</span></span><br><span class="line">            <span class="keyword">if</span> (wc &gt;= CAPACITY ||</span><br><span class="line">                wc &gt;= (core ? corePoolSize : maximumPoolSize))</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="comment">// 使用CAS将workerCount+1, 修改成功则跳出循环，否则进入下面的状态判断</span></span><br><span class="line">            <span class="keyword">if</span> (compareAndIncrementWorkerCount(c))</span><br><span class="line">                <span class="keyword">break</span> <span class="keyword">retry</span>;</span><br><span class="line">            c = ctl.get();  <span class="comment">// 重新读取ctl</span></span><br><span class="line">            <span class="comment">// 判断当前运行状态，如果不等于上面获取的运行状态rs，</span></span><br><span class="line">            <span class="comment">// 说明rs被其他线程修改了，跳到retry重新校验线程池状态</span></span><br><span class="line">            <span class="keyword">if</span> (runStateOf(c) != rs)</span><br><span class="line">                <span class="keyword">continue</span> <span class="keyword">retry</span>;</span><br><span class="line">            <span class="comment">// 走到这里说明compareAndIncrementWorkerCount失败; </span></span><br><span class="line">            <span class="comment">// 重试内部循环（状态没变，则继续内部循环，尝试使用CAS修改workerCount）</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">boolean</span> workerStarted = <span class="literal">false</span>;  <span class="comment">// Worker的线程是否启动</span></span><br><span class="line">    <span class="built_in">boolean</span> workerAdded = <span class="literal">false</span>;    <span class="comment">// Worker是否成功增加</span></span><br><span class="line">    Worker w = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        w = <span class="keyword">new</span> Worker(firstTask);  <span class="comment">// 用firstTask和当前线程创建一个Worker</span></span><br><span class="line">        <span class="keyword">final</span> Thread t = w.thread;  <span class="comment">// 拿到Worker对应的线程</span></span><br><span class="line">        <span class="keyword">if</span> (t != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">            mainLock.lock();    <span class="comment">// 加锁</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// Recheck while holding lock.</span></span><br><span class="line">                <span class="comment">// Back out on ThreadFactory failure or if</span></span><br><span class="line">                <span class="comment">// shut down before lock acquired.</span></span><br><span class="line">                <span class="built_in">int</span> rs = runStateOf(ctl.get()); <span class="comment">// 加锁的情况下重新获取当前的运行状态</span></span><br><span class="line"> </span><br><span class="line">                <span class="comment">// 如果当前的运行状态为RUNNING，</span></span><br><span class="line">                <span class="comment">// 或者当前的运行状态为SHUTDOWN并且firstTask为空，则通过校验</span></span><br><span class="line">                <span class="keyword">if</span> (rs &lt; SHUTDOWN ||</span><br><span class="line">                    (rs == SHUTDOWN &amp;&amp; firstTask == <span class="literal">null</span>)) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (t.isAlive())    <span class="comment">// 预先校验线程是可以启动的</span></span><br><span class="line">                        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalThreadStateException();</span><br><span class="line">                    workers.add(w); <span class="comment">// 将刚创建的worker添加到工作者列表</span></span><br><span class="line">                    <span class="built_in">int</span> s = workers.size();</span><br><span class="line">                    <span class="keyword">if</span> (s &gt; largestPoolSize)</span><br><span class="line">                        largestPoolSize = s;</span><br><span class="line">                    workerAdded = <span class="literal">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                mainLock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (workerAdded) &#123;  <span class="comment">// 如果Worker添加成功，则启动线程执行</span></span><br><span class="line">                t.start();</span><br><span class="line">                workerStarted = <span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (! workerStarted)    <span class="comment">// 如果Worker的线程没有成功启动</span></span><br><span class="line">            addWorkerFailed(w); <span class="comment">// 则进行回滚, 移除之前添加的Worker</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> workerStarted;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法主要目的就是使用入参中的firstTask和当前线程添加一个Worker，前面的for循环主要是对当前线程池的运行状态和有效的线程数进行一些校验，校验逻辑比较绕，可以参考注释进行理解。该方法涉及到的其他方法有addWorkerFailed（见下文addWorkerFailed源码解读）；还有就是Worker的线程启动时，会调用Worker里的run方法，执行runWorker(this)方法（见下文runWorker源码解读）。</p>
<h3 id="addWorkerFailed方法"><a href="#addWorkerFailed方法" class="headerlink" title="addWorkerFailed方法"></a>addWorkerFailed方法</h3><figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Rolls back the worker thread creation.</span></span><br><span class="line"><span class="comment"> * - removes worker from workers, if present</span></span><br><span class="line"><span class="comment"> * - decrements worker count</span></span><br><span class="line"><span class="comment"> * - rechecks for termination, in case the existence of this</span></span><br><span class="line"><span class="comment"> *   worker was holding up termination</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addWorkerFailed</span>(<span class="params">Worker w</span>)</span> &#123;    <span class="comment">// 回滚Worker的添加，就是将Worker移除</span></span><br><span class="line">    final ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">    mainLock.<span class="keyword">lock</span>();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (w != <span class="literal">null</span>)</span><br><span class="line">            workers.<span class="keyword">remove</span>(w);  <span class="comment">// 移除Worker</span></span><br><span class="line">        decrementWorkerCount(); <span class="comment">// 有效线程数-1</span></span><br><span class="line">        tryTerminate(); <span class="comment">// 有worker线程移除，可能是最后一个线程退出需要尝试终止线程池</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mainLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法很简单，就是移除入参中的Worker并将workerCount-1，最后调用tryTerminate尝试终止线程池，tryTerminate见下文对应方法源码解读。</p>
<h3 id="runWorker方法"><a href="#runWorker方法" class="headerlink" title="runWorker方法"></a>runWorker方法</h3><p>上文addWork方法里说道，当Worker里的线程启动时，就会调用该方法。</p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Worker的线程开始执行任务</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">void</span> runWorker(Worker w) &#123;</span><br><span class="line">    Thread wt = Thread.currentThread(); <span class="comment">// 获取当前线程</span></span><br><span class="line">    Runnable <span class="keyword">task</span> = w.firstTask;    <span class="comment">// 拿到Worker的初始任务</span></span><br><span class="line">    w.firstTask = <span class="keyword">null</span>;</span><br><span class="line">    w.unlock(); <span class="comment">// allow interrupts</span></span><br><span class="line">    <span class="keyword">boolean</span> completedAbruptly = <span class="keyword">true</span>;   <span class="comment">// Worker是不是因异常而死亡</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">task</span> != <span class="keyword">null</span> || (<span class="keyword">task</span> = getTask()) != <span class="keyword">null</span>) &#123;<span class="comment">// Worker取任务执行</span></span><br><span class="line">            w.lock();   <span class="comment">// 加锁</span></span><br><span class="line">            <span class="comment">/**如果线程池停止，确保线程中断; 如果不是，确保线程不被中断。</span></span><br><span class="line"><span class="comment">             * 在第二种情况下进行重新检查，以便在清除中断的同时处理shutdownNow竞争</span></span><br><span class="line"><span class="comment">             * 线程池停止指运行状态为STOP/TIDYING/TERMINATED中的一种</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">if</span> ((runStateAtLeast(ctl.get(), STOP) ||    <span class="comment">// 判断线程池运行状态</span></span><br><span class="line">                 (Thread.interrupted() &amp;&amp;   <span class="comment">// 重新检查</span></span><br><span class="line">                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp; <span class="comment">// 再次判断线程池运行状态</span></span><br><span class="line">                !wt.isInterrupted())<span class="comment">// 走到这里代表线程池运行状态为停止,检查wt是否中断</span></span><br><span class="line">                wt.interrupt(); <span class="comment">// 线程池的状态为停止并且wt不为中断, 则将wt中断</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                beforeExecute(wt, <span class="keyword">task</span>);<span class="comment">// 执行beforeExecute（默认空，需要自己重写）</span></span><br><span class="line">                Throwable thrown = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="keyword">task</span>.run(); <span class="comment">// 执行任务</span></span><br><span class="line">                &#125; <span class="keyword">catch</span> (RuntimeException x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> x; <span class="comment">//如果抛异常,则completedAbruptly为true</span></span><br><span class="line">                &#125; <span class="keyword">catch</span> (Error x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> x;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Throwable x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> <span class="keyword">new</span> Error(x);</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    afterExecute(<span class="keyword">task</span>, thrown);<span class="comment">// 执行afterExecute（需要自己重写）</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                <span class="keyword">task</span> = <span class="keyword">null</span>;    <span class="comment">// 将执行完的任务清空</span></span><br><span class="line">                w.completedTasks++; <span class="comment">// Worker完成任务数+1</span></span><br><span class="line">                w.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        completedAbruptly = <span class="keyword">false</span>;  <span class="comment">// 如果执行到这里，则worker是正常退出</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        processWorkerExit(w, completedAbruptly);<span class="comment">// 调用processWorkerExit方法</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法为Worker线程开始执行任务，首先执行当初创建Worker时的初始任务，接着从工作队列中获取任务执行。主要涉及两个方法：获取任务的方法getTask（见下文getTask源码解读）和执行Worker退出的方法processWorkerExit（见下文processWorkerExit源码解读）。注：processWorkerExit在处理正常Worker退出时，没有对workerCount-1，而是在getTask方法中进行workerCount-1。</p>
<h3 id="getTask方法"><a href="#getTask方法" class="headerlink" title="getTask方法"></a>getTask方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> Runnable <span class="title function_">getTask</span><span class="params">()</span> &#123;    <span class="comment">// Worker从工作队列获取任务</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">timedOut</span> <span class="operator">=</span> <span class="literal">false</span>; <span class="comment">// poll方法取任务是否超时</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;  <span class="comment">// 无线循环</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">c</span> <span class="operator">=</span> ctl.get();  <span class="comment">// ctl</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">rs</span> <span class="operator">=</span> runStateOf(c); <span class="comment">// 当前运行状态</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 如果线程池运行状态为停止，或者可以停止（状态为SHUTDOWN并且队列为空）</span></span><br><span class="line">        <span class="comment">// 则返回null，代表当前Worker需要移除</span></span><br><span class="line">        <span class="keyword">if</span> (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123;    </span><br><span class="line">            decrementWorkerCount(); <span class="comment">// 将workerCount - 1</span></span><br><span class="line">            <span class="comment">// 返回null前将workerCount - 1,</span></span><br><span class="line">            <span class="comment">// 因此processWorkerExit中completedAbruptly＝false时无需再减</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="type">int</span> <span class="variable">wc</span> <span class="operator">=</span> workerCountOf(c);  <span class="comment">// 当前的workerCount</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 判断当前Worker是否可以被移除, 即当前Worker是否可以一直等待任务。</span></span><br><span class="line">        <span class="comment">// 如果allowCoreThreadTimeOut为true，或者workerCount大于核心线程数，</span></span><br><span class="line">        <span class="comment">// 则当前线程是有超时时间的（keepAliveTime），无法一直等待任务。</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">timed</span> <span class="operator">=</span> allowCoreThreadTimeOut || wc &gt; corePoolSize;    </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 如果wc超过最大线程数 或者 当前线程会超时并且已经超时，</span></span><br><span class="line">        <span class="comment">// 并且wc &gt; 1 或者 工作队列为空，则返回null，代表当前Worker需要移除</span></span><br><span class="line">        <span class="keyword">if</span> ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))</span><br><span class="line">            &amp;&amp; (wc &gt; <span class="number">1</span> || workQueue.isEmpty())) &#123;   <span class="comment">// 确保有Worker可以移除 </span></span><br><span class="line">            <span class="keyword">if</span> (compareAndDecrementWorkerCount(c))</span><br><span class="line">                <span class="comment">// 返回null前将workerCount - 1，</span></span><br><span class="line">                <span class="comment">// 因此processWorkerExit中completedAbruptly＝false时无需再减</span></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">null</span>;    </span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 根据线程是否会超时调用相应的方法，poll为带超时的获取任务方法</span></span><br><span class="line">            <span class="comment">// take()为不带超时的获取任务方法，会一直阻塞直到获取到任务</span></span><br><span class="line">            <span class="type">Runnable</span> <span class="variable">r</span> <span class="operator">=</span> timed ? </span><br><span class="line">                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :</span><br><span class="line">                workQueue.take();</span><br><span class="line">            <span class="keyword">if</span> (r != <span class="literal">null</span>)</span><br><span class="line">                <span class="keyword">return</span> r;</span><br><span class="line">            timedOut = <span class="literal">true</span>;    <span class="comment">// 走到这代表当前线程获取任务超时</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException retry) &#123;</span><br><span class="line">            timedOut = <span class="literal">false</span>;   <span class="comment">// 被中断</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Worker从工作队列获取任务，如果allowCoreThreadTimeOut为false并且  workerCount&lt;=corePoolSize，则这些核心线程永远存活，并且一直在尝试获取工作队列的任务；否则，线程会有超时时间（keepAliveTime），当在keepAliveTime时间内获取不到任务，该线程的Worker会被移除。 <br>Worker移除的过程：getTask方法返回null，导致runWorker方法中跳出while循环，调用processWorkerExit方法将Worker移除。注意：在返回null的之前，已经将workerCount-1，因此在processWorkerExit中，completedAbruptly=false的情况（即正常超时退出）不需要再将workerCount-1。</p>
<h3 id="processWorkerExit方法"><a href="#processWorkerExit方法" class="headerlink" title="processWorkerExit方法"></a>processWorkerExit方法</h3><figure class="highlight processing"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">processWorkerExit</span>(Worker w, <span class="type">boolean</span> completedAbruptly) &#123;   <span class="comment">// Worker的退出</span></span><br><span class="line">    <span class="comment">// 如果Worker是异常死亡（completedAbruptly=true），则workerCount-1；</span></span><br><span class="line">    <span class="comment">// 如果completedAbruptly为false的时候（正常超时退出），则代表task=getTask()等于null，</span></span><br><span class="line">    <span class="comment">// getTask()方法中返回null的地方，都已经将workerCount - 1，所以此处无需再-1</span></span><br><span class="line">    <span class="keyword">if</span> (completedAbruptly) </span><br><span class="line">        <span class="title function_">decrementWorkerCount</span>();</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">final</span> ReentrantLock mainLock = <span class="variable">this</span>.<span class="property">mainLock</span>;</span><br><span class="line">    mainLock.<span class="property">lock</span>();    <span class="comment">// 加锁</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        completedTaskCount += w.<span class="property">completedTasks</span>; <span class="comment">// 该Worker完成的任务数加到总完成的任务数</span></span><br><span class="line">        workers.<span class="property">remove</span>(w);  <span class="comment">// 移除该Worker</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mainLock.<span class="property">unlock</span>();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="title function_">tryTerminate</span>(); <span class="comment">// 有Worker线程移除，可能是最后一个线程退出，需要尝试终止线程池</span></span><br><span class="line"> </span><br><span class="line">    <span class="type">int</span> c = ctl.<span class="property">get</span>();  <span class="comment">// 获取当前的ctl</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="title function_">runStateLessThan</span>(c, STOP)) &#123;  <span class="comment">// 如果线程池的运行状态还没停止（RUNNING或SHUTDOWN）</span></span><br><span class="line">        <span class="keyword">if</span> (!completedAbruptly) &#123;   <span class="comment">// 如果Worker不是异常死亡</span></span><br><span class="line">            <span class="comment">// min为线程池的理论最小线程数:如果允许核心线程超时则min为0,否则min为核心线程数</span></span><br><span class="line">            <span class="type">int</span> <span class="built_in">min</span> = allowCoreThreadTimeOut ? <span class="number">0</span> : corePoolSize;    </span><br><span class="line">            <span class="comment">// 如果min为0,工作队列不为空,将min设置为1,确保至少有1个Worker来处理队列里的任务 </span></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">min</span> == <span class="number">0</span> &amp;&amp; ! workQueue.<span class="property">isEmpty</span>())</span><br><span class="line">                <span class="built_in">min</span> = <span class="number">1</span>;</span><br><span class="line">            <span class="comment">// 当前有效的线程数&gt;=min，直接返回;</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="title function_">workerCountOf</span>(c) &gt;= <span class="built_in">min</span>)</span><br><span class="line">                <span class="keyword">return</span>; <span class="comment">// replacement not needed </span></span><br><span class="line">            <span class="comment">// 如果代码走到这边，代表workerCountOf(c) &lt; min，此时会走到下面的addWorker方法。</span></span><br><span class="line">            <span class="comment">// 通过getTask方法我们知道，当allowCoreThreadTimeOut为false</span></span><br><span class="line">            <span class="comment">// 并且workerCount&lt;=corePoolSize时，是不会走到processWorkerExit方法的。</span></span><br><span class="line">            <span class="comment">// 因此走到这边只可能是当前移除的Worker是最后一个Worker，但是此时工作</span></span><br><span class="line">            <span class="comment">// 队列还不为空，因此min被设置成了1，所以需要在添加一个Worker来处理工作队列。</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="title function_">addWorker</span>(<span class="literal">null</span>, <span class="literal">false</span>); <span class="comment">// 添加一个Worker</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法就是执行Worker的退出：统计完成的任务数，将Worker移除，并尝试终止线程池，最后根据情况决定是否创建一个新的Worker。两种情况下会创建一个新的Worker：1）被移除的Worker是由于异常而死亡；2）被移除的Worker是最后一个Worker，但是工作队列还有任务。completedAbruptly=false时，没有将workerCount-1是因为已经在getTask方法中将workerCount-1。</p>
<h3 id="tryTerminate方法"><a href="#tryTerminate方法" class="headerlink" title="tryTerminate方法"></a>tryTerminate方法</h3><figure class="highlight kotlin"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> void tryTerminate() &#123; <span class="comment">// 尝试终止线程池</span></span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        int c = ctl.<span class="keyword">get</span>();</span><br><span class="line">        <span class="comment">// 只有当前状态为STOP 或者 SHUTDOWN并且队列为空，才会尝试整理并终止</span></span><br><span class="line">        <span class="comment">// 1: 当前状态为RUNNING，则不尝试终止，直接返回</span></span><br><span class="line">        <span class="comment">// 2: 当前状态为TIDYING或TERMINATED，代表有其他线程正在执行终止，直接返回</span></span><br><span class="line">        <span class="comment">// 3: 当前状态为SHUTDOWN 并且 workQueue不为空，则不尝试终止，直接返回</span></span><br><span class="line">        <span class="keyword">if</span> (isRunning(c) || <span class="comment">// 1</span></span><br><span class="line">            runStateAtLeast(c, TIDYING) ||  <span class="comment">// 2</span></span><br><span class="line">            (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty()))   <span class="comment">// 3</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        <span class="comment">// 走到这代表线程池可以终止（通过上面的校验）</span></span><br><span class="line">        <span class="comment">// 如果此时有效线程数不为0， 将中断一个空闲的Worker，以确保关闭信号传播</span></span><br><span class="line">        <span class="keyword">if</span> (workerCountOf(c) != <span class="number">0</span>) &#123; <span class="comment">// Eligible to terminate </span></span><br><span class="line">            interruptIdleWorkers(ONLY_ONE);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">        mainLock.lock();    <span class="comment">// 加锁，终止线程池</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 使用CAS将ctl的运行状态设置为TIDYING，有效线程数设置为0</span></span><br><span class="line">            <span class="keyword">if</span> (ctl.compareAndSet(c, ctlOf(TIDYING, <span class="number">0</span>))) &#123;  </span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    terminated();   <span class="comment">// 供用户重写的terminated方法，默认为空</span></span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    <span class="comment">// 将ctl的运行状态设置为TERMINATED，有效线程数设置为0</span></span><br><span class="line">                    ctl.<span class="keyword">set</span>(ctlOf(TERMINATED, <span class="number">0</span>));  </span><br><span class="line">                    termination.signalAll();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            mainLock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// else retry on failed CAS</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法用来尝试终止线程池，主要在移除Worker后会调用此方法。首先进行一些状态的校验，如果通过校验，则在加锁的条件下，使用CAS将运行状态设为TERMINATED，有效线程数设为0。</p>
<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>本文完全参考<a href="https://blog.csdn.net/v123411739/article/details/79124193">https://blog.csdn.net/v123411739/article/details/79124193</a><br>不含一点原创知识，奥里给</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title>New Beginning</title>
    <url>/2021/04/02/blog-title/</url>
    <content><![CDATA[<hr>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前段时间忽然想给同事分享一下JDK1.8的源码，在准备学习的过程中顺便想着要不搭建下个人微博，说干就干！</p>
<span id="more"></span>

<h2 id="搭站"><a href="#搭站" class="headerlink" title="搭站"></a>搭站</h2><p>照着<a href="https://hexo.io/zh-cn/docs/">Hexo</a>文档;同时参考<a href="https://maxiang.io/#%E6%AC%A2%E8%BF%8E%E4%BD%BF%E7%94%A8%E9%A9%AC%E5%85%8B%E9%A3%9E%E8%B1%A1">Markdown</a></p>
<p>照着网上换了个<a href="https://link.jianshu.com/?t=https://github.com/iissnan/hexo-theme-next/releases">Next</a>主题</p>
<p>然后在一通乱搞</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo g</span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure>

<p>emmmm好像搞定了</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>搭建好啦，话说调字体这些真的很烦人</p>
<p>明天开始分析jdk1.8源码</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>搭站</tag>
      </tags>
  </entry>
  <entry>
    <title>线程池</title>
    <url>/2021/04/09/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url>
    <content><![CDATA[<hr>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>项目上经常用到线程池，是Java常用的一个东西，今天来总结下线程池的用法。</p>
<span id="more"></span>

<blockquote>
<p>为什么要使用线程池？直接new个线程不是很舒服？</p>
</blockquote>
<p>如果我们在方法中直接new一个线程来处理，当这个方法被调用频繁时就会创建很多线程，不仅会消耗系统资源，还会降低系统的稳定性，一不小心把系统搞崩了，就可以直接去财务那结帐了。</p>
<p>如果我们合理的使用线程池，则可以避免把系统搞崩的窘境。总得来说，使用线程池可以带来以下几个好处：</p>
<p>降低资源消耗。通过重复利用已创建的线程，降低线程创建和销毁造成的消耗。</p>
<p>提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。</p>
<p>增加线程的可管理型。线程是稀缺资源，使用线程池可以进行统一分配，调优和监控。</p>
<blockquote>
<p>线程池的核心属性有哪些？</p>
</blockquote>
<p>threadFactory（线程工厂）：用于创建工作线程的工厂。</p>
<p>corePoolSize（核心线程数）：当线程池运行的线程少于 corePoolSize 时，将创建一个新线程来处理请求，即使其他工作线程处于空闲状态。</p>
<p>workQueue（队列）：用于保留任务并移交给工作线程的阻塞队列。</p>
<p>maximumPoolSize（最大线程数）：线程池允许开启的最大线程数。</p>
<p>handler（拒绝策略）：往线程池添加任务时，将在下面两种情况触发拒绝策略：1）线程池运行状态不是 RUNNING；2）线程池已经达到最大线程数，并且阻塞队列已满时。</p>
<p>keepAliveTime（保持存活时间）：如果线程池当前线程数超过 corePoolSize，则多余的线程空闲时间超过 keepAliveTime 时会被终止。</p>
<blockquote>
<p>线程池的运作流程</p>
</blockquote>
<p>千言万语不如一张图：<br><img src="https://i.loli.net/2021/04/09/L9uUqX63V4wsOnj.png" alt="thread pool"></p>
<blockquote>
<p>线程池中的各个状态分别代表什么含义？</p>
</blockquote>
<p>线程池目前有5个状态：</p>
<p>RUNNING：接受新任务并处理排队的任务。</p>
<p>SHUTDOWN：不接受新任务，但处理排队的任务。</p>
<p>STOP：不接受新任务，不处理排队的任务，并中断正在进行的任务。</p>
<p>TIDYING：所有任务都已终止，workerCount 为零，线程转换到 TIDYING 状态将运行 terminated() 钩子方法。</p>
<p>TERMINATED：terminated() 已完成。</p>
<blockquote>
<p>这几个状态之间是怎么流转的？</p>
</blockquote>
<p><img src="https://i.loli.net/2021/04/09/a6SnvlGQiHXZAYh.png" alt="thread pool2"></p>
<blockquote>
<p>线程池有哪些队列？</p>
</blockquote>
<p>常见的阻塞队列有以下几种：</p>
<p>ArrayBlockingQueue：基于数组结构的有界阻塞队列，按先进先出对元素进行排序。</p>
<p>LinkedBlockingQueue：基于链表结构的有界/无界阻塞队列，按先进先出对元素进行排序，吞吐量通常高于 ArrayBlockingQueue。Executors.newFixedThreadPool 使用了该队列。</p>
<p>SynchronousQueue：不是一个真正的队列，而是一种在线程之间移交的机制。要将一个元素放入 SynchronousQueue 中，必须有另一个线程正在等待接受这个元素。如果没有线程等待，并且线程池的当前大小小于最大值，那么线程池将创建一个线程，否则根据拒绝策略，这个任务将被拒绝。使用直接移交将更高效，因为任务会直接移交给执行它的线程，而不是被放在队列中，然后由工作线程从队列中提取任务。只有当线程池是无界的或者可以拒绝任务时，该队列才有实际价值。Executors.newCachedThreadPool使用了该队列。</p>
<p>PriorityBlockingQueue：具有优先级的无界队列，按优先级对元素进行排序。元素的优先级是通过自然顺序或 Comparator 来定义的。</p>
<blockquote>
<p>使用队列有什么需要注意</p>
</blockquote>
<p>使用有界队列时，需要注意线程池满了后，被拒绝的任务如何处理。</p>
<p>使用无界队列时，需要注意如果任务的提交速度大于线程池的处理速度，可能会导致内存溢出。</p>
<blockquote>
<p>线程池有哪些拒绝策略</p>
</blockquote>
<p>常见的有以下几种：</p>
<p>AbortPolicy：中止策略。默认的拒绝策略，直接抛出 RejectedExecutionException。调用者可以捕获这个异常，然后根据需求编写自己的处理代码。</p>
<p>DiscardPolicy：抛弃策略。什么都不做，直接抛弃被拒绝的任务。</p>
<p>DiscardOldestPolicy：抛弃最老策略。抛弃阻塞队列中最老的任务，相当于就是队列中下一个将要被执行的任务，然后重新提交被拒绝的任务。如果阻塞队列是一个优先队列，那么“抛弃最旧的”策略将导致抛弃优先级最高的任务，因此最好不要将该策略和优先级队列放在一起使用。</p>
<p>CallerRunsPolicy：调用者运行策略。在调用者线程中执行该任务。该策略实现了一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是将任务回退到调用者（调用线程池执行任务的主线程），由于执行任务需要一定时间，因此主线程至少在一段时间内不能提交任务，从而使得线程池有时间来处理完正在执行的任务。</p>
<blockquote>
<p>线程只能在任务到达时才启动吗？</p>
</blockquote>
<p>默认情况下，即使是核心线程也只能在新任务到达时才创建和启动。但是我们可以使用 prestartCoreThread（启动一个核心线程）或 prestartAllCoreThreads（启动全部核心线程）方法来提前启动核心线程。</p>
<blockquote>
<p>核心线程怎么实现一直存活？</p>
</blockquote>
<p>阻塞队列方法有四种形式，它们以不同的方式处理操作，如下表。<br><img src="https://i.loli.net/2021/04/09/BPk2qrvVnJGQUub.png" alt="thread pool3"></p>
<p>核心线程在获取任务时，通过阻塞队列的 take() 方法实现的一直阻塞（存活）。</p>
<blockquote>
<p>非核心线程如何实现在 keepAliveTime 后死亡？</p>
</blockquote>
<p>原理同上，也是利用阻塞队列的方法，在获取任务时通过阻塞队列的 poll(time,unit) 方法实现的在延迟死亡。</p>
<blockquote>
<p>非核心线程能成为核心线程吗？</p>
</blockquote>
<p>虽然我们一直讲着核心线程和非核心线程，但是其实线程池内部是不区分核心线程和非核心线程的。只是根据当前线程池的工作线程数来进行调整，因此看起来像是有核心线程于非核心线程。</p>
<blockquote>
<p>如何终止线程池？</p>
</blockquote>
<p>终止线程池主要有两种方式：</p>
<p>shutdown：“温柔”的关闭线程池。不接受新任务，但是在关闭前会将之前提交的任务处理完毕。</p>
<p>shutdownNow：“粗暴”的关闭线程池，也就是直接关闭线程池，通过 Thread#interrupt() 方法终止所有线程，不会等待之前提交的任务执行完毕。但是会返回队列中未处理的任务。</p>
<blockquote>
<p>Executors 提供了哪些创建线程池的方法？</p>
</blockquote>
<p>newFixedThreadPool：固定线程数的线程池。corePoolSize = maximumPoolSize，keepAliveTime为0，工作队列使用无界的LinkedBlockingQueue。适用于为了满足资源管理的需求，而需要限制当前线程数量的场景，适用于负载比较重的服务器。</p>
<p>newSingleThreadExecutor：只有一个线程的线程池。corePoolSize = maximumPoolSize = 1，keepAliveTime为0， 工作队列使用无界的LinkedBlockingQueue。适用于需要保证顺序的执行各个任务的场景。</p>
<p>newCachedThreadPool： 按需要创建新线程的线程池。核心线程数为0，最大线程数为 Integer.MAX_VALUE，keepAliveTime为60秒，工作队列使用同步移交 SynchronousQueue。该线程池可以无限扩展，当需求增加时，可以添加新的线程，而当需求降低时会自动回收空闲线程。适用于执行很多的短期异步任务，或者是负载较轻的服务器。</p>
<p>newScheduledThreadPool：创建一个以延迟或定时的方式来执行任务的线程池，工作队列为 DelayedWorkQueue。适用于需要多个后台线程执行周期任务。</p>
<p>newWorkStealingPool：JDK 1.8 新增，用于创建一个可以窃取的线程池，底层使用 ForkJoinPool 实现。</p>
<blockquote>
<p>线程池里有个 ctl，你知道它是如何设计的吗</p>
</blockquote>
<p>ctl 是一个打包两个概念字段的原子整数。</p>
<p>1）workerCount：指示线程的有效数量；</p>
<p>2）runState：指示线程池的运行状态，有 RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED 等状态。</p>
<p>int 类型有32位，其中 ctl 的低29为用于表示 workerCount，高3位用于表示 runState，如下图所示。<br><img src="https://i.loli.net/2021/04/09/zAaGlNbgi62n7fF.png" alt="thread pool4"></p>
<blockquote>
<p>ctl 为什么这么设计？有什么好处吗？</p>
</blockquote>
<p>个人认为，ctl 这么设计的主要好处是将对 runState 和 workerCount 的操作封装成了一个原子操作。</p>
<p>runState 和 workerCount 是线程池正常运转中的2个最重要属性，线程池在某一时刻该做什么操作，取决于这2个属性的值。</p>
<p>因此无论是查询还是修改，我们必须保证对这2个属性的操作是属于“同一时刻”的，也就是原子操作，否则就会出现错乱的情况。如果我们使用2个变量来分别存储，要保证原子性则需要额外进行加锁操作，这显然会带来额外的开销，而将这2个变量封装成1个 AtomicInteger 则不会带来额外的加锁开销，而且只需使用简单的位操作就能分别得到 runState 和 workerCount。</p>
<p>由于这个设计，workerCount 的上限 CAPACITY   = (1 &lt;&lt; 29) - 1，对应的二进制原码为：0001 1111 1111 1111 1111 1111 1111 1111（不用数了，29个1）。</p>
<p>通过 ctl 得到 runState，只需通过位操作：ctl &amp; ~CAPACITY。</p>
<p><del>（按位取反），于是“</del>CAPACITY”的值为：1110 0000 0000 0000 0000 0000 0000 0000，只有高3位为1，与 ctl 进行 &amp; 操作，结果为 ctl 高3位的值，也就是 runState。</p>
<p>通过 ctl 得到 workerCount 则更简单了，只需通过位操作：c &amp; CAPACITY。</p>
<blockquote>
<p>小伙子不错不错，那我最后问一个，在我们实际使用中，线程池的大小配置多少合适？</p>
</blockquote>
<p>要想合理的配置线程池大小，首先我们需要区分任务是计算密集型还是I/O密集型。</p>
<p>对于计算密集型，设置 线程数 = CPU数 + 1，通常能实现最优的利用率。</p>
<p>对于I/O密集型，网上常见的说法是设置 线程数 = CPU数 * 2 ，这个做法是可以的，但个人觉得不是最优的。</p>
<p>在我们日常的开发中，我们的任务几乎是离不开I/O的，常见的网络I/O（RPC调用）、磁盘I/O（数据库操作），并且I/O的等待时间通常会占整个任务处理时间的很大一部分，在这种情况下，开启更多的线程可以让 CPU 得到更充分的使用，一个较合理的计算公式如下：</p>
<p>线程数 = CPU数 * CPU利用率 * (任务等待时间 / 任务计算时间 + 1)</p>
<p>例如我们有个定时任务，部署在4核的服务器上，该任务有100ms在计算，900ms在I/O等待，则线程数约为：4 * 1 * (1 + 900 / 100) = 40个。</p>
<p>当然，具体我们还要结合实际的使用场景来考虑。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title>随笔</title>
    <url>/2024/08/29/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94/</url>
    <content><![CDATA[<p>帅逼镇楼<br><img src="/images/20240903-01.jpg" alt="图片1"></p>
<p>最近团队要搭建文档中心，使用gitbook研究了下忽然想起自己还有一个被遗忘的博客。访问了下三年前部署的博客现在还能正常运行，这里不得不给github点个赞。翻了下以前自己的技术文章，有所庆幸自己比三年前还是成长了很多。</p>
<p>思来想去觉得还是有必要用文字记录一下生活和工作，在这里立一个flag，以后保持周更，持续半年。</p>
<h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><p>三年前和老婆一起到长沙，两个人就开始吃吃吃，每天晚上煲汤喝，周末各种糖食饮料大杂烩，然后血脂、脂肪肝、甘油酸脂全部来了。。。以前听说过中年幸福肥，之前还不信，现在明白了和爱的人在一起后，的确容易变胖（她吃不完的我是真得吃啊）</p>
<p>和老婆在一起在长沙已经三年啦，每天上班下班过着重复的日子，可因为有她每天都觉得充满意义。在去年年底一起把婚结了，人生一大重要任务完成。</p>
<h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><p>从回长沙后就一直呆在三一了，三一给人整体感觉就是工作强度贼大，但是很多时候是做的无用功，有一种为了加班而加班的感觉，中间知道了有加班时长，我常年倒数一二，中间动了几次想走的念头，不过长沙不得不说是互联网荒漠，没有其他的公司能给的比三一多了，再加上当前领导的确挺有人格魅力的，就还是好好三一呆着了。</p>
<p>最近一年整个经济环境不好，互联网裁员裁的厉害，三一今年也裁了60%了，听说还需要裁掉剩下的50%。希望能领到一个大礼包，可以空出些时间去外面玩玩，很久没陪老婆去旅游了</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>最近奶奶生病了，脑梗。周末回去看她，感觉硬朗的老人一下子变得好憔悴，很心疼。奶奶目前左半边用不了力气，不过可以看出奶奶在积极的对待这件事，自己在病床上一直在活动自己的左边身体，希望经过治疗后奶奶能康复如初。</p>
<p>最近也有点感悟。第一要保持自己身体健康，第二要好好照顾家人，第三才是把工作做好。以后也会按照这个方式执行下去。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>缓存使用：如何保证数据一致性、缓存设计模式</title>
    <url>/2021/04/28/redis/%E7%BC%93%E5%AD%98%E4%BD%BF%E7%94%A8%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E3%80%81%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>缓存使用在现在的项目中非常常见，缓存在为我们带来便利的同时，也会带来一些常见的问题，如果不谨慎使用，可能会带来意想不到的结果。</p>
<p>面试中，缓存使用带来的各种问题也是面试官喜欢考察的点，今天我将跟大家一起探讨以下几个常见的问题：</p>
<blockquote>
<p>如何保证数据库和缓存的数据一致性？<br> 先操作数据库 or 先操作缓存？<br> 失效缓存 or 更新缓存？<br> 缓存的常见设计模式有哪些？</p>
</blockquote>
<span id="more"></span>

<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="缓存查询通用流程"><a href="#缓存查询通用流程" class="headerlink" title="缓存查询通用流程"></a>缓存查询通用流程</h3><p><img src="https://i.loli.net/2021/04/28/FxWlkwTbHpvcC5J.png" alt="1"></p>
<p>这个缓存查询流程相信大家都不陌生，这应该是目前应用最广的缓存查询流程。<br>但是大部分人可能不知道，这个流程其实有一个名字：Cache Aside Pattern，这是缓存设计模式的一种。<br>上图是 Cache Aside Pattern 的查询流程，而更新流程如下。<br><img src="https://i.loli.net/2021/04/28/6zPkSiXGuNMoIdQ.png" alt="2"></p>
<p>这个更新流程会引出两个问题：<br>1）为什么是先操作数据库，可以先操作缓存吗？<br>2）为什么是失效缓存，可以更新缓存吗？<br>接下来我们一一分析。</p>
<h3 id="先操作数据库-or-先操作缓存"><a href="#先操作数据库-or-先操作缓存" class="headerlink" title="先操作数据库 or 先操作缓存"></a>先操作数据库 or 先操作缓存</h3><p>先操作数据库<br>案例如下，有两个并发的请求，一个写请求，一个读请求，流程如下：<br><img src="https://i.loli.net/2021/04/28/bsT8tD35qxC2QHc.png" alt="3"><br>脏数据时间范围：更新数据库后，失效缓存前。这个时间范围很小，通常不会超过几毫秒。</p>
<p>先操作缓存<br>案例如下，有两个并发的请求，一个写请求，一个读请求，流程如下：<br><img src="https://i.loli.net/2021/04/28/zSQNUincFBLm6ax.png" alt="4"><br>脏数据时间范围：更新数据库后，下一次对该数据的更新前。这个时间范围不确定性很大，情况如下：<br>1）如果下一次对该数据的更新马上就到来，那么会失效缓存，脏数据的时间就很短。</p>
<p>2）如果下一次对该数据的更新要很久才到来，那这期间缓存保存的一直是脏数据，时间范围很长。</p>
<p>结论：通过上述案例可以看出，先操作数据库和先操作缓存都会存在脏数据的情况。但是相比之下，先操作数据库，再操作缓存是更优的方式，即使在并发极端情况下，也只会出现很小量的脏数据。</p>
<h3 id="失效缓存-or-更新缓存"><a href="#失效缓存-or-更新缓存" class="headerlink" title="失效缓存 or 更新缓存"></a>失效缓存 or 更新缓存</h3><p>更新缓存<br>案例如下，有两个并发的写请求，流程如下：<br><img src="https://i.loli.net/2021/04/28/g6aCTFuixeH3GcD.png" alt="5"><br>分析：数据库中的数据是请求B的，缓存中的数据是请求A的，数据库和缓存存在数据不一致。</p>
<p>失效缓存<br>案例如下，有两个并发的写请求，流程如下：<br><img src="https://i.loli.net/2021/04/28/5imrc4nexJR9PSh.png" alt="6"><br>分析：由于是删除缓存，所以不存在数据不一致的情况。</p>
<p>结论：通过上述案例，可以很明显的看出，失效缓存是更优的方式。</p>
<h3 id="如何保证数据库和缓存的数据一致性"><a href="#如何保证数据库和缓存的数据一致性" class="headerlink" title="如何保证数据库和缓存的数据一致性"></a>如何保证数据库和缓存的数据一致性</h3><p>在上文的案例中，无论是先操作数据库，还是先操作缓存，都会存在脏数据的情况，有办法避免吗？<br>答案是有的，由于数据库和缓存是两个不同的数据源，要保证其数据一致性，其实就是典型的分布式事务场景，可以引入分布式事务来解决，常见的有：2PC、TCC、MQ事务消息等。</p>
<p>但是引入分布式事务必然会带来性能上的影响，这与我们当初引入缓存来提升性能的目的是相违背的。</p>
<p>所以在实际使用中，通常不会去保证缓存和数据库的强一致性，而是做出一定的牺牲，保证两者数据的最终一致性。</p>
<p>如果是实在无法接受脏数据的场景，则比较合理的方式是放弃使用缓存，直接走数据库。</p>
<p>保证数据库和缓存数据最终一致性的常用方案如下：<br>1）更新数据库，数据库产生 binlog。</p>
<p>2）监听和消费 binlog，执行失效缓存操作。</p>
<p>3）如果步骤2失效缓存失败，则引入重试机制，将失败的数据通过MQ方式进行重试，同时考虑是否需要引入幂等机制。<br><img src="https://i.loli.net/2021/04/28/PAbvjX3dMT7l5FL.png" alt="7"><br>兜底：当出现未知的问题时，及时告警通知，人为介入处理。</p>
<p>人为介入是终极大法，那些外表看着光鲜艳丽的应用，其背后大多有一群苦逼的程序员，在不断的修复各种脏数据和bug。<br>上文我们聊到了缓存设计模式中的 Cache Aside，并对常见的问题进行了延伸。<br>接着，我们来聊下缓存设计模式的其他几种：Read Through、Write Through、Write Behind Caching。</p>
<h3 id="Read-Write-Through"><a href="#Read-Write-Through" class="headerlink" title="Read/Write Through"></a>Read/Write Through</h3><p>在 Cache Aside 中，应用层需要和两个数据源打交道：缓存、数据库，这增加了 应用层的复杂度，能否只和一个数据源打交道？</p>
<p>Read/Write Through 就是用来解决这个问题的，该模式下应用层只和缓存打交道，由缓存去操作和维护数据库。</p>
<p>该模式会让应用层变得更加简单，同时代码也会更简洁。</p>
<h4 id="Read-Through"><a href="#Read-Through" class="headerlink" title="Read Through"></a>Read Through</h4><p>应用层查询数据时，当缓存未命中时，由缓存去查询数据库，并且将结果写入缓存中，最后返回结果给应用层。<br><img src="https://i.loli.net/2021/04/28/tmLy1V3bolDH4JP.png" alt="8"></p>
<h4 id="Write-Through"><a href="#Write-Through" class="headerlink" title="Write Through"></a>Write Through</h4><p>应用层更新数据时，由缓存去更新数据库。同时，当缓存命中时，写缓存和写数据库需要同步控制，保证同时成功。<br><img src="https://i.loli.net/2021/04/28/OhRIjPGVHYZSBMN.png" alt="9"></p>
<h3 id="Write-Behind-Caching"><a href="#Write-Behind-Caching" class="headerlink" title="Write Behind Caching"></a>Write Behind Caching</h3><p>Write Behind 又称为 Write Back，从应用层的视角来看和 Write Through 类似，在该模式下，应用层也是只需要和缓存一个数据源打交道，不同点在于：</p>
<p>Write Through 会立刻把数据同步写入数据库中，这样做的优点是操作简单，缺点是数据修改需要同时写入数据库，数据写入速度会比较慢。</p>
<p>Write Behind 会在一段时间之后异步的把数据批量写入数据库，这样的做的优点是：1）应用层操作只写缓存，应用层会觉得操作飞快无比；2）缓存在异步的写入数据库时，会将多个 I/O 操作合并成一个，减少 I/O 次数。</p>
<p>缺点是：1）复杂度高；2）更新后的数据还未写入数据库时，如果此时出现系统断电的情况，数据将无法找回。</p>
<p>Write Behind 的核心流程图如下：<br><img src="https://i.loli.net/2021/04/28/HksJ9fdGEjIvPMh.png" alt="10"></p>
<p>Write Back 缓存模式由于其复杂性比较高，所以在业务应用中使用的比较少，但是由于其带来的性能提升，还是有不少优秀的软件采用了该设计模式，例如：linux 中的页缓存、MySQL 中的 InnoDB 存储引擎。<br>linux 中的 page cache（页缓存）采用的就是 write back 机制：用户 write 时只是将数据写到 page cache，并标记为 dirty，并没有真正写到硬盘上 。内核在某个时刻会将 page cache 里的 dirty 数据 wirteback 到硬盘上。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>缓存穿透、缓存击穿、缓存雪崩解决方案</title>
    <url>/2021/04/29/redis/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天来了解下Redis的缓存穿透、缓存击穿、缓存雪崩内容</p>
<span id="more"></span>

<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>描述：访问一个缓存和数据库都不存在的 key，此时会直接打到数据库上，并且查不到数据，没法写缓存，所以下一次同样会打到数据库上。</p>
<p>此时，缓存起不到作用，请求每次都会走到数据库，流量大时数据库可能会被打挂。此时缓存就好像被“穿透”了一样，起不到任何作用。</p>
<p>解决方案：<br>1、接口校验。在正常业务流程中可能会存在少量访问不存在 key 的情况，但是一般不会出现大量的情况，所以这种场景最大的可能性是遭受了非法攻击。可以在最外层先做一层校验：用户鉴权、数据合法性校验等，例如商品查询中，商品的ID是正整数，则可以直接对非正整数直接过滤等等。</p>
<p>2、缓存空值。当访问缓存和DB都没有查询到值时，可以将空值写进缓存，但是设置较短的过期时间，该时间需要根据产品业务特性来设置。</p>
<p>3、布隆过滤器。使用布隆过滤器存储所有可能访问的 key，不存在的 key 直接被过滤，存在的 key 则再进一步查询缓存和数据库。</p>
<h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>布隆过滤器的特点是判断不存在的，则一定不存在；判断存在的，大概率存在，但也有小概率不存在。并且这个概率是可控的，我们可以让这个概率变小或者变高，取决于用户本身的需求。</p>
<p>布隆过滤器由一个 bitSet 和 一组 Hash 函数（算法）组成，是一种空间效率极高的概率型算法和数据结构，主要用来判断一个元素是否在集合中存在。</p>
<p>在初始化时，bitSet 的每一位被初始化为0，同时会定义 Hash 函数，例如有3组 Hash 函数：hash1、hash2、hash3。</p>
<p>写入流程<br>当我们要写入一个值时，过程如下，以“jionghui”为例：</p>
<p>1）首先将“jionghui”跟3组 Hash 函数分别计算，得到 bitSet 的下标为：1、7、10。</p>
<p>2）将 bitSet 的这3个下标标记为1。</p>
<p>假设我们还有另外两个值：java 和 diaosi，按上面的流程跟 3组 Hash 函数分别计算，结果如下：</p>
<p>java：Hash 函数计算 bitSet 下标为：1、7、11</p>
<p>diaosi：Hash 函数计算  bitSet 下标为：4、10、11<br><img src="https://i.loli.net/2021/04/29/qMPiaSztOyBoI97.png" alt="1"></p>
<p>查询流程<br>当我们要查询一个值时，过程如下，同样以“jionghui”为例：</p>
<p>1）首先将“jionghui”跟3组 Hash 函数分别计算，得到 bitSet 的下标为：1、7、10。</p>
<p>2）查看 bitSet 的这3个下标是否都为1，如果这3个下标不都为1，则说明该值必然不存在，如果这3个下标都为1，则只能说明可能存在，并不能说明一定存在。</p>
<p>其实上图的例子已经说明了这个问题了，当我们只有值“jionghui”和“diaosi”时，bitSet 下标为1的有：1、4、7、10、11。</p>
<p>当我们又加入值“java”时，bitSet 下标为1的还是这5个，所以当 bitSet 下标为1的为：1、4、7、10、11 时，我们无法判断值“java”存不存在。</p>
<p>其根本原因是，不同的值在跟 Hash 函数计算后，可能会得到相同的下标，所以某个值的标记位，可能会被其他值给标上了。</p>
<p>这也是为啥布隆过滤器只能判断某个值可能存在，无法判断必然存在的原因。但是反过来，如果该值根据 Hash 函数计算的标记位没有全部都为1，那么则说明必然不存在，这个是肯定的。</p>
<p>降低这种误判率的思路也比较简单：<br>1）一个是加大 bitSet 的长度，这样不同的值出现“冲突”的概率就降低了，从而误判率也降低。</p>
<p>2）提升 Hash 函数的个数，Hash 函数越多，每个值对应的 bit 越多，从而误判率也降低。</p>
<p>布隆过滤器的误判率还有专门的推导公式，有兴趣的可以去搜相关的文章和论文查看。</p>
<h3 id="HashMap-和-布隆过滤器"><a href="#HashMap-和-布隆过滤器" class="headerlink" title="HashMap 和 布隆过滤器"></a>HashMap 和 布隆过滤器</h3><p>估计有同学看了上面的例子，会觉得使用 HashMap 也能实现。<br>确实，当数据量不大时，HashMap 实现起来一点问题都没有，而且还没有误判率，简直完美，还要个鸡儿布隆过滤器。<br>不过，当数据量上去后，布隆过滤器的空间优势就会开始体现，特别是要存储的 key 占用空间越大，布隆过滤器的优势越明显。<br>Guava 中的 BloomFilter 在默认情况下，误判率接近3%，大概要使用5个 Hash 函数。<br>也就是说一个 key 最多占用空间就是 5 bit，而且当多个 key 填充同一个 bit 时，会进一步降低使用空间。<br>布隆过滤器占用多少空间，主要取决于 Hash 函数的个数，跟 key 本身的大小无关，这使得其在空间的优势非常大。</p>
<h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>描述：某一个热点 key，在缓存过期的一瞬间，同时有大量的请求打进来，由于此时缓存过期了，所以请求最终都会走到数据库，造成瞬时数据库请求量大、压力骤增，甚至可能打垮数据库。</p>
<p>解决方案：<br>1、加互斥锁。在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。</p>
<p>关于互斥锁的选择，网上看到的大部分文章都是选择 Redis 分布式锁（可以参考我之前的文章：面试必问的分布式锁，你懂了吗？），因为这个可以保证只有一个请求会走到数据库，这是一种思路。</p>
<p>但是其实仔细想想的话，这边其实没有必要保证只有一个请求走到数据库，只要保证走到数据库的请求能大大降低即可，所以还有另一个思路是 JVM 锁。</p>
<p>JVM 锁保证了在单台服务器上只有一个请求走到数据库，通常来说已经足够保证数据库的压力大大降低，同时在性能上比分布式锁更好。</p>
<p>需要注意的是，无论是使用“分布式锁”，还是“JVM 锁”，加锁时要按 key 维度去加锁。<br> <br>我看网上很多文章都是使用一个“固定的 key”加锁，这样会导致不同的 key 之间也会互相阻塞，造成性能严重损耗。</p>
<p>使用 redis 分布式锁的伪代码，仅供参考：</p>
<figure class="highlight processing"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="built_in">Object</span> <span class="title function_">getData</span>(<span class="built_in">String</span> <span class="built_in">key</span>) <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    <span class="built_in">Object</span> value = redis.<span class="property">get</span>(<span class="built_in">key</span>);</span><br><span class="line">    <span class="comment">// 缓存值过期</span></span><br><span class="line">    <span class="keyword">if</span> (value == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// lockRedis：专门用于加锁的redis；</span></span><br><span class="line">        <span class="comment">// &quot;empty&quot;：加锁的值随便设置都可以</span></span><br><span class="line">        <span class="keyword">if</span> (lockRedis.<span class="property">set</span>(<span class="built_in">key</span>, <span class="string">&quot;empty&quot;</span>, <span class="string">&quot;PX&quot;</span>, lockExpire, <span class="string">&quot;NX&quot;</span>)) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 查询数据库，并写到缓存，让其他线程可以直接走缓存</span></span><br><span class="line">                value = <span class="title function_">getDataFromDb</span>(<span class="built_in">key</span>);</span><br><span class="line">                redis.<span class="property">set</span>(<span class="built_in">key</span>, value, <span class="string">&quot;PX&quot;</span>, expire);</span><br><span class="line">            &#125; <span class="title function_">catch</span> (Exception e) &#123;</span><br><span class="line">                <span class="comment">// 异常处理</span></span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                <span class="comment">// 释放锁</span></span><br><span class="line">                lockRedis.<span class="property">delete</span>(<span class="built_in">key</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// sleep50ms后，进行重试</span></span><br><span class="line">            Thread.<span class="property">sleep</span>(<span class="number">50</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="title function_">getData</span>(<span class="built_in">key</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2、热点数据不过期。直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。</p>
<p>这种方式适用于比较极端的场景，例如流量特别特别大的场景，使用时需要考虑业务能接受数据不一致的时间，还有就是异常情况的处理，不要到时候缓存刷新不上，一直是脏数据，那就凉了。</p>
<h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>描述：大量的热点 key 设置了相同的过期时间，导在缓存在同一时刻全部失效，造成瞬时数据库请求量大、压力骤增，引起雪崩，甚至导致数据库被打挂。</p>
<p>缓存雪崩其实有点像“升级版的缓存击穿”，缓存击穿是一个热点 key，缓存雪崩是一组热点 key。</p>
<p>解决方案：<br>1、过期时间打散。既然是大量缓存集中失效，那最容易想到就是让他们不集中生效。可以给缓存的过期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。</p>
<p>2、热点数据不过期。该方式和缓存击穿一样，也是要着重考虑刷新的时间间隔和数据异常如何处理的情况。</p>
<p>3、加互斥锁。该方式和缓存击穿一样，按 key 维度加锁，对于同一个 key，只允许一个线程去计算，其他线程原地阻塞等待第一个线程的计算结果，然后直接走缓存即可。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>面试必问的 Redis：主从复制</title>
    <url>/2021/04/25/redis/%E9%9D%A2%E8%AF%95%E5%BF%85%E9%97%AE%E7%9A%84-Redis%EF%BC%9A%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在分布式环境中，数据副本 (Replica) 和复制 (Replication) 作为提升系统可用性和读写性能的有效手段被大量应用在各种分布式系统中，Redis 也不例外。</p>
<p>虽说现在基本不会直接使用主从复制来作为 Redis 的高可用方案，但是无论是哨兵还是集群，都会使用到主从复制，因此，有必要先学习下主从复制的原理。</p>
<span id="more"></span>

<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="主从复制实现原理"><a href="#主从复制实现原理" class="headerlink" title="主从复制实现原理"></a>主从复制实现原理</h3><p>在当前最新的 Redis 6.0 中，主从复制的完整过程如下：</p>
<h4 id="开启主从复制"><a href="#开启主从复制" class="headerlink" title="开启主从复制"></a>开启主从复制</h4><p>通常有以下三种方式：<br>1）在 slave 直接执行命令：slaveof <masterip> <masterport><br>2）在 slave 配置文件中加入：slaveof <masterip> <masterport><br>3）使用启动命令：–slaveof <masterip> <masterport></p>
<p>注：在 Redis 5.0 之后，slaveof 相关命令和配置已经被替换成 replicaof，例如 replicaof <masterip> <masterport>。为了兼容旧版本，通过配置的方式仍然支持 slaveof，但是通过命令的方式则不行了。</p>
<h4 id="建立套接字（socket）连接"><a href="#建立套接字（socket）连接" class="headerlink" title="建立套接字（socket）连接"></a>建立套接字（socket）连接</h4><p>slave 将根据指定的 IP 地址和端口，向 master 发起套接字（socket）连接，master 在接受（accept） slave 的套接字连接之后，为该套接字创建相应的客户端状态，此时连接建立完成。</p>
<h4 id="发送PING命令"><a href="#发送PING命令" class="headerlink" title="发送PING命令"></a>发送PING命令</h4><p>slave 向 master 发送一个 PING 命令，以检査套接字的读写状态是否正常、 master 能否正常处理命令请求。</p>
<p>如果 slave 收到 “PONG” 回复，那么表示 master 和 slave 之间的网络连接状态正常， 并且 master 可以正常处理命令请求。</p>
<p>如果是其他回复或者没有回复，表示 master 和 slave 之间的网络连接状态不佳或者 master 暂时没办法处理 slave 的命令请求，则 slave 进入 error 流程：slave 断开当前的连接，之后再进行重试。</p>
<h4 id="身份验证"><a href="#身份验证" class="headerlink" title="身份验证"></a>身份验证</h4><p>如果 master 和 slave 都没有设置密码，则无需验证。</p>
<p>如果 master 和 slave 都设置了密码，并且密码相同，则验证成功。</p>
<p>否则，master 和 slave 设置的密码不同、master 和 slave 一个设置密码一个没设置密码都会返回错误。</p>
<p>所有错误情况都会令 slave 进入 error 流程：slave 断开当前的连接，之后再进行重试。</p>
<h4 id="发送端口信息"><a href="#发送端口信息" class="headerlink" title="发送端口信息"></a>发送端口信息</h4><p>在身份验证通过后后， slave 将向 master 发送自己的监听端口号， master 收到后记录在 slave 所对应的客户端状态的 slave_listening_port 属性中。</p>
<h4 id="发送IP地址"><a href="#发送IP地址" class="headerlink" title="发送IP地址"></a>发送IP地址</h4><p>如果配置了 slave_announce_ip，则 slave 向 master 发送 slave_announce_ip 配置的 IP 地址， master 收到后记录在 slave 所对应的客户端状态的 slave_ip 属性。</p>
<p>该配置是用于解决服务器返回内网 IP 时，其他服务器无法访问的情况。可以通过该配置直接指定公网 IP。</p>
<h4 id="发送CAPA"><a href="#发送CAPA" class="headerlink" title="发送CAPA"></a>发送CAPA</h4><p>CAPA 全称是 capabilities，这边表示的是同步复制的能力。</p>
<p>slave 会在这一阶段发送 capa 告诉 master 自己具备的（同步）复制能力， master 收到后记录在 slave 所对应的客户端状态的 slave_capa 属性。</p>
<p>CAPA 在最新的 Redis 6.0 版本中有两种值：eof 和 psync2。<br> <br>eof 表示 slave 支持直接接收从 socket 发送过来的 RDB 数据流，也就是无盘加载（diskless_load）。</p>
<p>psync2 表示 slave 支持 Redis 4.0 引入的部分重同步 v2 版本，这个在下文会详细介绍。</p>
<h4 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h4><p>slave 将向 master 发送 PSYNC 命令， master 收到该命令后判断是进行部分重同步还是完整重同步，然后根据策略进行数据的同步</p>
<p>1）如果是 slave 第一次执行复制，则向 master 发送 PSYNC ? -1， master 返回 +FULLRESYNC <replid> <offset> 执行完整重同步</p>
<p>2）如果不是第一次执行复制，则向 master 发送 PSYNC replid offset，其中 replid 是 master 的复制 ID，而 offset 是 slave 当前的复制偏移量。master 根据 replid 和 offset 来判断应该执行哪种同步操作。</p>
<p>如果是完整重同步，则返回 +FULLRESYNC <replid> <offset>；如果是部分重同步，则返回 +CONTINUE <replid>，此时 slave 只需等待 master 将自己缺少的数据发送过来就可以。</p>
<h4 id="命令传播"><a href="#命令传播" class="headerlink" title="命令传播"></a>命令传播</h4><p>当完成了同步之后，就会进人命令传播阶段，这时 master 只要一直将自己执行的写命令发送给 slave ，而 slave 只要一直接收并执行 master 发来的写命令，就可以保证 master 和 slave 一直保持一致了。</p>
<p>在命令传播阶段， slave 默认会以每秒一次的频率，向 master 发送命令：REPLCONF ACK <reploff>，其中 reploff 是 slave 当前的复制偏移量。</p>
<p>发送REPLCONF ACK 命令对于主从服务器有三个作用：</p>
<p>1）检测 master 和 slave 的网络连接状态。</p>
<p>2）汇报自己的复制偏移量，检测命令丢失，master 会对比复制偏移量，如果发现 slave 的复制偏移量小于自己，会向 slave 发送未同步的数据。</p>
<p>3）辅助实现 min-slaves 配置，用于防止 master 在不安全的情况下执行写命令。</p>
<p>例如以下配置表示：当延迟时间小于10秒的 slave 数量小于3个，则会拒绝执行写命令。而这边的延迟时间，就是以 slave 最近一次发送 ACK 时间和当前时间作对比。</p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line"><span class="built_in">min</span>-slaves-<span class="built_in">to</span>-<span class="built_in">write</span> <span class="number">3</span></span><br><span class="line"><span class="built_in">min</span>-slaves-<span class="built_in">max</span>-lag <span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>以部分重同步为例，主从复制的核心步骤流程图如下：<br><img src="https://i.loli.net/2021/04/25/GdBXI6uUPpiMm53.png" alt="12"></p>
<h3 id="旧版同步：SYNC"><a href="#旧版同步：SYNC" class="headerlink" title="旧版同步：SYNC"></a>旧版同步：SYNC</h3><p>Redis 2.8 之前的数据同步通过 SYNC 命令完成，完整流程如下：</p>
<p>1、slave 向 master 发送 SYNC 命令。</p>
<p>2、master 收到 SYNC 命令后执行 BGSAVE 命令，fork 子进程生成 RDB 文件，同时会使用一个缓冲区记录从现在开始执行的所有写命令。</p>
<p>Redis 在这边使用了 COW（copy-on-write）的特性，这边简单介绍一下。</p>
<p>fork 子进程时，一种比较“愚蠢”的做法是将父进程的整个地址空间拷贝一份给子进程，但这是非常耗时的，因此一般不会这么做。</p>
<p>另一种做法是，fork 之后，父子进程共用父进程已有的地址空间，只有当父子进程要进行写操作时，才将要修改的内容复制一份，再进行写操作，这也是 copy-on-write 名字的由来。</p>
<p>回到本文，这边当主进程 fork 出子进程时，因为 COW 的关系，可以认为在 fork 的这一刻，快照已经生成了，只是还没写到 RDB 文件。</p>
<p>那这边就有一个问题，RDB 文件是 fork 这一刻的数据，从 fork 这一刻到 master 将 RDB 文件发送给 slave 之间，主进程还在继续执行写命令，这期间的写命令 slave 怎么获得？</p>
<p>这就用到上面“同时会使用一个缓冲区记录从现在开始执行的所有写命令”，这个缓冲区会记录 fork 之后的所有写命令。</p>
<p>后面当 master 将 RDB 文件发送给 slave 后，master 会继续将缓冲区中的写命令发送给 slave，也就是下面的第4步，从而保证 slave 的数据是完整的。</p>
<p>3、当 BGSAVE 命令执行完毕，master 会将生成的 RDB 文件发送给 slave。slave 接收 RDB 文件，并载入到内存，将数据库状态更新至 master 执行 BGSAVE 时的数据库状态。</p>
<p>这边发送 RDB 文件的方式有两种：1）socket：master 将 RDB 文件流通过 socket 直接发送到 slave；2）disk：master 将 RDB 文件先持久化到磁盘，再发送到 slave。</p>
<p>默认使用方式为 disk，可以通过以下配置来使用 socket 方式。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">repl-diskless-sync <span class="built_in">yes</span></span><br></pre></td></tr></table></figure>
<p>同时，相关的参数配置还有 diskless-sync-delay：该参数表示等待一定时长再开始复制，这样可以等待多个 slave 节点重新连接上来。</p>
<p>socket（无磁盘）方式适合磁盘读写速度慢但网络带宽非常高的环境。</p>
<p>另外，这边主进程检查子进程 BGSAVE 是否执行完毕是通过时间事件定时检查的。</p>
<p>4、master 将记录在缓冲区里面的所有写命令发送给 slave，slave 执行这些命令，将数据库状态更新至 master 当前所处的状态。</p>
<p>SYNC 存在的问题：slave 每次断线重连都需要使用完整重同步，效率低下。</p>
<h3 id="新版同步：SYNC"><a href="#新版同步：SYNC" class="headerlink" title="新版同步：SYNC"></a>新版同步：SYNC</h3><p>为了解决 slave 每次断线重连都需要使用完整重同步，redis 在 2.8 版本引入了 PSYNC，PSYNC 包含完整重同步和部分重同步。</p>
<p>1、完整重同步：和 SYNC 命令基本一致。</p>
<p>2、部分重同步：slave 只需要接收和同步断线期间丢失的写命令即可，不需要进行完整重同步。</p>
<p>为了实现部分重同步，Redis 引入了复制偏移量、复制积压缓冲区和运行 ID 三个概念。</p>
<h4 id="复制偏移量（offset）"><a href="#复制偏移量（offset）" class="headerlink" title="复制偏移量（offset）"></a>复制偏移量（offset）</h4><p>执行主从复制的双方都会分别维护一个复制偏移量，master 每次向 slave 传播 N 个字节，自己的复制偏移量就增加 N；同理 slave 接收 N 个字节，复制偏移量也增加 N。通过对比主从之间的复制偏移量就可以知道主从间的同步状态。</p>
<h4 id="复制积压缓冲区（replication-backlog-buffer）"><a href="#复制积压缓冲区（replication-backlog-buffer）" class="headerlink" title="复制积压缓冲区（replication backlog buffer）"></a>复制积压缓冲区（replication backlog buffer）</h4><p>复制积压缓冲区是 master 维护的一个固定长度的 FIFO 队列，默认大小为 1MB。</p>
<p>当 master 进行命令传播时，不仅将写命令发给 slave 还会同时写进复制积压缓冲区，因此 master 的复制积压缓冲区会保存一部分最近传播的写命令。</p>
<p>当 slave 重连上 master 时会将自己的复制偏移量通过 PSYNC 命令发给 master，master 检查自己的复制积压缓冲区，如果发现这部分未同步的命令还在自己的复制积压缓冲区中的话就可以利用这些保存的命令进行部分同步，反之如果断线太久这部分命令已经不在复制缓冲区中了，那没办法只能进行全量同步。</p>
<h4 id="运行-ID（runid）"><a href="#运行-ID（runid）" class="headerlink" title="运行 ID（runid）"></a>运行 ID（runid）</h4><p>每个 Redis server 都会有自己的运行 ID，由 40 个随机的十六进制字符组成。当 slave 初次复制 master 时，master 会将自己的运行 ID 发给 slave 进行保存，这样 slave 重连时再将这个运行 ID 发送给重连上的 master ，master 会接受这个 ID 并与自身的运行 ID 比较进而判断是否是同一个 master。</p>
<h4 id="引入这三个概念后，数据同步过程如下："><a href="#引入这三个概念后，数据同步过程如下：" class="headerlink" title="引入这三个概念后，数据同步过程如下："></a>引入这三个概念后，数据同步过程如下：</h4><p>1）slave 通过 PSYNC runid offset 命令，将正在复制的 runid 和 offset 发送给 master。</p>
<p>2）master 判断 runid 和自己的 runid 相同，并且 offset 还在复制积压缓冲区，则进行部分重同步：通过复制积压缓冲区将 slave 缺失的命令发送给 slave，slave 执行命令，将数据库状态更新至 master 所处的状态。</p>
<p>3）否则，如果 master 判断 runid 不相同，或者 offset 已经不在复制积压缓冲区，则执行完整重同步。</p>
<p>PSYNC 的完整流程如下图：<br><img src="https://i.loli.net/2021/04/25/U2JWv51Kdr9mBMb.png" alt="13"></p>
<h4 id="PSYNC-存在的问题"><a href="#PSYNC-存在的问题" class="headerlink" title="PSYNC 存在的问题"></a>PSYNC 存在的问题</h4><p>通过上述流程，我们可以看出，PSYNC 执行部分重同步需要满足两个条件：1）master runid 不变；2）复制偏移量在 master 复制积压缓冲区中。一旦不满足这两个条件，则仍然需要进行完整重同步，例如以下场景。</p>
<p>1、slave 重启，缓存的 master runid 和 offset 都会丢失，slave 需进行完整重同步。</p>
<p>2、redis 发生故障切换，故障切换后 master runid 发生了变化，slave 需进行完整重同步。</p>
<p>slave 维护性重启、master 故障切换都是 redis 运维常见场景，因此，PSYNC 的这两个问题出现概率还是非常高的。</p>
<h3 id="PSYNC2"><a href="#PSYNC2" class="headerlink" title="PSYNC2"></a>PSYNC2</h3><p>为了解决 PSYNC 在 slave 重启和故障切换导致完整重同步的问题，Redis 在 4.0 版本中对 PSYNC 进行了优化，我们称为 PSYNC2。</p>
<p>PSYNC2 进行了以下2个主要改动：</p>
<h4 id="引入两组-replid-和-offset-替换原来的-runid-和-offset"><a href="#引入两组-replid-和-offset-替换原来的-runid-和-offset" class="headerlink" title="引入两组 replid 和 offset 替换原来的 runid 和 offset"></a>引入两组 replid 和 offset 替换原来的 runid 和 offset</h4><p>第一组：replid 和 master_repl_offset<br>对于 master，表示为自己的复制 ID 和复制偏移量；<br>对于 slave，表示为自己正在同步的 master 的复制 ID 和复制偏移量。<br>可以认为这一组的两个字段就是对应原来的 runid 和 offset。</p>
<p> <br>第二组：replid2 和 second_repl_offset<br>对于 master 和 slave，都表示自己的上一个 master 的复制 ID 和复制偏移量；主要用于故障切换时支持部分重同步。<br>值得注意的是，runid 并不是在引入 replid 之后就不存在了。在 4.0 之前，redis 使用 runid 来作为主从复制的标识，而在 4.0 后引入了 replid 来作为主从复制的标识，但是，runid 在 redis 中的功能不仅仅是作为主从复制的标识，runid 仍然有其他的功能，例如：用于作为 redis 服务器的唯一标识。</p>
<h4 id="slave-也会开启复制积压缓冲区"><a href="#slave-也会开启复制积压缓冲区" class="headerlink" title="slave 也会开启复制积压缓冲区"></a>slave 也会开启复制积压缓冲区</h4><p>slave 开启复制积压缓冲区，主要是用于故障切换后，当某个 slave 升级为 master，该 slave 仍然可以通过复制积压缓冲区继续支持部分重同步功能。</p>
<p>如果 slave 不开启复制积压缓冲区，当该 slave 升级为 master 后，复制积压缓冲区是空的，就没法支持部分重同步了。</p>
<p>接下来，让我们看看 Redis 是如何针对 PSYNC 的两个问题来进行优化。</p>
<h4 id="优化场景1：slave-重启后导致完整同步"><a href="#优化场景1：slave-重启后导致完整同步" class="headerlink" title="优化场景1：slave 重启后导致完整同步"></a>优化场景1：slave 重启后导致完整同步</h4><p>产生该问题的根本原因是 slave 重启后，复制 ID（运行 ID） 和 复制偏移量丢失了。解决办法其实很简单，就是在关闭服务器前将这两个变量存下来即可。</p>
<p>Redis 的做法如下：slave 在正常关闭前会调用 rdbSaveInfoAuxFields 函数把当前的复制 ID（replid） 和复制偏移量（master_repl_offset）作为辅助字段保存到 RDB 文件中，后面该 slave 重启的时候，就可以从 RDB 文件中读取复制 ID 和复制偏移量，然后使用这两个变量来进行部分重同步。</p>
<h4 id="优化场景2：master-故障切换后导致完整重同步"><a href="#优化场景2：master-故障切换后导致完整重同步" class="headerlink" title="优化场景2：master 故障切换后导致完整重同步"></a>优化场景2：master 故障切换后导致完整重同步</h4><p>产生该问题的根本原因是故障切换后出现了新的 master，而新 master 的复制 ID（运行 ID）发生改变导致没法进行部分重同步。</p>
<p>在正常同步的情况下，新 master 的数据跟老 master 理论上是完全一致的，包括复制积压缓冲区的数据。</p>
<p>因此理论上 slave 是可以进行部分重同步的，现在仅仅是因为复制 ID 变了而没法进行。所以，我们的目标就是想办法让新 master 和其他 slave 可以串联起来。</p>
<p>新 master 和其他没有晋升的 slave 的共同点是故障切换前的 master 是相同的，因此很容易想到的做法是：利用故障切换前的 master 来串联新 master 和剩余 slave。</p>
<p>Redis 的做法如下：当节点从 slave 晋升为 master 后，会将原来自己保存的第一组复制 ID 和复制偏移量（也就是老 master 的），移动到第二组复制 ID 和复制偏移量，然后将第一组复制 ID 重新生成一个新的，也就是属于自己的复制 ID。</p>
<p>相当于，slave 晋升为 master 后，replid 保存了自己的复制 ID，replid2 保存了老 master 的复制ID。</p>
<p>这样，新 master 就可以通过 replid2 来判断 slave 是否之前跟自己从是从同一个 master 复制数据，如果是的话，则尝试使用部分重同步。</p>
<p>PSYNC2 的完整流程如下，可以看出和 PSYNC 很类似，主要区别在于紫色框部分。</p>
<h4 id="主从复制的演变"><a href="#主从复制的演变" class="headerlink" title="主从复制的演变"></a>主从复制的演变</h4><p>从 Redis 2.* 到现在，开发人员对主从复制流程进行逐步的优化，以下是演进过程：</p>
<p>1、2.8 版本之前 Redis 复制采用 SYNC 命令，无论是第一次复制还是断线重连后的复制都采用完整重同步，成本高。</p>
<p>2、2.8 ~ 4.0 之间复制采用 PSYNC 命令，主要优化了 Redis 在断线重连时候可通过 runid 和 offset 信息使用部分重同步。</p>
<p>3、4.0 版本之后对 PSYNC 进行了优化，通常称为 PSYNC2，主要优化了 PSYNC 在 slave 重启和故障切换时的完整重同步问题。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>面试必问的 Redis：RDB、AOF、混合持久化</title>
    <url>/2021/04/24/redis/%E9%9D%A2%E8%AF%95%E5%BF%85%E9%97%AE%E7%9A%84-Redis%EF%BC%9ARDB%E3%80%81AOF%E3%80%81%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>继续战斗</p>
<span id="more"></span>

<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="Redis-核心主流程"><a href="#Redis-核心主流程" class="headerlink" title="Redis 核心主流程"></a>Redis 核心主流程</h3><p>AOF 和 RDB 的持久化过程中，有不少操作是在时间事件 serverCron 中被触发的。所以，这边有必要先了解下 Redis 中的事件核心流程。</p>
<p>Redis 的服务器进程就是一个事件循环，最重要的有两个事件：文件事件和时间事件。Redis 在服务器初始化后，会无限循环，处理产生的文件事件和时间事件。</p>
<p>文件事件常见的有：接受连接（accept）、读取（read）、写入（write）、关闭连接（close）等。</p>
<p>时间事件中常见的就是 serverCron，redis 核心流程中通常也只有这个时间事件。serverCron 默认配置下每100ms会被触发一次，在该时间事件中，会执行很多操作：清理过期键、AOF 后台重写、RDB 的 save point 的检查、将 aof_buf 内容写到磁盘上（flushAppendOnlyFile 函数）等等。</p>
<p>Redis 的核心主流程如下图：<br><img src="https://i.loli.net/2021/04/24/BO7E4yUSkGxATgV.png" alt="1"></p>
<h3 id="Redis-的持久化机制有哪几种"><a href="#Redis-的持久化机制有哪几种" class="headerlink" title="Redis 的持久化机制有哪几种"></a>Redis 的持久化机制有哪几种</h3><p>RDB、AOF、混合持久化（redis4.0引入）</p>
<h3 id="RDB的实现原理、优缺点"><a href="#RDB的实现原理、优缺点" class="headerlink" title="RDB的实现原理、优缺点"></a>RDB的实现原理、优缺点</h3><p>描述：类似于快照。在某个时间点，将 Redis 在内存中的数据库状态（数据库的键值对等信息）保存到磁盘里面。RDB 持久化功能生成的 RDB 文件是经过压缩的二进制文件。</p>
<p>命令：有两个 Redis 命令可以用于生成 RDB 文件，一个是 SAVE，另一个是 BGSAVE。</p>
<p>开启：使用 save point 配置，满足 save point 条件后会触发 BGSAVE 来存储一次快照，这边的 save point 检查就是在上文提到的 serverCron 中进行。</p>
<p>save point 格式：save <seconds> <changes>，含义是 Redis 如果在 seconds 秒内数据发生了 changes 次改变，就保存快照文件。例如 Redis 默认就配置了以下3个：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">save</span> <span class="number">900</span> <span class="number">1</span> #<span class="number">900</span>秒内有<span class="number">1</span>个key发生了变化，则触发保存RDB文件</span><br><span class="line"><span class="attribute">save</span> <span class="number">300</span> <span class="number">10</span> #<span class="number">300</span>秒内有<span class="number">10</span>个key发生了变化，则触发保存RDB文件</span><br><span class="line"><span class="attribute">save</span> <span class="number">60</span> <span class="number">10000</span> #<span class="number">60</span>秒内有<span class="number">10000</span>个key发生了变化，则触发保存RDB文件</span><br></pre></td></tr></table></figure>

<p>关闭：1）注释掉所有save point 配置可以关闭 RDB 持久化。2）在所有 save point 配置后增加：save “”，该配置可以删除所有之前配置的 save point</p>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line"><span class="built_in">save</span> <span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>SAVE：生成 RDB 快照文件，但是会阻塞主进程，服务器将无法处理客户端发来的命令请求，所以通常不会直接使用该命令。<br>BGSAVE：fork 子进程来生成 RDB 快照文件，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理请求，详细过程如下图：<br><img src="https://i.loli.net/2021/04/24/qwpZVMb6aNuiyhI.png" alt="2"><br>fork：在 Linux 系统中，调用 fork() 时，会创建出一个新进程，称为子进程，子进程会拷贝父进程的 page table。如果进程占用的内存越大，进程的 page table 也会越大，那么 fork 也会占用更多的时间。如果 Redis 占用的内存很大，那么在 fork 子进程时，则会出现明显的停顿现象。</p>
<p>RDB 的优点：<br>1）RDB 文件是是经过压缩的二进制文件，占用空间很小，它保存了 Redis 某个时间点的数据集，很适合用于做备份。 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。</p>
<p>2）RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。</p>
<p>3）RDB 可以最大化 redis 的性能。父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。</p>
<p>4）RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</p>
<p>RDB 的缺点：<br>1）RDB 在服务器故障时容易造成数据的丢失。RDB 允许我们通过修改 save point 配置来控制持久化的频率。但是，因为 RDB 文件需要保存整个数据集的状态， 所以它是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。所以通常可能设置至少5分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失5分钟数据。</p>
<p>2）RDB 保存时使用 fork 子进程进行数据的持久化，如果数据比较大的话，fork 可能会非常耗时，造成 Redis 停止处理服务N毫秒。如果数据集很大且 CPU 比较繁忙的时候，停止服务的时间甚至会到一秒。</p>
<p>3）Linux fork 子进程采用的是 copy-on-write 的方式。在 Redis 执行 RDB 持久化期间，如果 client 写入数据很频繁，那么将增加 Redis 占用的内存，最坏情况下，内存的占用将达到原先的2倍。刚 fork 时，主进程和子进程共享内存，但是随着主进程需要处理写操作，主进程需要将修改的页面拷贝一份出来，然后进行修改。极端情况下，如果所有的页面都被修改，则此时的内存占用是原先的2倍。</p>
<h3 id="AOF的实现原理、优缺点"><a href="#AOF的实现原理、优缺点" class="headerlink" title="AOF的实现原理、优缺点"></a>AOF的实现原理、优缺点</h3><p>描述：保存 Redis 服务器所执行的所有写操作命令来记录数据库状态，并在服务器启动时，通过重新执行这些命令来还原数据集。</p>
<p>开启：AOF 持久化默认是关闭的，可以通过配置：appendonly yes 开启。</p>
<p>关闭：使用配置 appendonly no 可以关闭 AOF 持久化。</p>
<p>AOF 持久化功能的实现可以分为三个步骤：命令追加、文件写入、文件同步。</p>
<p>命令追加：当 AOF 持久化功能打开时，服务器在执行完一个写命令之后，会将被执行的写命令追加到服务器状态的 aof 缓冲区（aof_buf）的末尾。</p>
<p>文件写入与文件同步：可能有人不明白为什么将 aof_buf 的内容写到磁盘上需要两步操作，这边简单解释一下。</p>
<p>Linux 操作系统中为了提升性能，使用了页缓存（page cache）。当我们将 aof_buf 的内容写到磁盘上时，此时数据并没有真正的落盘，而是在 page cache 中，为了将 page cache 中的数据真正落盘，需要执行 fsync / fdatasync 命令来强制刷盘。这边的文件同步做的就是刷盘操作，或者叫文件刷盘可能更容易理解一些。</p>
<p>在文章开头，我们提过 serverCron 时间事件中会触发 flushAppendOnlyFile 函数，该函数会根据服务器配置的 appendfsync 参数值，来决定是否将 aof_buf 缓冲区的内容写入和保存到 AOF 文件。</p>
<p>appendfsync 参数有三个选项：<br>1）always：每处理一个命令都将 aof_buf 缓冲区中的所有内容写入并同步到AOF 文件，即每个命令都刷盘。</p>
<p>2）everysec：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超过一秒钟， 那么再次对 AOF 文件进行同步， 并且这个同步操作是异步的，由一个后台线程专门负责执行，即每秒刷盘1次。</p>
<p>3）no：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 但并不对 AOF 文件进行同步， 何时同步由操作系统来决定。即不执行刷盘，让操作系统自己执行刷盘。</p>
<p>AOF 的优点<br>1）AOF 比 RDB可靠。你可以设置不同的 fsync 策略：no、everysec 和 always。默认是 everysec，在这种配置下，redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据。</p>
<p>2）AOF文件是一个纯追加的日志文件。即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机等等）， 我们也可以使用 redis-check-aof 工具也可以轻易地修复这种问题。</p>
<p>3）当 AOF文件太大时，Redis 会自动在后台进行重写：重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。整个重写是绝对安全，因为重写是在一个新的文件上进行，同时 Redis 会继续往旧的文件追加数据。当新文件重写完毕，Redis 会把新旧文件进行切换，然后开始把数据写到新文件上。</p>
<p>4）AOF 文件有序地保存了对数据库执行的所有写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。如果你不小心执行了 FLUSHALL 命令把所有数据刷掉了，但只要 AOF 文件没有被重写，那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。</p>
<p>AOF 的缺点<br>1）对于相同的数据集，AOF 文件的大小一般会比 RDB 文件大。</p>
<p>2）根据所使用的 fsync 策略，AOF 的速度可能会比 RDB 慢。通常 fsync 设置为每秒一次就能获得比较高的性能，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快。</p>
<p>3）AOF 在过去曾经发生过这样的 bug ：因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。（举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug ） 。虽然这种 bug 在 AOF 文件中并不常见， 但是相较而言， RDB 几乎是不可能出现这种 bug 的。</p>
<h3 id="混合持久化的实现原理、优缺点"><a href="#混合持久化的实现原理、优缺点" class="headerlink" title="混合持久化的实现原理、优缺点"></a>混合持久化的实现原理、优缺点</h3><p>描述：混合持久化并不是一种全新的持久化方式，而是对已有方式的优化。混合持久化只发生于 AOF 重写过程。使用了混合持久化，重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据。</p>
<p>整体格式为：[RDB file][AOF tail]</p>
<p>开启：混合持久化的配置参数为 aof-use-rdb-preamble，配置为 yes 时开启混合持久化，在 redis 4 刚引入时，默认是关闭混合持久化的，但是在 redis 5 中默认已经打开了。<br>关闭：使用 aof-use-rdb-preamble no 配置即可关闭混合持久化。</p>
<p>混合持久化本质是通过 AOF 后台重写（bgrewriteaof 命令）完成的，不同的是当开启混合持久化时，fork 出的子进程先将当前全量数据以 RDB 方式写入新的 AOF 文件，然后再将 AOF 重写缓冲区（aof_rewrite_buf_blocks）的增量命令以 AOF 方式写入到文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p>
<p>优点：结合 RDB 和 AOF 的优点, 更快的重写和恢复。</p>
<p>缺点：AOF 文件里面的 RDB 部分不再是 AOF 格式，可读性差。</p>
<h3 id="为什么需要-AOF-重写"><a href="#为什么需要-AOF-重写" class="headerlink" title="为什么需要 AOF 重写"></a>为什么需要 AOF 重写</h3><p>AOF 持久化是通过保存被执行的写命令来记录数据库状态的，随着写入命令的不断增加，AOF 文件中的内容会越来越多，文件的体积也会越来越大。</p>
<p>如果不加以控制，体积过大的 AOF 文件可能会对 Redis 服务器、甚至整个宿主机造成影响，并且 AOF 文件的体积越大，使用 AOF 文件来进行数据还原所需的时间就越多。</p>
<p>举个例子， 如果你对一个计数器调用了 100 次 INCR ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录。</p>
<p>然而在实际上， 只使用一条 SET 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。</p>
<p>为了处理这种情况， Redis 引入了 AOF 重写：可以在不打断服务端处理请求的情况下， 对 AOF 文件进行重建（rebuild）。</p>
<h3 id="AOF-重写"><a href="#AOF-重写" class="headerlink" title="AOF 重写"></a>AOF 重写</h3><p>描述：Redis 生成新的 AOF 文件来代替旧 AOF 文件，这个新的 AOF 文件包含重建当前数据集所需的最少命令。具体过程是遍历所有数据库的所有键，从数据库读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。</p>
<p>命令：有两个 Redis 命令可以用于触发 AOF 重写，一个是 BGREWRITEAOF 、另一个是  REWRITEAOF 命令；</p>
<p>开启：AOF 重写由两个参数共同控制，auto-aof-rewrite-percentage 和 auto-aof-rewrite-min-size，同时满足这两个条件，则触发 AOF 后台重写 BGREWRITEAOF。</p>
<figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 当前AOF文件比上次重写后的AOF文件大小的增长比例超过100</span></span><br><span class="line"><span class="keyword">auto</span>-aof-rewrite-percentage <span class="number">100</span> </span><br><span class="line"><span class="comment">// 当前AOF文件的文件大小大于64MB</span></span><br><span class="line"><span class="keyword">auto</span>-aof-rewrite-min-size <span class="number">64</span>mb</span><br></pre></td></tr></table></figure>

<p>关闭：auto-aof-rewrite-percentage 0，指定0的百分比，以禁用自动AOF重写功能。</p>
<figure class="highlight coq"><table><tr><td class="code"><pre><span class="line"><span class="built_in">auto</span>-aof-<span class="built_in">rewrite</span>-percentage <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>REWRITEAOF：进行 AOF 重写，但是会阻塞主进程，服务器将无法处理客户端发来的命令请求，通常不会直接使用该命令。<br>BGREWRITEAOF：fork 子进程来进行 AOF 重写，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理请求。<br>REWRITEAOF 和 BGREWRITEAOF 的关系与 SAVE 和 BGSAVE 的关系类似。</p>
<h3 id="AOF-后台重写存在的问题"><a href="#AOF-后台重写存在的问题" class="headerlink" title="AOF 后台重写存在的问题"></a>AOF 后台重写存在的问题</h3><p>AOF 后台重写使用子进程进行从写，解决了主进程阻塞的问题，但是仍然存在另一个问题：子进程在进行 AOF 重写期间，服务器主进程还需要继续处理命令请求，新的命令可能会对现有的数据库状态进行修改，从而使得当前的数据库状态和重写后的 AOF 文件保存的数据库状态不一致。</p>
<h3 id="如何解决-AOF-后台重写存在的数据不一致问题"><a href="#如何解决-AOF-后台重写存在的数据不一致问题" class="headerlink" title="如何解决 AOF 后台重写存在的数据不一致问题"></a>如何解决 AOF 后台重写存在的数据不一致问题</h3><p>为了解决上述问题，Redis 引入了 AOF 重写缓冲区（aof_rewrite_buf_blocks），这个缓冲区在服务器创建子进程之后开始使用，当 Redis 服务器执行完一个写命令之后，它会同时将这个写命令追加到 AOF 缓冲区和 AOF 重写缓冲区。</p>
<p>这样一来可以保证：<br>1、现有 AOF 文件的处理工作会如常进行。这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。<br>2、从创建子进程开始，也就是 AOF 重写开始，服务器执行的所有写命令会被记录到 AOF 重写缓冲区里面。</p>
<p>这样，当子进程完成 AOF 重写工作后，父进程会在 serverCron 中检测到子进程已经重写结束，则会执行以下工作：<br>1、将 AOF 重写缓冲区中的所有内容写入到新 AOF 文件中，这时新 AOF 文件所保存的数据库状态将和服务器当前的数据库状态一致。<br>2、对新的 AOF 文件进行改名，原子的覆盖现有的 AOF 文件，完成新旧两个 AOF 文件的替换。</p>
<p>之后，父进程就可以继续像往常一样接受命令请求了。</p>
<h3 id="AOF-重写缓冲区内容过多怎么办"><a href="#AOF-重写缓冲区内容过多怎么办" class="headerlink" title="AOF 重写缓冲区内容过多怎么办"></a>AOF 重写缓冲区内容过多怎么办</h3><p>将 AOF 重写缓冲区的内容追加到新 AOF 文件的工作是由主进程完成的，所以这一过程会导致主进程无法处理请求，如果内容过多，可能会使得阻塞时间过长，显然是无法接受的。</p>
<p>Redis 中已经针对这种情况进行了优化：</p>
<p>1、在进行 AOF 后台重写时，Redis 会创建一组用于父子进程间通信的管道，同时会新增一个文件事件，该文件事件会将写入 AOF 重写缓冲区的内容通过该管道发送到子进程。</p>
<p>2、在重写结束后，子进程会通过该管道尽量从父进程读取更多的数据，每次等待可读取事件1ms，如果一直能读取到数据，则这个过程最多执行1000次，也就是1秒。如果连续20次没有读取到数据，则结束这个过程。</p>
<p>通过这些优化，Redis 尽量让 AOF 重写缓冲区的内容更少，以减少主进程阻塞的时间。</p>
<p>到此，AOF 后台重写的核心内容基本告一段落，通过一张图来看下其完整流程。<br><img src="https://i.loli.net/2021/04/24/zKL6ET9WocyiGZu.png" alt="3"></p>
<h3 id="RDB、AOF、混合持久，我应该用哪一个？"><a href="#RDB、AOF、混合持久，我应该用哪一个？" class="headerlink" title="RDB、AOF、混合持久，我应该用哪一个？"></a>RDB、AOF、混合持久，我应该用哪一个？</h3><p>一般来说， 如果想尽量保证数据安全性， 你应该同时使用 RDB 和 AOF 持久化功能，同时可以开启混合持久化。</p>
<p>如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。</p>
<p>如果你的数据是可以丢失的，则可以关闭持久化功能，在这种情况下，Redis 的性能是最高的。</p>
<p>使用 Redis 通常都是为了提升性能，而如果为了不丢失数据而将 appendfsync  设置为 always 级别时，对 Redis 的性能影响是很大的，在这种不能接受数据丢失的场景，其实可以考虑直接选择 MySQL 等类似的数据库。</p>
<h3 id="服务启动时如何加载持久化数据"><a href="#服务启动时如何加载持久化数据" class="headerlink" title="服务启动时如何加载持久化数据"></a>服务启动时如何加载持久化数据</h3><p>简单来说，如果同时启用了 AOF 和 RDB，Redis 重新启动时，会使用 AOF 文件来重建数据集，因为通常来说， AOF 的数据会更完整。</p>
<p>而在引入了混合持久化之后，使用 AOF 重建数据集时，会通过文件开头是否为“REDIS”来判断是否为混合持久化。</p>
<p>完整流程如下图所示：<br><img src="https://i.loli.net/2021/04/24/xDN6YWkJBIKnm4L.png" alt="4"></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>面试必问的 Redis：数据结构和基础概念</title>
    <url>/2021/04/24/redis/%E9%9D%A2%E8%AF%95%E5%BF%85%E9%97%AE%E7%9A%84-Redis%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 Java 后端的面试中，redis 应该是目前所有框架/中间件中被问到频率最高的，至少也是之一。</p>
<p>就算把范围扩大到整个 Java 后端面试知识体系，面试中出现频率比 redis 高的也不多，可能就那么几个：HashMap、线程池之类的。 </p>
<p>由于比较重要，知识点也比较多，所以这边预计分为多篇来呈现。</p>
<p>除了本文之外，主要还有两个方向，一个围绕高可用，主要是持久化、主从复制、哨兵、集群模式等。</p>
<p>另一个围绕 redis 的实践，主要是分布式锁、缓存穿透、缓存雪崩、缓存击穿等。</p>
<span id="more"></span>


<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="redis-是单线程还是多线程"><a href="#redis-是单线程还是多线程" class="headerlink" title="redis 是单线程还是多线程"></a>redis 是单线程还是多线程</h3><p>这个问题应该已经看到过无数次了，最近 redis 6 出来之后又被翻出来了。</p>
<p>redis 4.0 之前，redis 是完全单线程的。</p>
<p>redis 4.0 时，redis 引入了多线程，但是额外的线程只是用于后台处理，例如：删除对象，核心流程还是完全单线程的。这也是为什么有些人说 4.0 是单线程的，因为他们指的是核心流程是单线程的。</p>
<p>这边的核心流程指的是 redis 正常处理客户端请求的流程，通常包括：接收命令、解析命令、执行命令、返回结果等。</p>
<p>而在最近，redis 6.0 版本又一次引入了多线程概念，与 4.0 不同的是，这次的多线程会涉及到上述的核心流程。</p>
<p>redis 6.0 中，多线程主要用于网络 I/O 阶段，也就是接收命令和写回结果阶段，而在执行命令阶段，还是由单线程串行执行。由于执行时还是串行，因此无需考虑并发安全问题。</p>
<p>值得注意的时，redis 中的多线程组不会同时存在“读”和“写”，这个多线程组只会同时“读”或者同时“写”。</p>
<p>redis 6.0 加入多线程 I/O 之后，处理命令的核心流程如下:</p>
<p>1、当有读事件到来时，主线程将该客户端连接放到全局等待读队列</p>
<p>2、读取数据：1）主线程将等待读队列的客户端连接通过轮询调度算法分配给 I/O 线程处理；2）同时主线程也会自己负责处理一个客户端连接的读事件；3）当主线程处理完该连接的读事件后，会自旋等待所有 I/O 线程处理完毕</p>
<p>3、命令执行：主线程按照事件被加入全局等待读队列的顺序（这边保证了执行顺序是正确的），串行执行客户端命令，然后将客户端连接放到全局等待写队列</p>
<p>4、写回结果：跟等待读队列处理类似，主线程将等待写队列的客户端连接使用轮询调度算法分配给 I/O 线程处理，同时自己也会处理一个，当主线程处理完毕后，会自旋等待所有 I/O 线程处理完毕，最后清空队列。</p>
<p>大致流程图如下：<br><img src="https://i.loli.net/2021/04/24/BOo9KzpQ7y3hDcJ.png" alt="1"></p>
<h3 id="为什么-redis-是单线程"><a href="#为什么-redis-是单线程" class="headerlink" title="为什么 redis 是单线程"></a>为什么 redis 是单线程</h3><p>在 redis 6.0 之前，redis 的核心操作是单线程的。</p>
<p>因为 redis 是完全基于内存操作的，通常情况下CPU不会是redis的瓶颈，redis 的瓶颈最有可能是机器内存的大小或者网络带宽。</p>
<p>既然CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了，因为如果使用多线程的话会更复杂，同时需要引入上下文切换、加锁等等，会带来额外的性能消耗。</p>
<p>而随着近些年互联网的不断发展，大家对于缓存的性能要求也越来越高了，因此 redis 也开始在逐渐往多线程方向发展。</p>
<p>最近的 6.0 版本就对核心流程引入了多线程，主要用于解决 redis 在网络 I/O 上的性能瓶颈。而对于核心的命令执行阶段，目前还是单线程的。</p>
<h3 id="redis-为什么使用单进程、单线程也很快"><a href="#redis-为什么使用单进程、单线程也很快" class="headerlink" title="redis 为什么使用单进程、单线程也很快"></a>redis 为什么使用单进程、单线程也很快</h3><p>1、基于内存的操作</p>
<p>2、使用了 I/O 多路复用模型，select、epoll 等，基于 reactor 模式开发了自己的网络事件处理器</p>
<p>3、单线程可以避免不必要的上下文切换和竞争条件，减少了这方面的性能消耗。</p>
<p>4、以上这三点是 redis 性能高的主要原因，其他的还有一些小优化，例如：对数据结构进行了优化，简单动态字符串、压缩列表等。</p>
<h3 id="项目中使用的-redis-版本"><a href="#项目中使用的-redis-版本" class="headerlink" title="项目中使用的 redis 版本"></a>项目中使用的 redis 版本</h3><p>这个问题是我在面试某大厂真实碰到过的，所以大家平时在使用中间件和框架时可以留意下自使用的版本。</p>
<p>下图是从 redis 官方 github 截的图，包含了 redis 2.2 之后的所有版本，目前常用的应该是：3.2.*、4.0.*、5.0.*。</p>
<h3 id="redis-在项目中的使用场景"><a href="#redis-在项目中的使用场景" class="headerlink" title="redis 在项目中的使用场景"></a>redis 在项目中的使用场景</h3><p>缓存、分布式锁、排行榜（zset）、计数（incrby）、消息队列（stream）、地理位置（geo）、访客统计（hyperloglog）等。</p>
<h3 id="redis常见的数据结构"><a href="#redis常见的数据结构" class="headerlink" title="redis常见的数据结构"></a>redis常见的数据结构</h3><p>常见的5种：</p>
<blockquote>
<p>String：字符串，最基础的数据类型。<br> List：列表。<br> Hash：哈希对象。<br> Set：集合。<br> Sorted Set：有序集合，Set 的基础上加了个分值。</p>
</blockquote>
<p>高级的4种：</p>
<blockquote>
<p>HyperLogLog：通常用于计数统计。使用少量固定大小的内存，来统计集合中唯一元素的数量。统计结果不是精确值，而是一个带有0.81%标准差（standard error）的近似值。所以，HyperLogLog适用于一些对于统计结果精确度要求不是特别高的场景，例如网站的UV统计。<br> Geo：redis 3.2 版本的新特性。可以将用户给定的地理位置信息储存起来， 并对这些信息进行操作：获取2个位置的距离、根据给定地理位置坐标获取指定范围内的地理位置集合。<br> Bitmap：位图。<br> Stream：主要用于消息队列，类似于 kafka，可以认为是 pub/sub 的改进版。提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。</p>
</blockquote>
<h3 id="Redis的字符串（SDS）和C语言的字符串区别"><a href="#Redis的字符串（SDS）和C语言的字符串区别" class="headerlink" title="Redis的字符串（SDS）和C语言的字符串区别"></a>Redis的字符串（SDS）和C语言的字符串区别</h3><p><img src="https://i.loli.net/2021/04/24/I9mCxS7NlQpoArY.png" alt="2"></p>
<h3 id="Sorted-Set底层数据结构"><a href="#Sorted-Set底层数据结构" class="headerlink" title="Sorted Set底层数据结构"></a>Sorted Set底层数据结构</h3><p>Sorted Set（有序集合）当前有两种编码：ziplist、skiplist</p>
<p>ziplist：使用压缩列表实现，当保存的元素长度都小于64字节，同时数量小于128时，使用该编码方式，否则会使用 skiplist。这两个参数可以通过 zset-max-ziplist-entries、zset-max-ziplist-value 来自定义修改。<br><img src="https://i.loli.net/2021/04/24/UXc6qoyLJuz3nwH.png" alt="3"><br>skiplist：zset实现，一个zset同时包含一个字典（dict）和一个跳跃表（zskiplist）<br><img src="https://i.loli.net/2021/04/24/tbv5FEIT74MDpGC.png" alt="4"></p>
<h3 id="Sorted-Set为什么同时使用字典和跳跃表？"><a href="#Sorted-Set为什么同时使用字典和跳跃表？" class="headerlink" title="Sorted Set为什么同时使用字典和跳跃表？"></a>Sorted Set为什么同时使用字典和跳跃表？</h3><p>主要是为了性能。</p>
<p>单独使用字典：在执行范围型操作，比如zrank、zrange，字典需要进行排序，至少需要O(NlogN)的时间复杂度及额外O(N)的内存空间。</p>
<p>单独使用跳跃表：根据成员查找分值操作的复杂度从O(1)上升为O(logN)。</p>
<h3 id="Sorted-Set为什么使用跳跃表，而不是红黑树？"><a href="#Sorted-Set为什么使用跳跃表，而不是红黑树？" class="headerlink" title="Sorted Set为什么使用跳跃表，而不是红黑树？"></a>Sorted Set为什么使用跳跃表，而不是红黑树？</h3><p>1）跳表的性能和红黑树差不多。</p>
<p>2）跳表更容易实现和调试。</p>
<h3 id="Hash-对象底层结构"><a href="#Hash-对象底层结构" class="headerlink" title="Hash 对象底层结构"></a>Hash 对象底层结构</h3><p>Hash 对象当前有两种编码：ziplist、hashtable</p>
<p>ziplist：使用压缩列表实现，每当有新的键值对要加入到哈希对象时，程序会先将保存了键的节点推入到压缩列表的表尾，然后再将保存了值的节点推入到压缩列表表尾。</p>
<p>因此：1）保存了同一键值对的两个节点总是紧挨在一起，保存键的节点在前，保存值的节点在后；2）先添加到哈希对象中的键值对会被放在压缩列表的表头方向，而后来添加的会被放在表尾方向。<br><img src="https://i.loli.net/2021/04/24/36xuDKOSo5IacNR.png" alt="5"><br>hashtable：使用字典作为底层实现，哈希对象中的每个键值对都使用一个字典键值来保存，跟 java 中的 HashMap 类似。<br><img src="https://i.loli.net/2021/04/24/klMN5Lwz1viJYqb.png" alt="6"></p>
<h3 id="Hash-对象的扩容流程"><a href="#Hash-对象的扩容流程" class="headerlink" title="Hash 对象的扩容流程"></a>Hash 对象的扩容流程</h3><p>hash 对象在扩容时使用了一种叫“渐进式 rehash”的方式，步骤如下：</p>
<p>1、计算新表 size、掩码，为新表 ht[1] 分配空间，让字典同时持有 ht[0] 和 ht[1] 两个哈希表。</p>
<p>2、将 rehash 索引计数器变量 rehashidx 的值设置为0，表示 rehash 正式开始。</p>
<p>3、在 rehash 进行期间，每次对字典执行添加、删除、査找、更新操作时，程序除了执行指定的操作以外，还会触发额外的 rehash 操作，在源码中的 _dictRehashStep 方法。</p>
<p>_dictRehashStep：从名字也可以看出来，大意是 rehash 一步，也就是 rehash 一个索引位置。</p>
<p>该方法会从 ht[0] 表的 rehashidx 索引位置上开始向后查找，找到第一个不为空的索引位置，将该索引位置的所有节点 rehash 到 ht[1]，当本次 rehash 工作完成之后，将 ht[0] 的 rehashidx 位置清空，同时将 rehashidx 属性的值加一。</p>
<p>4、将 rehash 分摊到每个操作上确实是非常妙的方式，但是万一此时服务器比较空闲，一直没有什么操作，难道 redis 要一直持有两个哈希表吗？</p>
<p>答案当然不是的。我们知道，redis 除了文件事件外，还有时间事件，redis 会定期触发时间事件，这些时间事件用于执行一些后台操作，其中就包含 rehash 操作：当 redis 发现有字典正在进行 rehash 操作时，会花费1毫秒的时间，一起帮忙进行 rehash。</p>
<p>5、随着操作的不断执行，最终在某个时间点上，ht[0] 的所有键值对都会被 rehash 至 ht[1]，此时 rehash 流程完成，会执行最后的清理工作：释放 ht[0] 的空间、将 ht[0] 指向 ht[1]、重置 ht[1]、重置 rehashidx 的值为 -1。</p>
<h3 id="渐进式-rehash-的优点"><a href="#渐进式-rehash-的优点" class="headerlink" title="渐进式 rehash 的优点"></a>渐进式 rehash 的优点</h3><p>渐进式 rehash 的好处在于它采取分而治之的方式，将 rehash 键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式 rehash 而带来的庞大计算量。</p>
<p>在进行渐进式 rehash 的过程中，字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间，字典的删除、査找、更新等操作会在两个哈希表上进行。例如，要在字典里面査找一个键的话，程序会先在 ht[0] 里面进行査找，如果没找到的话，就会继续到 ht[1] 里面进行査找，诸如此类。</p>
<p>另外，在渐进式 rehash 执行期间，新增的键值对会被直接保存到 ht[1], ht[0] 不再进行任何添加操作，这样就保证了 ht[0] 包含的键值对数量会只减不增，并随着 rehash 操作的执行而最终变成空表。</p>
<h3 id="rehash-流程在数据量大的时候会有什么问题吗"><a href="#rehash-流程在数据量大的时候会有什么问题吗" class="headerlink" title="rehash 流程在数据量大的时候会有什么问题吗"></a>rehash 流程在数据量大的时候会有什么问题吗</h3><p>1、扩容期开始时，会先给 ht[1] 申请空间，所以在整个扩容期间，会同时存在 ht[0] 和 ht[1]，会占用额外的空间。</p>
<p>2、扩容期间同时存在 ht[0] 和 ht[1]，查找、删除、更新等操作有概率需要操作两张表，耗时会增加。</p>
<p>3、redis 在内存使用接近 maxmemory 并且有设置驱逐策略的情况下，出现 rehash 会使得内存占用超过 maxmemory，触发驱逐淘汰操作，导致 master/slave 均有有大量的 key 被驱逐淘汰，从而出现 master/slave 主从不一致。</p>
<h3 id="Redis的事件处理器"><a href="#Redis的事件处理器" class="headerlink" title="Redis的事件处理器"></a>Redis的事件处理器</h3><p>redis 基于 reactor 模式开发了自己的网络事件处理器，由4个部分组成：套接字、I/O 多路复用程序、文件事件分派器（dispatcher）、以及事件处理器。<br><img src="https://i.loli.net/2021/04/24/9rlMPFzw7fIH4EL.png" alt="7"></p>
<p>套接字：socket 连接，也就是客户端连接。当一个套接字准备好执行连接、写入、读取、关闭等操作时， 就会产生一个相应的文件事件。因为一个服务器通常会连接多个套接字， 所以多个文件事件有可能会并发地出现。</p>
<p>I/O 多路复用程序：提供 select、epoll、evport、kqueue 的实现，会根据当前系统自动选择最佳的方式。负责监听多个套接字，当套接字产生事件时，会向文件事件分派器传送那些产生了事件的套接字。</p>
<p>当多个文件事件并发出现时， I/O 多路复用程序会将所有产生事件的套接字都放到一个队列里面，然后通过这个队列，以有序、同步、每次一个套接字的方式向文件事件分派器传送套接字：当上一个套接字产生的事件被处理完毕之后，才会继续传送下一个套接字。</p>
<p>文件事件分派器：接收 I/O 多路复用程序传来的套接字， 并根据套接字产生的事件的类型， 调用相应的事件处理器。</p>
<p>事件处理器：事件处理器就是一个个函数， 定义了某个事件发生时， 服务器应该执行的动作。例如：建立连接、命令查询、命令写入、连接关闭等等。</p>
<h3 id="Redis-删除过期键的策略（缓存失效策略、数据过期策略）"><a href="#Redis-删除过期键的策略（缓存失效策略、数据过期策略）" class="headerlink" title="Redis 删除过期键的策略（缓存失效策略、数据过期策略）"></a>Redis 删除过期键的策略（缓存失效策略、数据过期策略）</h3><p>定时删除：在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。对内存最友好，对 CPU 时间最不友好。</p>
<p>惰性删除：放任键过期不管，但是每次获取键时，都检査键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。对 CPU 时间最优化，对内存最不友好。</p>
<p>定期删除：每隔一段时间，默认100ms，程序就对数据库进行一次检査，删除里面的过期键。至 于要删除多少过期键，以及要检査多少个数据库，则由算法决定。前两种策略的折中，对 CPU 时间和内存的友好程度较平衡。</p>
<p>Redis 使用惰性删除和定期删除。</p>
<h3 id="Redis-的内存驱逐（淘汰）策略"><a href="#Redis-的内存驱逐（淘汰）策略" class="headerlink" title="Redis 的内存驱逐（淘汰）策略"></a>Redis 的内存驱逐（淘汰）策略</h3><p>当 redis 的内存空间（maxmemory 参数配置）已经用满时，redis 将根据配置的驱逐策略（maxmemory-policy 参数配置），进行相应的动作。</p>
<p>当前 redis 的淘汰策略有以下8种。</p>
<p>noeviction：默认策略，不淘汰任何 key，直接返回错误</p>
<p>allkeys-lru：在所有的 key 中，使用 LRU 算法淘汰部分 key</p>
<p>allkeys-lfu：在所有的 key 中，使用 LFU 算法淘汰部分 key</p>
<p>allkeys-random：在所有的 key 中，随机淘汰部分 key</p>
<p>volatile-lru：在设置了过期时间的 key 中，使用 LRU 算法淘汰部分 key</p>
<p>volatile-lfu：在设置了过期时间的 key 中，使用 LFU 算法淘汰部分 key</p>
<p>volatile-random：在设置了过期时间的 key 中，随机淘汰部分 key</p>
<p>volatile-ttl：在设置了过期时间的 key 中，挑选 TTL（time to live，剩余时间）短的 key 淘汰</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>concurrenthashmap的原理</title>
    <url>/2021/05/15/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/concurrenthashmap/</url>
    <content><![CDATA[<hr>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在涉及到Java多线程开发时，如果我们使用HashMap可能会导致死锁问题，使用HashTable效率又不高。而ConcurrentHashMap既可以保持同步也可以提高并发效率，所以这个时候ConcurrentHashmap是我们最好的选择。</p>
<span id="more"></span>

<h2 id="为什么使用ConcurrentHashMap"><a href="#为什么使用ConcurrentHashMap" class="headerlink" title="为什么使用ConcurrentHashMap"></a>为什么使用ConcurrentHashMap</h2><p>在多线程环境中使用HashMap的put方法有可能导致程序死循环，因为多线程可能会导致HashMap形成环形链表，即链表的一个节点的next节点永不为null，就会产生死循环。这时，CPU的利用率接近100%，所以并发情况下不能使用HashMap。</p>
<p>HashTable通过使用synchronized保证线程安全，但在线程竞争激烈的情况下效率低下。因为当一个线程访问HashTable的同步方法时，其他线程只能阻塞等待占用线程操作完毕。</p>
<p>ConcurrentHashMap使用分段锁的思想，对于不同的数据段使用不同的锁，可以支持多个线程同时访问不同的数据段，这样线程之间就不存在锁竞争，从而提高了并发效率。</p>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><h3 id="jdk1-7"><a href="#jdk1-7" class="headerlink" title="jdk1.7"></a>jdk1.7</h3><p>在 JDK1.7 中 ConcurrentHashMap 采用了数组 + Segment + 分段锁的方式实现。</p>
<h4 id="Segment-分段锁"><a href="#Segment-分段锁" class="headerlink" title="Segment (分段锁)"></a>Segment (分段锁)</h4><p>ConcurrentHashMap 中的分段锁称为 Segment，它即类似于 HashMap 的结构，即内部拥有一个 Entry 数组，数组中的每个元素又是一个链表，同时又是一个<br>ReentrantLock（Segment 继承了 ReentrantLock）。</p>
<h4 id="内部结构"><a href="#内部结构" class="headerlink" title="内部结构"></a>内部结构</h4><p>ConcurrentHashMap 使用分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，<br>能够实现真正的并发访问。如下图是 ConcurrentHashMap 的内部结构图：<br><img src="https://i.loli.net/2021/04/04/RArqW3HnDogNyBQ.jpg" alt="concurrentHashMap1"><br>从上面的结构我们可以了解到，ConcurrentHashMap 定位一个元素的过程需要进行两次 Hash 操作。</p>
<p>第一次 Hash 定位到 Segment，第二次 Hash 定位到元素所在的链表的头部。</p>
<h4 id="该结构的优劣势"><a href="#该结构的优劣势" class="headerlink" title="该结构的优劣势"></a>该结构的优劣势</h4><p>优势：<br>写操作的时候可以只对元素所在的 Segment 进行加锁即可，不会影响到其他的 Segment，这样，在最理想的情况下，ConcurrentHashMap 可以最高同时支持<br>Segment 数量大小的写操作（刚好这些写操作都非常平均地分布在所有的 Segment 上）。</p>
<p>所以，通过这一种结构，ConcurrentHashMap 的并发能力可以大大的提高。</p>
<p>劣势：<br>这一种结构的带来的副作用是 Hash 的过程要比普通的 HashMap 要长</p>
<h3 id="jdk1-8"><a href="#jdk1-8" class="headerlink" title="jdk1.8"></a>jdk1.8</h3><p>1.7 已经解决了并发问题，并且能支持 N 个 Segment 这么多次数的并发，但依然存在 HashMap 在 1.7 版本中的问题。那么是什么问题呢？<br>很明显那就是查询遍历链表效率太低。</p>
<p>JDK8 中 ConcurrentHashMap 参考了 JDK8 HashMap 的实现，采用了数组 + 链表 + 红黑树的实现方式来设计，内部大量采用 CAS 操作，这里我简要介绍下 CAS。</p>
<p>CAS 是 compare and swap 的缩写，即我们所说的比较交换。cas 是一种基于锁的操作，而且是乐观锁。在 java 中锁分为乐观锁和悲<br>观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不<br>加锁来处理资源，比如通过给记录加 version 来获取数据，性能较悲观锁有很大的提高。</p>
<p>CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值 (B)。如果内存地址里面的值和 A 的值是一样的，那么就将内存里面<br>的值更新成 B。CAS 是通过无限循环来获取数据的，若果在第一轮循环中，a 线程获取地址里面的值被 b 线程修改了，那么 a 线程需要自<br>旋，到下次循环才有可能机会执行。</p>
<p>JDK8 中彻底放弃了 Segment 转而采用的是 Node，其设计思想也不再是 JDK1.7 中的分段锁思想。</p>
<p>Node：保存 key，value 及 key 的 hash 值的数据结构。其中 value 和 next 都用 volatile 修饰，保证并发的可见性。</p>
<p>看看put方法的源码，源码如下：</p>
<figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">public V put(K key, V value) &#123;</span><br><span class="line">    <span class="keyword">return</span> putVal(key, value, <span class="literal">false</span>);</span><br><span class="line"> 　　&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Implementation for put and putIfAbsent */</span></span><br><span class="line">final V putVal(K key, V value, <span class="built_in">boolean</span> onlyIfAbsent) &#123;　　　　　</span><br><span class="line">    <span class="comment">//(1）若为空 抛异常</span></span><br><span class="line">    <span class="keyword">if</span> (key == <span class="literal">null</span> || value == <span class="literal">null</span>) throw <span class="keyword">new</span> NullPointerException();　　　　　</span><br><span class="line">    <span class="comment">//(2) 计算hash值</span></span><br><span class="line">    int <span class="built_in">hash</span> = spread(key.hashCode());</span><br><span class="line">    int binCount = <span class="number">0</span>;　　　　　</span><br><span class="line">    <span class="comment">//(3)</span></span><br><span class="line">    <span class="keyword">for</span> (Node&lt;K,V&gt;[] <span class="literal">tab</span> = table;;) &#123;</span><br><span class="line">        Node&lt;K,V&gt; f; int n, i, fh;　　　　　　　</span><br><span class="line">        <span class="comment">//(4) 判断是否需要进行初始化。</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">tab</span> == <span class="literal">null</span> || (n = <span class="literal">tab</span>.<span class="built_in">length</span>) == <span class="number">0</span>)</span><br><span class="line">            <span class="literal">tab</span> = initTable();　　　　　　　</span><br><span class="line">        <span class="comment">//(5)f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((f = tabAt(<span class="literal">tab</span>, i = (n - <span class="number">1</span>) &amp; <span class="built_in">hash</span>)) == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (casTabAt(<span class="literal">tab</span>, i, <span class="literal">null</span>,</span><br><span class="line">                         <span class="keyword">new</span> Node&lt;K,V&gt;(<span class="built_in">hash</span>, key, value, <span class="literal">null</span>)))</span><br><span class="line">                <span class="keyword">break</span>;                   <span class="comment">// no lock when adding to empty bin</span></span><br><span class="line">        &#125;　　　　　　　</span><br><span class="line">        <span class="comment">//(6)如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((fh = f.<span class="built_in">hash</span>) == MOVED)</span><br><span class="line">            <span class="literal">tab</span> = helpTransfer(<span class="literal">tab</span>, f);</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            V oldVal = <span class="literal">null</span>;　　　　　　　　　　</span><br><span class="line">            <span class="comment">//(7)如果都不满足，则利用 synchronized 锁写入数据。结点上锁 这里的结点可以理解为hash值相同组成的链表的头结点</span></span><br><span class="line">            synchronized (f) &#123;</span><br><span class="line">                <span class="keyword">if</span> (tabAt(<span class="literal">tab</span>, i) == f) &#123;　　　　　　　　　　　　　　</span><br><span class="line">                    <span class="comment">//(8)fh〉0 说明这个节点是一个链表的节点 不是树的节点.</span></span><br><span class="line">                    <span class="keyword">if</span> (fh &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                        binCount = <span class="number">1</span>;　　　　　　　　　　　　　　　　　</span><br><span class="line">                        <span class="comment">//(9)在这里遍历链表所有的结点</span></span><br><span class="line">                        <span class="keyword">for</span> (Node&lt;K,V&gt; e = f;; ++binCount) &#123;</span><br><span class="line">                            K ek;　　　　　　　　　　　　　　　　　　　</span><br><span class="line">                            <span class="comment">//（10）如果hash值和key值相同 则修改对应结点的value值</span></span><br><span class="line">                            <span class="keyword">if</span> (e.<span class="built_in">hash</span> == <span class="built_in">hash</span> &amp;&amp;</span><br><span class="line">                                ((ek = e.key) == key ||</span><br><span class="line">                                 (ek != <span class="literal">null</span> &amp;&amp; key.<span class="built_in">equals</span>(ek)))) &#123;</span><br><span class="line">                                oldVal = e.val;</span><br><span class="line">                                <span class="keyword">if</span> (!onlyIfAbsent)</span><br><span class="line">                                    e.val = value;</span><br><span class="line">                                <span class="keyword">break</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            Node&lt;K,V&gt; pred = e;　　　　　　　　　　　　　　　　　　　</span><br><span class="line">                            <span class="comment">//(11)如果遍历到了最后一个结点，那么就证明新的节点需要插入 就把它插入在链表尾部</span></span><br><span class="line">                            <span class="keyword">if</span> ((e = e.next) == <span class="literal">null</span>) &#123;</span><br><span class="line">                                pred.next = <span class="keyword">new</span> Node&lt;K,V&gt;(<span class="built_in">hash</span>, key,</span><br><span class="line">                                                          value, <span class="literal">null</span>);</span><br><span class="line">                                <span class="keyword">break</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;　　　　　　　　　　　　　　</span><br><span class="line">                    <span class="comment">//（12）如果这个节点是树节点，就按照树的方式插入值</span></span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span> (f instanceof TreeBin) &#123;</span><br><span class="line">                        Node&lt;K,V&gt; p;</span><br><span class="line">                        binCount = <span class="number">2</span>;</span><br><span class="line">                        <span class="keyword">if</span> ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(<span class="built_in">hash</span>, key,</span><br><span class="line">                                                       value)) != <span class="literal">null</span>) &#123;</span><br><span class="line">                            oldVal = p.val;</span><br><span class="line">                            <span class="keyword">if</span> (!onlyIfAbsent)</span><br><span class="line">                                p.val = value;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (binCount != <span class="number">0</span>) &#123;　　　　　　　　　　　　</span><br><span class="line">                <span class="comment">//（13）如果链表长度已经达到临界值8 就需要把链表转换为树结构。如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。</span></span><br><span class="line">                <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD)</span><br><span class="line">                    treeifyBin(<span class="literal">tab</span>, i);</span><br><span class="line">                <span class="keyword">if</span> (oldVal != <span class="literal">null</span>)</span><br><span class="line">                    <span class="keyword">return</span> oldVal;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;　　　　　</span><br><span class="line">    <span class="comment">//代码（14）将当前ConcurrentHashMap的元素数量+1</span></span><br><span class="line">    addCount(<span class="number">1</span>L, binCount);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>concurrenthashmap的原理自己目前也不是很清楚，以后清楚了再继续补充。</p>
<h3 id="CAS原理"><a href="#CAS原理" class="headerlink" title="CAS原理"></a>CAS原理</h3><p>待学习补充。。。。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>jdk1.8</tag>
      </tags>
  </entry>
  <entry>
    <title>jdk1.8 里的 HashMap</title>
    <url>/2021/04/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/jdk1-8-%E9%87%8C%E7%9A%84-HashMap/</url>
    <content><![CDATA[<hr>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>HashMap是一个比较经典的数据结构，平时代码里面也用到过很多HashMap，现在让我们来分析一下HashMap的基础数据结构和源码。</p>
<span id="more"></span>

<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>和Jdk1.7不同，在1.8中HashMap引入了红黑树的结构，即由数组+链表+红黑树组成，图如下：<br><img src="https://i.loli.net/2021/04/03/hbLgAFHxvmUpnze.png" alt="HashMap"><br>引入红黑树的目的是因为在 hash 冲突严重时（链表过长）的查找性能，使用链表的查找性能是O(n)，而使用红黑树是 O(logn)。</p>
<blockquote>
<p>那什么时候用链表，什么时候用红黑树呢？</p>
</blockquote>
<p>在HashMap源码中有两个参数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">TREEIFY_THRESHOLD</span> <span class="operator">=</span> <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">UNTREEIFY_THRESHOLD</span> <span class="operator">=</span> <span class="number">6</span>;</span><br></pre></td></tr></table></figure>
<p>对于插入，第一个代表链表当同一个索引位置的节点在新增后达到9个（阈值8）：如果此时数组长度大于等于 64，则会触发链表节点转红黑树节点（treeifyBin）；<br>而如果数组长度小于64，则不会触发链表转红黑树，而是会进行扩容，因为此时的数据量还比较小。</p>
<p>对于移除，当同一个索引位置的节点在移除后达到 6 个，并且该索引位置的节点为红黑树节点，会触发红黑树节点转链表节点（untreeify）。</p>
<blockquote>
<p>这里有个问题，为什么阈值是8，而不是9或者10？<br>又是一段长长的注释</p>
</blockquote>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="comment">* Because TreeNodes are about twice the size of regular nodes, we</span></span><br><span class="line"><span class="comment"> * use them only when bins contain enough nodes to warrant use</span></span><br><span class="line"><span class="comment"> * (see TREEIFY_THRESHOLD). And when they become too small (due to</span></span><br><span class="line"><span class="comment"> * removal or resizing) they are converted back to plain bins.  In</span></span><br><span class="line"><span class="comment"> * usages with well-distributed user hashCodes, tree bins are</span></span><br><span class="line"><span class="comment"> * rarely used.  Ideally, under random hashCodes, the frequency of</span></span><br><span class="line"><span class="comment"> * nodes in bins follows a Poisson distribution</span></span><br><span class="line"><span class="comment"> * (http://en.wikipedia.org/wiki/Poisson_distribution) with a</span></span><br><span class="line"><span class="comment"> * parameter of about 0.5 on average for the default resizing</span></span><br><span class="line"><span class="comment"> * threshold of 0.75, although with a large variance because of</span></span><br><span class="line"><span class="comment"> * resizing granularity. Ignoring variance, the expected</span></span><br><span class="line"><span class="comment"> * occurrences of list size k are (exp(-0.5) * pow(0.5, k) /</span></span><br><span class="line"><span class="comment"> * factorial(k)). The first values are:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 0:    0.60653066</span></span><br><span class="line"><span class="comment"> * 1:    0.30326533</span></span><br><span class="line"><span class="comment"> * 2:    0.07581633</span></span><br><span class="line"><span class="comment"> * 3:    0.01263606</span></span><br><span class="line"><span class="comment"> * 4:    0.00157952</span></span><br><span class="line"><span class="comment"> * 5:    0.00015795</span></span><br><span class="line"><span class="comment"> * 6:    0.00001316</span></span><br><span class="line"><span class="comment"> * 7:    0.00000094</span></span><br><span class="line"><span class="comment"> * 8:    0.00000006</span></span><br><span class="line"><span class="comment"> * more: less than 1 in ten million</span></span><br></pre></td></tr></table></figure>
<p>大概意思就是说，在负载因子是0.75的时候，使用随机的哈希码，节点分布在 hash 桶中的频率遵循泊松分布，按照泊松分布的公式计<br>算，链表中节点个数为8时的概率为 0.00000006，这个概率足够低了，并且到8个节点时，红黑树的性能优势也会开始展现出来，因此<br>8是一个较合理的数字。</p>
<p>红黑树节点大小约为链表节点的2倍，在节点太少时，红黑树的查找性能优势并不明显，付出2倍空间的代价作者觉得不值得。</p>
<p>这些都是出于时间和空间上权衡的考虑。</p>
<blockquote>
<p>转回链表结构为什么是8而不是6？</p>
</blockquote>
<p>如果我们设置节点多于8个转红黑树，少于8个就马上转链表，当节点个数在8徘徊时，就会频繁进行红黑树和链表的转换，造成性能的损耗。</p>
<blockquote>
<p>那 HashMap 有哪些重要属性？分别用于做什么的？</p>
</blockquote>
<p>除了用来存储我们的节点 table 数组外，HashMap 还有以下几个重要属性：1）size：HashMap 已经存储的节点个数；2）threshold：扩容阈值，当 HashMap 的个数达到该值，触发扩容。3）loadFactor：负载因子，扩容阈值 = 容量 * 负载因子</p>
<blockquote>
<p>threshold 除了用于存放扩容阈值还有其他作用吗</p>
</blockquote>
<p>在我们新建 HashMap 对象时， threshold 还会被用来存初始化时的容量。HashMap 直到我们第一次插入节点时，才会对 table 进行初始化，避免不必要的空间浪费。</p>
<blockquote>
<p>HashMap 的默认初始容量是多少？HashMap 的容量有什么限制吗？</p>
</blockquote>
<p>默认初始容量是16。HashMap 的容量必须是2的N次方，HashMap 会根据我们传入的容量计算一个大于等于该容量的最小的2的N次方，例如传 9，容量为16。<br>又是一段优美的源码欣赏</p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">static final <span class="built_in">int</span> tableSizeFor(<span class="built_in">int</span> cap) &#123;</span><br><span class="line">    <span class="built_in">int</span> <span class="built_in">n</span> = cap - <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">n</span> |= <span class="built_in">n</span> &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">n</span> |= <span class="built_in">n</span> &gt;&gt;&gt; <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">n</span> |= <span class="built_in">n</span> &gt;&gt;&gt; <span class="number">4</span>;</span><br><span class="line">    <span class="built_in">n</span> |= <span class="built_in">n</span> &gt;&gt;&gt; <span class="number">8</span>;</span><br><span class="line">    <span class="built_in">n</span> |= <span class="built_in">n</span> &gt;&gt;&gt; <span class="number">16</span>;</span><br><span class="line">    return (<span class="built_in">n</span> &lt; <span class="number">0</span>) ? <span class="number">1</span> <span class="symbol">:</span> (<span class="built_in">n</span> &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY <span class="symbol">:</span> <span class="built_in">n</span> + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>千言万语不如一张图：<br><img src="https://i.loli.net/2021/04/03/aWmpX8KIZBPiTtN.png" alt="HashMap1"><br>这5个公式会通过最高位的1，拿到2个1、4个1、8个1、16个1、32个1。当然，有多少个1，取决于我们的入参有多大，但我们肯定的是经过这5个计算，得到的值是一个低位全是1的值，最后返回的时候 +1，则会得到1个比n 大的 2 的N次方。</p>
<p>然后回头看int n = cap - 1;很nice，就是处理2^n本身</p>
<blockquote>
<p>HashMap为什么必须是2^n方？</p>
</blockquote>
<p>这个跟计算索引方式有关：(n - 1) &amp; hash，当b为2的N次方的时候，n-1低位全是1，此时n-1进行&amp;运算的结果都是低N位，达到取模的效果，实现均匀分布。实际上，这个设计就是基于公式：x mod 2^n = x &amp; (2^n - 1)，因为 &amp; 运算比 mod 具有更高的效率。</p>
<h2 id="HashMap的插入流程"><a href="#HashMap的插入流程" class="headerlink" title="HashMap的插入流程"></a>HashMap的插入流程</h2><p>再来一次……千言万语不如一张图：<br><img src="https://i.loli.net/2021/04/03/oPDsjvYwVRfkyqe.png" alt="HashMap3"><br>先上一段源码：</p>
<figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">final V putVal(int <span class="built_in">hash</span>, K key, V value, <span class="built_in">boolean</span> onlyIfAbsent,</span><br><span class="line">               <span class="built_in">boolean</span> evict) &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] <span class="literal">tab</span>; Node&lt;K,V&gt; p; int n, i;</span><br><span class="line">    <span class="comment">//首先判断是不是为空，如果为空，扩容</span></span><br><span class="line">    <span class="keyword">if</span> ((<span class="literal">tab</span> = table) == <span class="literal">null</span> || (n = <span class="literal">tab</span>.<span class="built_in">length</span>) == <span class="number">0</span>)</span><br><span class="line">        n = (<span class="literal">tab</span> = <span class="built_in">resize</span>()).<span class="built_in">length</span>;</span><br><span class="line">    <span class="comment">//计算索引，如果之前没有放过数据，直接放入</span></span><br><span class="line">    <span class="keyword">if</span> ((p = <span class="literal">tab</span>[i = (n - <span class="number">1</span>) &amp; <span class="built_in">hash</span>]) == <span class="literal">null</span>)</span><br><span class="line">        <span class="literal">tab</span>[i] = newNode(<span class="built_in">hash</span>, key, value, <span class="literal">null</span>);</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">//进入这里说明索引位置已经放入过数据了</span></span><br><span class="line">        Node&lt;K,V&gt; e; K k;</span><br><span class="line">    <span class="comment">//判断put的数据和之前的数据是否重复</span></span><br><span class="line">        <span class="keyword">if</span> (p.<span class="built_in">hash</span> == <span class="built_in">hash</span> &amp;&amp;</span><br><span class="line">            ((k = p.key) == key || (key != <span class="literal">null</span> &amp;&amp; key.<span class="built_in">equals</span>(k)))) </span><br><span class="line">            e = p;  <span class="comment">//key的地址或key的equals()只要有一个相等就认为key重复了，就直接覆盖原来key的value</span></span><br><span class="line">    <span class="comment">//判断是否是红黑树，如果是红黑树就直接插入树中</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (p instanceof TreeNode)</span><br><span class="line">            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, <span class="literal">tab</span>, <span class="built_in">hash</span>, key, value);</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//如果不是红黑树，就遍历每个节点，判断链表长度是否大于8，如果大于就转换为红黑树</span></span><br><span class="line">            <span class="keyword">for</span> (int binCount = <span class="number">0</span>; ; ++binCount) &#123;</span><br><span class="line">                <span class="keyword">if</span> ((e = p.next) == <span class="literal">null</span>) &#123;</span><br><span class="line">                    p.next = newNode(<span class="built_in">hash</span>, key, value, <span class="literal">null</span>);</span><br><span class="line">                    <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="number">1</span>) <span class="comment">// -1 for 1st</span></span><br><span class="line">                        treeifyBin(<span class="literal">tab</span>, <span class="built_in">hash</span>);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//判断索引每个元素的key是否可要插入的key相同，如果相同就直接覆盖</span></span><br><span class="line">                <span class="keyword">if</span> (e.<span class="built_in">hash</span> == <span class="built_in">hash</span> &amp;&amp;</span><br><span class="line">                    ((k = e.key) == key || (key != <span class="literal">null</span> &amp;&amp; key.<span class="built_in">equals</span>(k))))</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                p = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果e不是null，说明没有迭代到最后就跳出了循环，说明链表中有相同的key，因此只需要将value覆盖，并将oldValue返回即可</span></span><br><span class="line">        <span class="keyword">if</span> (e != <span class="literal">null</span>) &#123; <span class="comment">// existing mapping for key</span></span><br><span class="line">            V oldValue = e.value;</span><br><span class="line">            <span class="keyword">if</span> (!onlyIfAbsent || oldValue == <span class="literal">null</span>)</span><br><span class="line">                e.value = value;</span><br><span class="line">            afterNodeAccess(e);</span><br><span class="line">            <span class="keyword">return</span> oldValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ++modCount; <span class="comment">//记录修改次数</span></span><br><span class="line">    <span class="keyword">if</span> (++size &gt; threshold) <span class="comment">//如果元素数量大于临界值，则进行扩容</span></span><br><span class="line">        <span class="built_in">resize</span>();</span><br><span class="line">    afterNodeInsertion(evict);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>hash值是用一下方法得到的。</p>
<figure class="highlight processing"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="title function_">hash</span>(<span class="built_in">Object</span> <span class="built_in">key</span>) &#123;</span><br><span class="line">    <span class="type">int</span> h;</span><br><span class="line">    <span class="title function_">return</span> (<span class="built_in">key</span> == <span class="literal">null</span>) ? <span class="number">0</span> : (h = <span class="built_in">key</span>.<span class="property">hashCode</span>()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>取hash值很简单，拿到 key 的 hashCode，并将 hashCode 的高16位和 hashCode 进行异或（XOR）运算，得到最终的 hash 值。</p>
<blockquote>
<p>为什么要将 hashCode 的高16位参与运算？</p>
</blockquote>
<p>主要是为了在 table 的长度较小的时候，让高位也参与运算，并且不会有太大的开销。否则如果n-1太小，为0111，结果只会取决于hash值的低三位，冲突大大增加。</p>
<blockquote>
<p>扩容（resize）流程是什么样子？</p>
</blockquote>
<p>来吧，千言万语不如一张图：<br><img src="https://i.loli.net/2021/04/03/mcf2OYU49w8xQET.png" alt="HashMap3"><br>在上一段源码：</p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> Node&lt;K,V&gt;[] resize() &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] oldTab = table;</span><br><span class="line">    <span class="keyword">int</span> oldCap = (oldTab == <span class="keyword">null</span>) ? <span class="number">0</span> : oldTab.length;</span><br><span class="line">    <span class="keyword">int</span> oldThr = threshold;</span><br><span class="line">    <span class="keyword">int</span> newCap, newThr = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (oldCap &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (oldCap &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">            threshold = Integer.MAX_VALUE;</span><br><span class="line">            <span class="keyword">return</span> oldTab;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((newCap = oldCap &lt;&lt; <span class="number">1</span>) &lt; MAXIMUM_CAPACITY &amp;&amp;</span><br><span class="line">                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)</span><br><span class="line">            newThr = oldThr &lt;&lt; <span class="number">1</span>; <span class="comment">// double threshold</span></span><br><span class="line">    &#125;</span><br><span class="line">     <span class="comment">//使用带有初始容量的构造器时，table容量为初始化得到的threshold</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (oldThr &gt; <span class="number">0</span>) <span class="comment">// initial capacity was placed in threshold</span></span><br><span class="line">        newCap = oldThr;</span><br><span class="line">    <span class="keyword">else</span> &#123;  <span class="comment">//默认构造器下进行扩容</span></span><br><span class="line">        <span class="comment">// zero initial threshold signifies using defaults</span></span><br><span class="line">        newCap = DEFAULT_INITIAL_CAPACITY;</span><br><span class="line">        newThr = (<span class="keyword">int</span>)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//使用带有初始容量的构造器在此处进行扩容</span></span><br><span class="line">    <span class="keyword">if</span> (newThr == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">float</span> ft = (<span class="keyword">float</span>)newCap * loadFactor;</span><br><span class="line">        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (<span class="keyword">float</span>)MAXIMUM_CAPACITY ?</span><br><span class="line">                  (<span class="keyword">int</span>)ft : Integer.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">    threshold = newThr;</span><br><span class="line">    @SuppressWarnings(&#123;<span class="string">&quot;rawtypes&quot;</span>,<span class="string">&quot;unchecked&quot;</span>&#125;)</span><br><span class="line">        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node[newCap];</span><br><span class="line">    table = newTab;</span><br><span class="line">    <span class="keyword">if</span> (oldTab != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; oldCap; ++j) &#123;</span><br><span class="line">            Node&lt;K,V&gt; e;</span><br><span class="line">            <span class="keyword">if</span> ((e = oldTab[j]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                oldTab[j] = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">if</span> (e.<span class="keyword">next</span> == <span class="keyword">null</span>)</span><br><span class="line">                    <span class="comment">// 当前index没有发生hash冲突，直接对2取模，即移位运算hash &amp;（2^n -1）</span></span><br><span class="line">                    <span class="comment">// 扩容都是按照2的幂次方扩容，因此newCap = 2^n</span></span><br><span class="line">                    newTab[e.hash &amp; (newCap - <span class="number">1</span>)] = e;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (e <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                    <span class="comment">// 当前index对应的节点为红黑树，这里篇幅比较长且需要了解其数据结构跟算法，因此不进行详解，当树的个数小于等于UNTREEIFY_THRESHOLD则转成链表</span></span><br><span class="line">                    ((TreeNode&lt;K,V&gt;)e).split(<span class="keyword">this</span>, newTab, j, oldCap);</span><br><span class="line">                <span class="keyword">else</span> &#123; <span class="comment">// preserve order</span></span><br><span class="line">                    <span class="comment">// 把当前index对应的链表分成两个链表，减少扩容的迁移量</span></span><br><span class="line">                    Node&lt;K,V&gt; loHead = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line">                    Node&lt;K,V&gt; hiHead = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line">                    Node&lt;K,V&gt; <span class="keyword">next</span>;</span><br><span class="line">                    <span class="keyword">do</span> &#123;</span><br><span class="line">                        <span class="keyword">next</span> = e.<span class="keyword">next</span>;</span><br><span class="line">                        <span class="keyword">if</span> ((e.hash &amp; oldCap) == <span class="number">0</span>) &#123;</span><br><span class="line">                         <span class="comment">// 扩容后不需要移动的链表</span></span><br><span class="line">                            <span class="keyword">if</span> (loTail == <span class="keyword">null</span>)</span><br><span class="line">                                loHead = e;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                loTail.<span class="keyword">next</span> = e;</span><br><span class="line">                            loTail = e;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="comment">// 扩容后需要移动的链表</span></span><br><span class="line">                            <span class="keyword">if</span> (hiTail == <span class="keyword">null</span>)</span><br><span class="line">                                hiHead = e;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                hiTail.<span class="keyword">next</span> = e;</span><br><span class="line">                            hiTail = e;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; <span class="keyword">while</span> ((e = <span class="keyword">next</span>) != <span class="keyword">null</span>);</span><br><span class="line">                    <span class="keyword">if</span> (loTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        loTail.<span class="keyword">next</span> = <span class="keyword">null</span>;</span><br><span class="line">                        newTab[j] = loHead;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span> (hiTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        hiTail.<span class="keyword">next</span> = <span class="keyword">null</span>;</span><br><span class="line">                        newTab[j + oldCap] = hiHead;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> newTab;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>红黑树和链表都是通过 e.hash &amp; oldCap == 0 来定位在新表的索引位置，这是为什么？</p>
</blockquote>
<pre><code>举个栗子来说一下这种情况：
设：oldCap=16 二进制为：0001 0000
oldCap-1=15 二进制为：0000 1111
e1.hash=10 二进制为：0000 1010
e2.hash=26 二进制为：0101 1010
e1在扩容前的位置为：e1.hash &amp; oldCap-1  结果为：0000 1010 
e2在扩容前的位置为：e2.hash &amp; oldCap-1  结果为：0000 1010 
结果相同，所以e1和e2在扩容前在同一个链表上，这是扩容之前的状态。
        
现在扩容后，需要重新计算元素的位置，在扩容前的链表中计算地址的方式为e.hash &amp; oldCap-1
那么在扩容后应该也这么计算呀，扩容后的容量为oldCap*2=32 0010 0000 newCap=32，新的计算
方式应该为
e1.hash &amp; newCap-1 
即：0000 1010 &amp; 0001 1111 
结果为0000 1010与扩容前的位置完全一样。
e2.hash &amp; newCap-1 
即：0101 1010 &amp; 0001 1111 
结果为0001 1010,为扩容前位置+oldCap。
而这里却没有e.hash &amp; newCap-1 而是 e.hash &amp; oldCap，其实这两个是等效的，都是判断倒数第五位
是0，还是1。如果是0，则位置不变，是1则位置改变为扩容前位置+oldCap。

因此计算新表的索引位置时，只取决于新表在高位多出来的这一位，而这一位的值刚好等于 oldCap。
因为只取决于这一位，所以只会存在两种情况：
1）(e.hash &amp; oldCap) == 0 ，则新表索引位置为“原索引位置” ；
2）(e.hash &amp; oldCap) != 0，则新表索引位置为“原索引 + oldCap 位置”。
</code></pre>
<p>牛逼！！什么？还不够形象？来大声跟我喊一句,千言万语不如两张张图：<br><img src="https://i.loli.net/2021/04/03/75RcIK3bUB6Lnuh.png" alt="HashMap4"><br><img src="https://i.loli.net/2021/04/03/3XTbdqwsWzo9ZM6.png" alt="HashMap5"></p>
<h2 id="死锁循环"><a href="#死锁循环" class="headerlink" title="死锁循环"></a>死锁循环</h2><blockquote>
<p>什么是死锁循环？</p>
</blockquote>
<p>导致死循环的根本原因是 JDK 1.7 扩容采用的是“头插法”，会导致同一索引位置的节点在扩容后顺序反掉。而 JDK 1.8 之后采用的是“尾插法”，扩容后节点顺序不会反掉，不存在死循环问题。</p>
<p>JDK1.7代码走一波：</p>
<figure class="highlight axapta"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> transfer(Entry[] newTable) &#123;</span><br><span class="line">    Entry[] src = table;</span><br><span class="line">    <span class="built_in">int</span> newCapacity = newTable.length;</span><br><span class="line">    <span class="keyword">for</span> (<span class="built_in">int</span> j = <span class="number">0</span>; j &lt; src.length; j++) &#123;</span><br><span class="line">        Entry&lt;K,V&gt; e = src[j];</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="literal">null</span>) &#123;</span><br><span class="line">            src[j] = <span class="literal">null</span>;</span><br><span class="line">            <span class="keyword">do</span> &#123;</span><br><span class="line">                Entry&lt;K,V&gt; <span class="keyword">next</span> = e.<span class="keyword">next</span>;</span><br><span class="line">                <span class="built_in">int</span> i = indexFor(e.hash, newCapacity);</span><br><span class="line">                e.<span class="keyword">next</span> = newTable[i];</span><br><span class="line">                newTable[i] = e;</span><br><span class="line">                e = <span class="keyword">next</span>;</span><br><span class="line">            &#125; <span class="keyword">while</span> (e != <span class="literal">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>For example:我们有1个容量为2的 HashMap，loadFactor=0.75，此时线程1和线程2 同时往该 HashMap 插入一个数据，都触发了扩容流程，接着有以下流程。</p>
<p>1）在2个线程都插入节点，触发扩容流程之前，此时的结构如下图。<br><img src="https://i.loli.net/2021/04/03/hB4g7oLI1y2uFlZ.png" alt="HashMap6"></p>
<p>2）线程1进行扩容，执行到代码：Entry&lt;K,V&gt; next = e.next 后被调度挂起，此时的结构如下图。<br><img src="https://i.loli.net/2021/04/03/DdA3McI5nGEphW8.png" alt="HashMap7"></p>
<p>3）线程1被挂起后，线程2进入扩容流程，并走完整个扩容流程，此时的结构如下图。<br><img src="https://i.loli.net/2021/04/03/j2sgUqQWebEiJuz.png" alt="HashMap8"></p>
<p>由于两个线程操作的是同一个 table，所以该图又可以画成如下图。<br><img src="https://i.loli.net/2021/04/03/y47hRprbWsLmOeg.png" alt="HashMap9"></p>
<p>4）线程1恢复后，继续走完第一次的循环流程，此时的结构如下图。<br><img src="https://i.loli.net/2021/04/03/eqg42DvnuzXBkSQ.png" alt="HashMap10"></p>
<p>5）线程1继续走完第二次循环，此时的结构如下图。<br><img src="https://i.loli.net/2021/04/03/S9TYNmsfMUtxiQ1.png" alt="HashMap11"></p>
<p>6）线程1继续执行第三次循环，执行到 e.next = newTable[i]时形成环，执行完第三次循环的结构如下图。<br><img src="https://i.loli.net/2021/04/03/ojqR2gk35QUOASP.png" alt="HashMap12"><br>如果此时线程1调用 map.get(11) ，悲剧就出现了。<br>当然HashMap仍然是不安全的,所以在多线程并发条件下推荐使用ConcurrentHashMap。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/v123411739/article/details/106324537">https://blog.csdn.net/v123411739/article/details/106324537</a><br><a href="https://blog.csdn.net/qq_37113604/article/details/81353626">https://blog.csdn.net/qq_37113604/article/details/81353626</a></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>jdk1.8</tag>
      </tags>
  </entry>
  <entry>
    <title>面试必问的Redis：高可用解决方案哨兵、集群</title>
    <url>/2021/04/26/redis/Redis%EF%BC%9A%E9%AB%98%E5%8F%AF%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E5%93%A8%E5%85%B5%E3%80%81%E9%9B%86%E7%BE%A4%E2%80%9D/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>哨兵和集群的两种高可用解决方案，但是两者在保证高可用上的实现基本是一致的，因为集群模式的高可用解决方案基本就是“照搬”哨兵模式的。</p>
<p>集群可以认为就是用来代替哨兵的，解决哨兵存在的一些问题，同时提供更优秀的特性。</p>
<p>因为现在基本不会使用到哨兵模式，哨兵模式可以说基本只存在于面试中，同时由于哨兵的内容在集群中都有类似的，所以本文对哨兵的介绍会比较简单。</p>
<span id="more"></span>

<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="哨兵是什么"><a href="#哨兵是什么" class="headerlink" title="哨兵是什么"></a>哨兵是什么</h3><p>哨兵（Sentinel） 是 Redis 的高可用性解决方案：由一个或多个 Sentinel 实例组成的 Sentinel 系统可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器。</p>
<p>Sentinel 可以在被监视的主服务器进入下线状态时，自动将下线主服务器的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。</p>
<h3 id="哨兵故障检测"><a href="#哨兵故障检测" class="headerlink" title="哨兵故障检测"></a>哨兵故障检测</h3><h4 id="检查主观下线状态"><a href="#检查主观下线状态" class="headerlink" title="检查主观下线状态"></a>检查主观下线状态</h4><p>在默认情况下，Sentinel 会以每秒一次的频率向所有与它创建了命令连接的实例（包括主服务器、从服务器、其他 Sentinel 在内）发送 PING 命令，并通过实例返回的 PING 命令回复来判断实例是否在线。</p>
<p>如果一个实例在 down-after-miliseconds 毫秒内，连续向 Sentinel 返回无效回复，那么 Sentinel 会修改这个实例所对应的实例结构，在结构的 flags 属性中设置 SRI_S_DOWN 标识，以此来表示这个实例已经进入主观下线状态。</p>
<h4 id="检查客观下线状态"><a href="#检查客观下线状态" class="headerlink" title="检查客观下线状态"></a>检查客观下线状态</h4><p>当 Sentinel 将一个主服务器判断为主观下线之后，为了确定这个主服务器是否真的下线了，它会向同样监视这一服务器的其他 Sentinel 进行询问，看它们是否也认为主服务器已经进入了下线状态（可以是主观下线或者客观下线）。</p>
<p>当 Sentinel 从其他 Sentinel 那里接收到足够数量（quorum，可配置）的已下线判断之后，Sentinel 就会将服务器置为客观下线，在 flags 上打上 SRI_O_DOWN 标识，并对主服务器执行故障转移操作。</p>
<h3 id="哨兵故障转移流程"><a href="#哨兵故障转移流程" class="headerlink" title="哨兵故障转移流程"></a>哨兵故障转移流程</h3><p>当哨兵监测到某个主节点客观下线之后，就会开始故障转移流程。核心流程如下：<br>1、发起一次选举，选举出领头 Sentinel</p>
<p>2、领头 Sentinel 在已下线主服务器的所有从服务器里面，挑选出一个从服务器，并将其升级为新的主服务器。</p>
<p>3、领头 Sentinel 将剩余的所有从服务器改为复制新的主服务器。</p>
<p>4、领头 Sentinel 更新相关配置信息，当这个旧的主服务器重新上线时，将其设置为新的主服务器的从服务器。</p>
<h3 id="选举领头哨兵"><a href="#选举领头哨兵" class="headerlink" title="选举领头哨兵"></a>选举领头哨兵</h3><p>当一个主服务器被判断为客观下线时，监视这个下线主服务器的各个 Sentinel 会进行协商，选举出一个领头 Sentinel，并由领头 Sentinel 对下线主服务器执行故障转移操作。Redis 选举领头 Sentinei 的流程如下：</p>
<p>1、当 Sentinel 发现自己监视的主服务器进入客观下线时，会发起一次选举：将 current_epoch（集群纪元）加1，向其他监视该 master 的 Sentinel 发送拉票命令：SENTINEL is-master-down-by-addr，要求目标 Sentinel 将选票投给自己。</p>
<p>2、目标 Sentinel  在接收到 SENTINEL is-master-down-by-addr 命令之后，会判断自己是否已经在本届选举投过票，如果没有则会将选票投给源 Sentinel，最后回复 leader 和 leader_epoch，代表自己所投的局部领头 Sentinel 的运行ID和配置纪元。</p>
<p>3、源 Sentinel 收到回复后，会将目标 Sentinel 的投票信息记录下来，用于后续统计。</p>
<p>4、Sentinel 中同样有自己的时间事件会被定期触发，当 Sentinel 状态为：SENTINEL_FAILOVER_STATE_WAIT_START，会触发选举的投票结果统计。如果某个 Sentinel 获得超过半数以上的选票（&gt;=voters/2+1），而且票数要大于等于 quorum，那么这个 Sentinel 将成为领头 Sentinel 。</p>
<p>因为领头 Sentinel 的产生需要半数以上 Sentinel 的支持，并且每个 Sentinel 在每个配置纪元里面只能投一次票 ，所以在一个配置纪元里面，只会出现一个领头 Sentinel 。</p>
<p>5、如果在一个配置纪元里没有一个 Sentinel 被选举为领头 Sentinel ，那么各个 Sentinel 将在一段时间之后再次进行选举，直到选出领头 Sentinel 为止。</p>
<h3 id="哨兵选举主服务器"><a href="#哨兵选举主服务器" class="headerlink" title="哨兵选举主服务器"></a>哨兵选举主服务器</h3><p>1、领头 Sentinel 会遍历已下线主节点的所有从节点，留下状态好的节点，过滤掉状态不好的节点，过滤规则主要有以下几个：</p>
<blockquote>
<p>从节点状态为主观下线或客观下线<br> 从节点链接断开<br> 上次收到该从节点的正常 PING 回复超过5秒（5 * SENTINEL_PING_PERIOD）<br> 从节点的优先级为0<br> 上一次收到该从节点对于 INFO 的回复时间超过允许的时间，master 为主观下线则为5秒，否则为30秒。这是因为在 master 为主观下线后，Sentinel 会更频繁的向从节点发送 INFO 命令，因为需要更实时的获取从节点的状态。<br> 从节点与已下线的主节点链接断开时间超过 down-after-miliseconds 配置的 10 倍</p>
</blockquote>
<p>2、对剩下的状态好的节点进行排序，状态越好的排在越前面，排序规则如下：</p>
<blockquote>
<p>比较优先级，优先级值（slave-priority）较小的排在前面，跟 Spring 里的 Order 有点类似，也是小的排前面。<br> 如果优先级相同，比较复制偏移量，复制偏移量较大的排前面。<br> 如果优先级和复制偏移量相同，比较运行ID，运行ID小的排前面。 </p>
</blockquote>
<p>3、最终，排序后的第一个从节点会当选为新的主节点</p>
<h3 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h3><p>哨兵模式最大的缺点就是所有的数据都放在一台服务器上，无法较好的进行水平扩展。</p>
<p>为了解决哨兵模式存在的问题，集群模式应运而生。在高可用上，集群基本是直接复用的哨兵模式的逻辑，并且针对水平扩展进行了优化。</p>
<p>集群模式具备的特点如下：<br>1、采取去中心化的集群模式，将数据按槽存储分布在多个 Redis 节点上。集群共有 16384 个槽，每个节点负责处理部分槽。</p>
<p>2、使用 CRC16 算法来计算 key 所属的槽：crc16(key,keylen) &amp; 16383。</p>
<p>3、所有的 Redis 节点彼此互联，通过 PING-PONG 机制来进行节点间的心跳检测。</p>
<p>4、分片内采用一主多从保证高可用，并提供复制和故障恢复功能。在实际使用中，通常会将主从分布在不同机房，避免机房出现故障导致整个分片出问题，下面的架构图就是这样设计的。</p>
<p>5、客户端与 Redis 节点直连，不需要中间代理层（proxy）。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。<br>集群的架构图如下所示：<br><img src="https://i.loli.net/2021/04/27/pwMlr46CXLzE7YZ.png" alt="1"></p>
<h3 id="Redis-集群目标"><a href="#Redis-集群目标" class="headerlink" title="Redis 集群目标"></a>Redis 集群目标</h3><p>1、高性能：没有代理层（proxy），采用异步复制，不对值进行合并操作。</p>
<p>2、水平扩展：集群共有 16384 个槽，每个节点负责处理部分槽，可以支持线性扩展至 1000 个节点。</p>
<p>3、写安全性：系统尝试（尽最大努力）保留来自与大多数主节点连接的客户机的所有写操作。但是由于使用异步复制，所以可能会丢失一些写命令。</p>
<p>4、可用性：集群模式下，Redis 能够自动进行故障检测、master 选举、故障转移。</p>
<h3 id="MOVED错误"><a href="#MOVED错误" class="headerlink" title="MOVED错误"></a>MOVED错误</h3><p>通过上面的介绍和架构图，我们知道客户端只会连接到某个节点上，但是该节点只负责部分槽，万一客户端请求的是其他槽怎么办？</p>
<p>Redis 引入 MOVED 错误来解决这个问题。</p>
<p>当客户端向节点发送与数据库键有关的命令时，接收命令的节点会计算出要处理的数据库键属于哪个槽，并检查这个槽是否是自己负责的。</p>
<p>如果键所在的槽正好是自己负责，那么节点直接执行这个命令。</p>
<p>否则，节点会向客户端返回一个 MOVED 错误，该命令可以指引客户端转向（redirect）正确的节点，并再次发送之前想要执行的命令，得到正确的结果。</p>
<h3 id="集群的主从复制"><a href="#集群的主从复制" class="headerlink" title="集群的主从复制"></a>集群的主从复制</h3><p>集群的每个分片中使用了主从复制来保证高可用，这边的主从复制逻辑也是直接复用的之前的主从复制模式的逻辑。</p>
<h3 id="纪元（epoch）"><a href="#纪元（epoch）" class="headerlink" title="纪元（epoch）"></a>纪元（epoch）</h3><p>Redis 集群中使用了类似于 Raft 算法 term（任期）的概念称为 epoch（纪元），用来给事件增加版本号。<br>Redis 集群中的纪元主要是两种：currentEpoch 和 configEpoch。</p>
<h4 id="currentEpoch"><a href="#currentEpoch" class="headerlink" title="currentEpoch"></a>currentEpoch</h4><p>集群当前的配置纪元，这是一个集群状态相关的概念，可以当做记录集群状态变更的递增版本号。<br>currentEpoch 作用在于，当集群的状态发生改变，某个节点为了执行一些动作需要寻求其他节点的同意时，就会增加 currentEpoch 的值，例如故障转移流程。<br>当从节点 A 发现其所属的主节点下线时，就会试图发起故障转移流程。首先就是增加 currentEpoch 的值，这个增加后的 currentEpoch 是所有集群节点中最大的。然后从节点A向所有节点发包用于拉票，请求其他主节点投票给自己，使自己能成为新的主节点。<br>其他节点收到包后，发现发送者的 currentEpoch 比自己的 currentEpoch 大，就会更新自己的 currentEpoch，并在尚未投票的情况下，投票给从节点 A，表示同意使其成为新的主节点。</p>
<h4 id="configEpoch"><a href="#configEpoch" class="headerlink" title="configEpoch"></a>configEpoch</h4><p>节点当前的配置纪元，这是一个集群节点配置相关的概念，每个集群节点都有自己独一无二的 configepoch。所谓的节点配置，实际上是指节点所负责的槽位信息。</p>
<p>每一个 master 在向其他节点发送消息时，都会附带其 configEpoch 信息，以及一份表示它所负责的 slots 信息。</p>
<p>节点收到消息之后，就会根据消息中的 configEpoch 和负责的 slots 信息，记录到相应节点属性中。这边有两种情况：</p>
<p>1）如果该消息中的 slots 在当前节点中被记录为还未有节点负责，那可以直接指定为发送消息的节点。</p>
<p>2）如果消息中的 slots 在当前节点已经被记录为有节点负责，这种情况相当于有多个节点都宣称他负责了某个 slot，那怎么处理了？</p>
<p>这时候就要用到 configEpoch，configEpoch 更大的说明是更新的配置，当前节点会使用 configEpoch 更大的配置。</p>
<p>多个节点宣称负责同一个 slot 最常见的场景就是故障转移之后。当故障的主节点重新连接时，他会向集群其他节点发送消息，会带上自己故障前负责的 slots 信息，当其他节点收到后判断该节点的 configEpoch 更小，知道是旧的配置信息，则不会进行更新。</p>
<p>节点的 configEpoch 会在自己当选为新的主节点的时候，更新为集群当前选举的纪元，其实也就是 currentEpoch 的值。</p>
<p>因为每一次选举只会有一个从节点当选为新的主节点，所以该从节点的 configEpoch 会是当前所有集群节点 configEpoch 中的最大值。这样，该从节点成为主节点后，就会向所有节点发送广播包，强制其他节点更新相关槽位的负责节点为自己。</p>
<h3 id="集群故障检测"><a href="#集群故障检测" class="headerlink" title="集群故障检测"></a>集群故障检测</h3><p>本节与哨兵的故障核心思想是相同的。</p>
<p>集群中的每个节点都会定期地向集群中的其他节点发送 PING 消息，以此来检测对方是否在线。</p>
<p>集群节点间互相发送 PING 检测的时机，目前看主要有以下两个：</p>
<p>1、每秒执行1次：随机检查5个节点，选出最早收到 PONG 回复的节点，也就是最久没有通信过的节点，发送 PING 消息。</p>
<p>2、每100毫秒执行1次：轮询集群的节点，对于那些链接正常的节点，如果上一次收到该节点的 PONG 回复时间距离现在已经超过集群超时时间的一半（server.cluster_node_timeout/2），则直接向该节点发送 PING。</p>
<p>如果接收 PING 消息的节点在规定的时间内（cluster_node_timeout，默认15秒），没有向发送 PING 消息的节点返回 PONG 回复或者发送其他任何消息，那么发送 PING 消息的节点就会将接收 PING 消息的节点标记为疑似下线（probable failure，PFAIL）。</p>
<p>这边 Redis 没有将 PONG 回复作为目标节点存活的唯一证明，而是将目标节点的任何消息都作为存活的证明。这是因为在集群负载较高的时候，收到 PONG 回复可能会出现延迟。</p>
<p>集群中的各个节点在向其他节点发送 PING（PONG、MEET）消息的时候，会附加上 Gossip（八卦）消息，Gossip 消息记录了集群中其他节点的状态信息，例如某个节点是处于在线状态、疑似下线状态（PFAIL），还是已下线状态（FAIL）。</p>
<p>Gossip 消息包含两部分：<br>1）正常节点的状态信息：随机选择集群节点数的 1/10，但是不能小于3，除非目标集群节点中正常的数量已经小于3。<br>2）被标记为 PFAIL 的节点信息会被全部添加到 Gossip 消息中。</p>
<p>当主节点 A 通过 Gossip 消息得知主节点 B 认为主节点 C 进入了 PFAIL 或 FAIL 状态时，主节点 A 会在自己的 clusterState.nodes 字典中找到主节点 C 对应的 clusterNode 结构，并将主节点 C 的故障报告（failure report）添加到 clusterNode 结构的 fail_reports 链表中。</p>
<p>这样，主节点 A 就可以通过主节点 C 的 clusterNode-&gt;fail_reports 链表快速计算出有多少个节点将主节点 C 标记为 PFAIL 状态。</p>
<p>当主节点 A 为主节点 C 新增故障报告的时候，会顺带检查是否需要将主节点 C 标记为 FAIL，如果通过 fail_reports 链表发现主节点 C 被半数以上负责处理槽的主节点标记为疑似下线（PFAIL），则会进一步将主节点 C 标记为已下线（FAIL），同时向集群广播 “主节点 C 已经 FAIL 的消息”，所有收到消息的节点都会立即将主节点 C 标记为已下线。</p>
<h3 id="集群故障转移"><a href="#集群故障转移" class="headerlink" title="集群故障转移"></a>集群故障转移</h3><p>当 slave 发现自己正在复制的 master 进入了已下线（FAIL）状态，slave 会对下线的 master 进行故障转移，以下是故障转移的执行步骤：</p>
<p>1、发起一次选举，该下线的 master 的所有 slave 里面，会有一个 slave 被选中。<br>2、被选中的 slave 会升级为新的 master，清除 slave 相关的信息：slave 标记位等。<br>3、新的 master 会撤销所有对已下线 master 的槽指派，并将这些槽全部指派给自己。<br>4、新的 master 向集群广播一条 PONG 消息，这条 PONG 消息可以让集群中的其他节点立即知道这个节点已经由 slave 变成了 master ，并且这个新的 master 已经接管了原本由已下线节点负责处理的槽。集群中的其他节点收到消息后会更新自己保存的相关配置信息。<br>5、新的 master 开始接收和自己负责处理的槽有关的命令请求，故障转移完成。</p>
<h3 id="集群选举"><a href="#集群选举" class="headerlink" title="集群选举"></a>集群选举</h3><p>故障转移的第一步就是选举出新的主节点，以下是集群选举新的主节点的方法：</p>
<p>1、当从节点发现自己正在复制的主节点进入已下线状态时，会发起一次选举：将 currentEpoch 加1，然后向集群广播一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 消息，要求所有收到这条消息、并且具有投票权的主节点向这个从节点投票。<br>2、其他节点收到消息后，会判断是否要给发送消息的节点投票，判断流程如下：</p>
<blockquote>
<p>当前节点是 slave，或者当前节点是 master，但是不负责处理槽，则当前节点没有投票权，直接返回。<br> 请求节点的 currentEpoch 小于当前节点的 currentEpoch，校验失败返回。因为发送者的状态与当前集群状态不一致，可能是长时间下线的节点刚刚上线，这种情况下，直接返回即可。<br> 当前节点在该 currentEpoch 已经投过票，校验失败返回。<br> 请求节点是 master，校验失败返回。<br> 请求节点的 master 为空，校验失败返回。<br> 请求节点的 master 没有故障，并且不是手动故障转移，校验失败返回。因为手动故障转移是可以在 master 正常的情况下直接发起的。<br> 上一次为该master的投票时间，在cluster_node_timeout的2倍范围内，校验失败返回。这个用于使获胜从节点有时间将其成为新主节点的消息通知给其他从节点，从而避免另一个从节点发起新一轮选举又进行一次没必要的故障转移<br> 请求节点宣称要负责的槽位，是否比之前负责这些槽位的节点，具有相等或更大的 configEpoch，如果不是，校验失败返回。</p>
</blockquote>
<p>如果通过以上所有校验，那么主节点将向要求投票的从节点返回一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，表示这个主节点支持从节点成为新的主节点。</p>
<p>3、每个参与选举的从节点都会接收 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，并根据自己收到了多少条这种消息来统计自己获得了多少个主节点的支持。</p>
<p>4、如果集群里有N个具有投票权的主节点，那么当一个从节点收集到大于等于N/2+1 张支持票时，这个从节点就会当选为新的主节点。因为在每一个配置纪元里面，每个具有投票权的主节点只能投一次票，所以如果有 N个主节点进行投票，那么具有大于等于 N/2+1 张支持票的从节点只会有一个，这确保了新的主节点只会有一个。</p>
<p>5、如果在一个配置纪元里面没有从节点能收集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行选举，直到选出新的主节点为止。</p>
<p>这个选举新主节点的方法和选举领头 Sentinel 的方法非常相似，因为两者都是基于 Raft 算法的领头选举（leader election）方法来实现的。</p>
<h3 id="如何保证集群在线扩容的安全性？"><a href="#如何保证集群在线扩容的安全性？" class="headerlink" title="如何保证集群在线扩容的安全性？"></a>如何保证集群在线扩容的安全性？</h3><p>例如：集群已经对外提供服务，原来有3分片，准备新增2个分片，怎么在不下线的情况下，无损的从原有的3个分片指派若干个槽给这2个分片？</p>
<p>Redis 使用了 ASK 错误来保证在线扩容的安全性。</p>
<p>在槽的迁移过程中若有客户端访问，依旧先访问源节点，源节点会先在自己的数据库里面査找指定的键，如果找到的话，就直接执行客户端发送的命令。</p>
<p>如果没找到，说明该键可能已经被迁移到目标节点了，源节点将向客户端返回一个 ASK 错误，该错误会指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令，从而获取到结果。</p>
<p>在槽的迁移过程中若有客户端访问，依旧先访问源节点，源节点会先在自己的数据库里面査找指定的键，如果找到的话，就直接执行客户端发送的命令。</p>
<p>如果没找到，说明该键可能已经被迁移到目标节点了，源节点将向客户端返回一个 ASK 错误，该错误会指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令，从而获取到结果。</p>
<h3 id="ASK错误"><a href="#ASK错误" class="headerlink" title="ASK错误"></a>ASK错误</h3><p>在进行重新分片期间，源节点向目标节点迁移一个槽的过程中，可能会出现这样一种情况：属于被迁移槽的一部分键值对保存在源节点里面，而另一部分键值对则保存在目标节点里面。</p>
<p>当客户端向源节点发送一个与数据库键有关的命令，并且命令要处理的数据库键恰好就属于正在被迁移的槽时。源节点会先在自己的数据库里面査找指定的键，如果找到的话，就直接执行客户端发送的命令。</p>
<p>否则，这个键有可能已经被迁移到了目标节点，源节点将向客户端返回一个 ASK 错误，指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令，从而获取到结果。</p>
<h3 id="MOVED和ASK的区别"><a href="#MOVED和ASK的区别" class="headerlink" title="MOVED和ASK的区别"></a>MOVED和ASK的区别</h3><p>从上面的介绍来看 MOVED 错误和 ASK 错误非常类似，都起到重定向客户端的效果，他们有什么区别？能否合并成一个？</p>
<p>MOVED 错误代表槽位的负责权已经从一个节点转移到了另一个节点：在客户端收到关于槽位 k 的MOVED 错误之后，会更新槽位 k 及其负责节点的对应关系，这样下次遇到关于槽位 k 的命令请求时，就可以直接将命令请求发送新的负责节点。</p>
<p>ASK 错误只是两个节点在迁移槽的过程中使用的一种临时措施：客户端收到关于槽位 k 的 ASK 错误之后，客户端只会在接下来的一次命令请求中将关于槽位 k 的命令请求发送至 ASK 错误所指示的节点，但这种重定向不会对客户端今后发送关于槽位 k 的命令请求产生任何影响，客户端之后仍然会将关于槽位 k 的命令请求发送至目前负责处理 k 槽位的节点，除非 ASK 错误再次出现。</p>
<p>总结就是：<br>1）ASK 是一种迁移槽临时措施，只是会产生一次重定向<br>2）MOVED 代表该槽已经完全由另一个节点负责了，会触发客户端刷新本地路由表，之后对于该槽的请求都会请求新的节点。</p>
<p>这边提到的本地路由表是该集群的插槽和负责处理该槽的节点地址的映射，通过该路由表客户端可以在大部分情况下都直接请求到正确的节点，而无需重定向，从而提升性能。</p>
<h3 id="数据丢失场景：脑裂（split-brain）"><a href="#数据丢失场景：脑裂（split-brain）" class="headerlink" title="数据丢失场景：脑裂（split-brain）"></a>数据丢失场景：脑裂（split-brain）</h3><p>脑裂是导致 Redis 产生数据丢失比较常见的场景。如下例子：</p>
<p>集群有3个节点，每个节点采用1主2从，如下图所示，红色圈代表出现了网络分区故障。<br><img src="https://i.loli.net/2021/04/27/i6VAxdak97gnJUb.png" alt="2"></p>
<p>当主节点 A 与集群中其他节点出现网络分区故障时，此时集群会分为2个分区，“少数派”：节点 A；多数派：节点 A1、A2、B、B1、B2、C、C1、C2。</p>
<p>由于集群节点之间的故障检测需要一定时间，通常是 cluster_node_timeout，因此在 cluster_node_timeout 期间内 Client1 仍然可以向节点 A 发出写命令，但此时由于网络分区节点 A 已经无法通过异步复制将命令传播到节点 A1 和 A2。</p>
<p>如果节点 A 在 cluster_node_timeout 内仍然无法恢复，则集群 “多数派” 这边会发起故障转移，选择 A1 和 A2 中的一个升级为新的 master，对外提供服务。</p>
<p>与此同时，节点 A 所在的 “少数派” 由于在 cluster_node_timeout 内无法检测到与其他节点的心跳，此时也会开始拒绝对外提供服务。</p>
<p>当网络分区故障恢复后，由于新 master 拥有更高的配置纪元，此时节点 A 会被降级为 slave，清空自身数据，然后复制新的 master。此时，节点 A 在网络分区故障期间处理的写命令就全部丢失了。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis 浅谈</title>
    <url>/2024/08/31/redis/redis%EF%BC%9A%E4%BB%8E%E9%9D%A2%E8%AF%95%E8%BF%9E%E7%8E%AF%E7%82%AE%E5%88%B0%E7%A5%9E%E4%BB%99%E6%89%93%E6%9E%B6/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>看了之前写了很多Redis的文章，Redis基本是面试绕不过的一个话题</p>
<p>为了引出本文要讨论的关于 Redlock 的神仙打架的问题，我们就得先通过一个面试连环炮：</p>
<ul>
<li>Redis 做分布式锁的时候有需要注意的问题？</li>
<li>如果是 Redis 是单点部署的，会带来什么问题？</li>
<li>那你准备怎么解决单点问题呢？</li>
<li>集群模式下，比如主从模式，有没有什么问题呢？</li>
<li>你知道 Redis 是怎么解决集群模式也不靠谱的问题的吗？</li>
<li>那你简单的介绍一下 Redlock 吧？</li>
<li>你觉得 Redlock 有什么问题呢？</li>
</ul>
<p>很明显，上面是一个常规的面试连环套路题。中间还可以插入很多其他的 Redis 的考察点，我这里就不做扩展了。</p>
<p>单点的 Redis 做分布式锁不靠谱，导致了基于 Redis 集群模式的分布式锁解决方案的出现。</p>
<p>基于 Redis 集群模式的分布式锁解决方案还是不靠谱，Redis 的作者提出了 Redlock 的解决方案。</p>
<p>Redis 作者提出的 Redlock 的解决方案，另一位分布式系统的大神觉得它不靠谱，于是他们之间开始了 battle。</p>
<p>基于这场 battle，又引发了更多的讨论。</p>
<p>这场 battle 难分伯仲，没有最后的赢家。如果一定要选出谁是最大的赢家的话，那一定是吃瓜网友。</p>
<p>因为对于吃瓜网友来说（比如我），可以从两位大神的交锋中学习到很多东西。</p>
<p>让你深刻的体会到：看起来那么无懈可击的想法，细细推敲之下，并不是那么天衣无缝。</p>
<p>所以本文就按照下面的五个模块展开讲述。</p>
<p><img src="https://s2.loli.net/2024/08/31/c8VOkjuQ9RUZE4K.png"></p>
<h2 id="单点Redis"><a href="#单点Redis" class="headerlink" title="单点Redis"></a>单点Redis</h2><p>按照我的经验，当面试聊到 Redis 的时候，百分之 90 的朋友都会说：Redis在我们的项目中是用来做热点数据缓存的。</p>
<p>然后百分之百的面试官都会问：</p>
<blockquote>
<p>Redis除了拿来做缓存，你还见过基于Redis的什么用法？</p>
</blockquote>
<p>接下来百分之 80 的朋友都会说到：我们还用 Redis 做过分布式锁。</p>
<p>（当然， Redis 除了缓存、分布式锁之外还有非常非常多的奇技淫巧，不是本文重点，大家有兴趣的可以自己去了解一下。）</p>
<p>那么面试官就会接着说：</p>
<blockquote>
<p>那你给我描述（或者写一下伪代码）基于Redis的加锁和释放锁的细节吧。</p>
</blockquote>
<p>注意面试官这里说的是<strong>加锁和释放锁的细节，魔鬼都在细节里。</strong></p>
<p>问这个问题面试官无非是想要听到下面几个关键点：</p>
<p><strong>关键点1：原子命令加锁</strong></p>
<blockquote>
<p>SET key random_value NX PX 30000</p>
</blockquote>
<p><strong>关键点二：设置值的时候，放的是random_value。</strong></p>
<p>而不是你随便扔个“OK”进去。</p>
<p>先解释一下上面的命令中的几个参数的含义：</p>
<p>random_value：是由客户端生成的一个随机字符串，它要保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的。</p>
<p>NX：表示只有当要设置的 key 值不存在的时候才能 set 成功。这保证了只有第一个请求的客户端才能获得锁，而其它客户端在锁被释放之前都无法获得锁。</p>
<p>PX 30000：表示这个锁有一个 30 秒的自动过期时间。当然，这里 30 秒只是一个例子，客户端可以选择合适的过期时间。</p>
<p>再解释一下为什么 value 需要设置为一个随机字符串。这也是第三个关键点。</p>
<p><strong>关键点三：value 的值设置为随机数主要是为了更安全的释放锁</strong>，释放锁的时候需要检查 key 是否存在，且 key 对应的值是否和我指定的值一样，是一样的才能释放锁。所以可以看到这里有获取、判断、删除三个操作，<strong>为了保障原子性，我们需要用 lua 脚本</strong>。</p>
<p><img src="https://s2.loli.net/2024/08/31/VsEJc9p1NuKIHZe.png"></p>
<p>啊？你问lua脚本怎么写？出门右转，不送谢谢。</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Lua script for Redis to acquire a lock</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">-- KEYS[1] is the key for the lock</span></span><br><span class="line"><span class="comment">-- ARGV[1] is the lock expiration time in seconds</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> redis.<span class="keyword">call</span>(&quot;exists&quot;, KEYS[<span class="number">1</span>]) == <span class="number">0</span> <span class="keyword">then</span></span><br><span class="line">    <span class="comment">-- The lock does not exist, acquire it</span></span><br><span class="line">    redis.<span class="keyword">call</span>(&quot;set&quot;, KEYS[<span class="number">1</span>], &quot;1&quot;)</span><br><span class="line">    redis.<span class="keyword">call</span>(&quot;expire&quot;, KEYS[<span class="number">1</span>], ARGV[<span class="number">1</span>])</span><br><span class="line">    <span class="comment">-- Return 1 to indicate the lock was acquired</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="comment">-- The lock already exists, return 0 to indicate it was not acquired</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>


<h2 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h2><p>面试官就会接着问了：</p>
<p>经过刚刚的讨论，我们已经有较好的方法获取锁和释放锁。基于Redis单实例，假设这个单实例总是可用，这种方法已经足够安全。如果这个Redis节点挂掉了呢？</p>
<p>到这个问题其实可以直接聊到 Redlock 了。但是你别慌啊，为了展示你丰富的知识储备（疯狂的刷题准备），你得先自己聊一聊 Redis 的集群，你可以这样去说：</p>
<p><img src="https://s2.loli.net/2024/08/31/Vg4kNRU9pQbKuPf.png"></p>
<p>为了避免节点挂掉导致的问题，我们可以采用Redis集群的方法来实现Redis的高可用。</p>
<p><strong>Redis集群方式共有三种：主从模式，哨兵模式，cluster(集群)模式</strong></p>
<p>其中主从模式会保证数据在从节点还有一份，但是主节点挂了之后，需要手动把从节点切换为主节点。它非常简单，但是在实际的生产环境中是很少使用的。</p>
<p>哨兵模式就是主从模式的升级版，该模式下会对响应异常的主节点进行主观下线或者客观下线的操作，并进行主从切换。它可以保证高可用。</p>
<p>cluster (集群)模式保证的是高并发，整个集群分担所有数据，不同的 key 会放到不同的 Redis 中。每个 Redis 对应一部分的槽。</p>
<p>（上面三种模式也是面试重点，可以说很多道道出来，由于不是本文重点就不详细描述了。主要表达的意思是你得在面试的时候遇到相关问题，需要展示自己是知道这些东西的，都是面试的套路。）</p>
<p>在上面描述的集群模式下还是会出现一个问题，由于节点之间是采用异步通信的方式。如果刚刚在 Master 节点上加了锁，但是数据还没被同步到 Salve。这时 Master 节点挂了，它上面的锁就没了，等新的 Master 出来后（主从模式的手动切换或者哨兵模式的一次 failover 的过程），就可以再次获取同样的锁，出现一把锁被拿到了两次的场景。</p>
<p>锁都被拿了两次了，也就不满足安全性了。一个安全的锁，不管是不是分布式的，在任意一个时刻，都只有一个客户端持有。</p>
<h2 id="Redlock简介"><a href="#Redlock简介" class="headerlink" title="Redlock简介"></a>Redlock简介</h2><p>为了解决上面的问题，Redis 的作者提出了名为 Redlock 的算法。</p>
<p>在 Redis 的分布式环境中，我们假设有 N 个 Redis Master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。</p>
<p>前面已经描述了在单点 Redis 下，怎么安全地获取和释放锁，我们确保将在 N 个实例上使用此方法获取和释放锁。</p>
<p>在下面的示例中，我们假设有 5 个完全独立的 Redis Master 节点，他们分别运行在 5 台服务器中，可以保证他们不会同时宕机。</p>
<p>从官网上我们可以知道，一个客户端如果要获得锁，必须经过下面的五个步骤：</p>
<ul>
<li>获取当前 Unix 时间，以毫秒为单位。</li>
<li>依次尝试从 N 个实例，使用相同的 key 和随机值获取锁。在步骤 2，当向 Redis 设置锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为 10 秒，则超时时间应该在 5-50 毫秒之间。这样可以避免服务器端 Redis 已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个 Redis 实例。</li>
<li>客户端使用当前时间减去开始获取锁时间（步骤 1 记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是 3 个节点）的 Redis 节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。</li>
<li>如果取到了锁，key 的真正有效时间等于有效时间减去获取锁所使用的时间（步骤 3 计算的结果）。</li>
<li>如果因为某些原因，获取锁失败（没有在至少 N/2+1 个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的 Redis 实例上进行解锁（即便某些 Redis 实例根本就没有加锁成功）。</li>
</ul>
<p>通过上面的步骤我们可以知道，只要大多数的节点可以正常工作，就可以保证 Redlock 的正常工作。这样就可以解决前面单点 Redis 的情况下我们讨论的节点挂掉，由于异步通信，导致锁失效的问题。</p>
<p>但是，还是不能解决故障重启后带来的锁的安全性的问题。你想一下下面这个场景：</p>
<p>我们一共有 A、B、C 这三个节点。</p>
<ul>
<li>客户端 1 在 A，B 上加锁成功。C 上加锁失败。</li>
<li>这时节点 B 崩溃重启了，但是由于持久化策略导致客户端 1 在 B 上的锁没有持久化下来。</li>
<li>客户端 2 发起申请同一把锁的操作，在 B，C 上加锁成功。</li>
<li>这个时候就又出现同一把锁，同时被客户端 1 和客户端 2 所持有了。</li>
</ul>
<p>（接下来又得说一说Redis的持久化策略了，全是知识点啊，朋友们）</p>
<p><img src="https://s2.loli.net/2024/08/31/DwnM9OvgI5s7xPL.png"></p>
<p>比如，Redis 的 AOF 持久化方式默认情况下是每秒写一次磁盘，即 fsync 操作，因此最坏的情况下可能丢失 1 秒的数据。</p>
<p>当然，你也可以设置成每次修改数据都进行 fsync 操作（fsync=always），但这会严重降低 Redis 的性能，违反了它的设计理念。（我也没见过这样用的，可能还是见的太少了吧。）</p>
<p>而且，你以为执行了 fsync 就不会丢失数据了？天真，真实的系统环境是复杂的，这都已经脱离 Redis 的范畴了。上升到服务器、系统问题了。</p>
<p><img src="https://s2.loli.net/2024/08/31/GNmIksKfJhyxTrX.png"></p>
<p>所以，根据墨菲定律，上面举的例子：由于节点重启引发的锁失效问题，总是有可能出现的。</p>
<p>为了解决这一问题，Redis 的作者又提出了延迟重启（delayed restarts）的概念。</p>
<p><img src="https://s2.loli.net/2024/08/31/U2AvsO6YKDQCtwP.png"></p>
<p>意思就是说，一个节点崩溃后，不要立即重启它，而是等待一定的时间后再重启。等待的时间应该大于锁的过期时间（TTL）。这样做的目的是保证这个节点在重启前所参与的锁都过期。相当于把以前的帐勾销之后才能参与后面的加锁操作。</p>
<p>但是有个问题就是：<strong>在等待的时间内，这个节点是不对外工作的。那么如果大多数节点都挂了，进入了等待。就会导致系统的不可用，因为系统在TTL时间内任何锁都将无法加锁成功</strong>。</p>
<p>Redlock 算法还有一个需要注意的点是它的释放锁操作。</p>
<p><strong>释放锁的时候是要向所有节点发起释放锁的操作的</strong>。这样做的目的是为了解决有可能在加锁阶段，这个节点收到加锁请求了，也set成功了，但是由于返回给客户端的响应包丢了，导致客户端以为没有加锁成功。所有，释放锁的时候要向所有节点发起释放锁的操作。</p>
<p>你可以觉得这不是常规操作吗？</p>
<p>有的细节就是这样，说出来后觉得不过如此，但是有可能自己就是想不到这个点，导致问题的出现，所以我们才会说：细节，魔鬼都在细节里。</p>
<p>好了，经过这么长，这么长的铺垫，我们终于可以进入到神仙打架环节。</p>
<h2 id="神仙打架"><a href="#神仙打架" class="headerlink" title="神仙打架"></a>神仙打架</h2><p>神仙一：Redis 的作者 antirez 。有的朋友对英文名字不太敏感，所以后面我就叫他卷发哥吧。</p>
<p>神仙二：分布式领域专家 Martin Kleppmann，我们叫他长发哥吧。</p>
<p>卷发哥在官网介绍 Redlock 页面的最后写到：如果你也是使用分布式系统的人员，你的观点和意见非常重要，欢迎和我们讨论。</p>
<p><img src="https://s2.loli.net/2024/08/31/lhYAs1wFMfKLHEo.png"></p>
<p>于是，“求锤得锤”！这一锤，锤出了众多的吃瓜网友，其中不乏在相关领域的专业人士。</p>
<p><img src="https://s2.loli.net/2024/08/31/7iNkh6ImpLGZCUy.png"></p>
<h2 id="长发哥实锤"><a href="#长发哥实锤" class="headerlink" title="长发哥实锤"></a>长发哥实锤</h2><p>故事得从 2016年2月8号 长发哥发布的一篇文章《How to do distributed locking》说起：</p>
<blockquote>
<p><a href="http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html</a></p>
</blockquote>
<p><img src="https://s2.loli.net/2024/08/31/LhecABotj8wqHFI.png"></p>
<p>这一部分直接翻译过来就是：</p>
<p>作为本书（《数据密集型应用系统设计》）研究的一部分，我在Redis网站上 看到了一种称为Redlock的算法。该算法声称在Redis实现容错的分布式锁（或更确切地说， 租约），并且该页面要求来自分布式系统人员的反馈。这个算法让我产生了一些思考，因此我花了一些时间写了我的这篇文章。</p>
<p>由于Redlock已经有10多个独立的实现，而且我们不知道谁已经在依赖此算法，因此我认为值得公开分享我的笔记。我不会讨论Redis的其他方面，其中一些已经在其他地方受到了批评 。</p>
<p>你看这个文章，开头就是火药味十足：你说要反馈，那我就给你反馈。而且你这个东西有其他问题，我也就不说了。（其实作者在这篇文章中也说了，他很喜欢并且也在使用 Redis，只是他觉得这个 Redlock 算法是不严谨的）</p>
<p>长发哥主要围绕了下面的这张图进行了展开：</p>
<p><img src="https://s2.loli.net/2024/08/31/NhTEHbpiSDk7zsg.png"></p>
<p>要是一眼没看明白，我再给你一个中文版的，来自长发哥于2017年出版的书《数据密集型应用系统设计》：</p>
<p><img src="https://s2.loli.net/2024/08/31/d7ilQx14BEHNCeu.png"></p>
<p>可以看到上面的图片中提到了申请租约、租约到期的关键词，租约其实就是可以理解为带超时时间的锁。</p>
<p>而在书中，这张图片的下面写的描述这样的，你咂摸咂摸：</p>
<p>拿 HBase 举例，其设计的目标是确保存储系统的文件一次只能由一个客户端访问，如果多个客户端试图同时写入该文件，文件就会被破坏。那么上面的图片解释起来就是：</p>
<ul>
<li> 客户端 1 先去申请锁，并且成功获取到锁。之后客户端进行了长时间的 GC 导致了 STW 的情况。</li>
<li>在 STW 期间，客户端 1 获取的锁的超时时间到了，锁也就失效了。</li>
<li>由于客户端 1 的锁已经过期失效了，所以客户端 2 去申请锁就可以成功获得锁。</li>
<li>客户端 2 开始写文件，并完成文件的写入。</li>
<li>客户端 1 从 STW 中恢复过来，他并不知道自己的锁过期了，还是会继续执行文件写入操作，导致客户端 2 写入的文件被破坏。而且可以看到，它没有满足锁在任意时刻只有一个客户端持有的原则，即没有满足互斥性。</li>
</ul>
<p><strong>书里面没有明说，但是你品一品，这里的锁服务难道不是在说 Redis？</strong></p>
<p>有的朋友就会说了，那客户端 1 写入文件的时候，再判断一下自己的锁有没有过期不就可以了吗？</p>
<p>你可真是个小机灵鬼呢，那我问你，GC 可能是发生在任何时间的，万一 GC 发生在判断之后呢？</p>
<p>你继续怼我，如果客户端使用的是没有 GC 的语言呢？</p>
<p><img src="https://s2.loli.net/2024/08/31/wLyEvzWksXRPheU.png"></p>
<p>GC 不是导致线程暂停的唯一原因啊，朋友们。发生这种情况的原因有很多的，你看看长发哥书里举的例子：</p>
<p><img src="https://s2.loli.net/2024/08/31/dJ7uNKhk3EqIQvY.png"></p>
<p>上面的内容总结起来，就是就算锁服务是正常的，但是由于锁是有持有时间的，由于客户端阻塞、长时间的 GC 或者网络原因，导致共享资源被一个以上的客户端同时访问了。</p>
<p>其实上面长发哥在书里直接说了：这是不正确的实现。</p>
<p>你多品一品，上面的图是不是有点像由于 Redis 锁的过期时间设置的不合理，导致前一个任务还没执行完成，但是锁的时间到期了，后一个任务也申请到了锁。</p>
<p>对于这种场景，Redission 其实有自己的看门狗机制。但是不在这次 Redlock 的讨论范围内，所以这里就不描述了。</p>
<p>长发哥提出的解决方案是什么呢？</p>
<p>他称为：fencing token。</p>
<p><strong>长发哥认为使用锁和租约机制来保护资源的并发访问时，必须确保因为异常原因，导致锁过期的那个节点不能影响其他正常的部分，要实现这一目标，可以采用一直相当简单的 fencing（栅栏）。</strong></p>
<p>假设每次锁服务在授予锁或者租约时，还会同时返回一个 fencing 令牌，该令牌每次授予都会递增。</p>
<p>然后，要求客户端每次向存储系统发送写请求时，都必须包含所持有的 fencing 令牌。存储系统需要对令牌进行校验，发现如果已经处理过更高令牌的请求，则拒绝执行该请求。</p>
<p>比如下面的图片</p>
<p><img src="https://s2.loli.net/2024/08/31/9CNuFOZAXyh5SoU.png"></p>
<ul>
<li>客户端 1 获得一个具有超时时间的锁的同时得到了令牌号 33，但随后陷入了一个长时间的暂停直到锁到期。</li>
<li>这时客户端2已经获得了锁和令牌号 34 ，然后发送写请求（以及令牌号 34 )到存储服务。</li>
<li>接下来客户端 1 恢复过来，并以令牌号 33 来尝试写入，存储服务器由于记录了最近已经完成了更高令牌号（34 )，因此拒绝令牌号 33 的写请求。</li>
</ul>
<p>在长发哥的这种机制中，<strong>实际上就是要求资源本身必须主动检查请求所持令牌信息，如果发现已经处理过更高令牌的请求，要拒绝持有低令牌的所有写请求。</strong></p>
<p>但是，不是所有的资源都是数据库里面的数据，我们可以通过版本号去支持额外的令牌检查的，那么对于不支持额外的令牌检查资源，我们也可以借助这种思想绕过这个限制，比如对于访问文件存储服务的情况，我们可以将令牌嵌入到文件名中。</p>
<p>总之，为了避免在锁保护之外发生请求处理，需要进行额外的检查机制。</p>
<p>长发哥在书中也说到了：在服务端检查令牌可能看起来有点复杂，但是这其实是推荐的正确的做法：<strong>系统服务不能假定所有的客户端都表现的符合预期。从安全角度讲，服务端必须防范这种来自客户端的滥用。</strong></p>
<p>这个就类似于我们作为后端开发人员，也不能相信来自前端或者其他接口过来的数据，必须对其进行校验。</p>
<p>到这里长发哥铺垫完成了，开始转头指向 RedLock，他认为 Redlock 是一个严重依赖系统时钟的分布式锁。</p>
<p><img src="https://s2.loli.net/2024/08/31/I8uj96ZDL7SOAhJ.png"></p>
<p>他举了一个例子：</p>
<ul>
<li>客户端 1 从 Redis 节点 A, B, C 成功获取了锁。由于网络问题，无法访问 D 和 E。</li>
<li>节点 C 上的时钟发生了向前跳跃，导致它上面维护的锁过期了。</li>
<li>客户端 2 从 Redis 节点 C, D, E 成功获取了同一个资源的锁。由于网络问题，无法访问 A 和 B。</li>
<li>现在，客户端 1 和客户端 2 都认为自己持有了锁。</li>
</ul>
<p>这样的场景是可能出现的，因为 Redlock 严重依赖系统时钟，所以一旦系统的时间变得不准确了，那么该算法的安全性也就得不到保障了。</p>
<p>长发哥举这个例子其实是为了辅佐他前面提出的观点：<strong>一个好的分布式算法应该是基于异步模型的，算法的安全性不应该依赖与任何记时假设，就是不能把时间作为安全保障的。在异步模型中，程序暂停、消息在网络中延迟甚至丢失、系统时间错误这些因素都不应该影响它的安全性，只能影响到它的活性。</strong></p>
<p>用大白话说，就是在极其极端的情况下，分布式系统顶天了也就是在有限的时间内不能给出结果而已，而不能给出一个错误的结果。</p>
<p>这样的算法实际上是存在的，比如 Paxos、Raft。很明显，按照这个标准， Redlock 的安全级别是不够的。</p>
<p>而对于卷发哥提出的延迟启动方案，长发哥还是一棒子打死：<strong>你延迟启动咋的？延迟启动还不是依赖于合理准确的时间度量。</strong></p>
<p><img src="https://s2.loli.net/2024/08/31/rOsIyPtiVDnTdfu.png"></p>
<p>可能是长发哥觉得举这个时钟跳跃的例子不够好的，大家都可能认为时钟跳跃是不现实的，因为对正确配置NTP就能摆正时钟非常有信心。</p>
<p>在这种情况下，他举了一个进程暂停可能导致算法失败的示例：</p>
<p><img src="https://s2.loli.net/2024/08/31/zpQnMKb8iAghFI6.png"></p>
<ul>
<li>客户端 1 向 Redis 节点 A, B, C, D, E 发起锁请求。</li>
<li>各个 Redis 节点已经把请求结果返回给了客户端 1，但客户端 1 在收到请求结果之前进入了长时间的 GC 阶段。</li>
<li>长时间的 GC，导致在所有的 Redis 节点上，锁过期了。</li>
<li>客户端 2 在 A, B, C, D, E 上申请并获取到了锁。</li>
<li>客户端 1 从 GC 阶段中恢复，收到了前面第 2 步来自各个 Redis 节点的请求结果。客户端 1 认为自己成功获取到了锁。</li>
<li>客户端 1 和客户端 2 现在都认为自己持有了锁。</li>
</ul>
<p>其实只要十分清楚 Redlock 的加锁过程，我们就知道，这种情况其实对于 Redlock 是没有影响的，因为在第 5 步，客户端 1 从 GC 阶段中恢复过来以后，在 Redlock 算法中，（我们前面 Redlock 简介的时候提到的第四步）如果取到了锁，key 的真正有效时间等于有效时间减去获取锁所使用的时间。</p>
<p>所以客户端1通过这个检查发现锁已经过期了，不会再认为自己成功获取到锁了。</p>
<p>而随后卷发哥的回击中也提到了这点。</p>
<p><img src="https://s2.loli.net/2024/08/31/r9dEGpiLqtWwIYV.png"></p>
<p>但是，细细想来，我觉得长发哥的意图不在于此。抛开上面的问题来讲，他更想突出的是，一个锁在客户端拿到后，还没使用就过期了，这是不好的。</p>
<p><strong>从客户端的角度来看，就是这玩意不靠谱啊，你给我一把锁，我还没用呢，你就过期了？</strong></p>
<p><img src="https://s2.loli.net/2024/08/31/TN3uLGFBf2Vw7at.png"></p>
<p>除了上面说的这些点外，长发哥还提出了一个算是自己的经验之谈吧：</p>
<p><strong>我们获取锁的用途是什么？</strong></p>
<p>在他看来不外乎两个方面，<strong>效率和正确性</strong>。他分别描述如下：</p>
<p><img src="https://s2.loli.net/2024/08/31/xkWuf9iBGrXyJsA.png"></p>
<p>如果是为了效率，那么就是要协调各个客户端，避免他们做重复的工作。这种场景下，即使锁偶尔失效了，只是可能出现两个客户端完成了同样的工作，其结果是成本略有增加（您最终向 AWS 支付的费用比原本多5美分），或者带来不便（例如，用户最终两次收到相同的电子邮件通知）。</p>
<p>如果是为了正确性，那么在任何情况下都不允许锁失效的情况发生，因为一旦发生，就可能意味着数据不一致，数据丢失，文件损坏，或者其它严重的问题。（比如个患者注射了两倍的药剂）</p>
<p>最后，长发哥得出的结论是：neither fish nor fowl（不伦不类）</p>
<p>对于提升效率的场景下，使用分布式锁，允许锁的偶尔失效，那么使用单 Redis 节点的锁方案就足够了，简单而且效率高。用 Redlock 太重。</p>
<p>对于正确性要求高的场景下，它是依赖于时间的，不是一个足够强的算法。Redlock并没有保住正确性。</p>
<p><img src="https://s2.loli.net/2024/08/31/xi5yFPRJf8BmUbp.png"></p>
<h2 id="卷发哥回击"><a href="#卷发哥回击" class="headerlink" title="卷发哥回击"></a>卷发哥回击</h2><p>长发哥发出《How to do distributed locking》这篇文章的第二天，卷发哥就进行了回击，发布了名为《Is Redlock safe?》的文章。</p>
<blockquote>
<p>文章地址：<a href="http://antirez.com/news/101">http://antirez.com/news/101</a></p>
</blockquote>
<p>要说大佬不愧是大佬，卷发哥的回击条理清楚，行文流畅。他总结后认为长发哥觉得 Redlock 不安全主要分为两个方面：</p>
<p><img src="https://s2.loli.net/2024/08/31/WJOberRHzt3lmCv.png"></p>
<ul>
<li>带有自动过期功能的分布式锁，需要一种方法（fencing机制）来避免客户端在过期时间后使用锁时出现问题，从而对共享资源进行真正的互斥保护。马丁说Redlock没有这种机制。</li>
<li>马丁说，无论问题“1”如何解决，该算法本质上都是不安全的，因为它对系统模型进行了记时假设，而这些假设在实际系统中是无法保证的。</li>
</ul>
<p>对于第一个点，卷发哥列了5大点来反驳这个问题，其中一个重要的观点是他认为虽然 Redlock 没有提供类似于fencing机制那样的单调递增的令牌，但是也有一个随机串，把这个随机串当做token，也可以达到同样的效果啊。当需要和共享资源交互的时候，我们检查一下这个token是否发生了变化，如果没有再执行“获取-修改-写回”的操作。</p>
<p><img src="https://s2.loli.net/2024/08/31/EfwiGYZ2mqnctQL.png"></p>
<p>最终得出的结论是一个灵魂反问：<strong>既然在锁失效的情况下已经存在一种fencing机制能继续保持资源的互斥访问了，那为什么还要使用一个分布式锁并且还要求它提供那么强的安全性保证呢？</strong></p>
<p>然而第二个问题，对于网络延迟或者 GC 暂停，我们前面分析过，对 Redlock 的安全性并不会产生影响，说明卷发哥在设计的时候其实是考虑过时间因素带来的问题的。</p>
<p>但是如果是长发哥提出的时钟发生跳跃，很明显，卷发哥知道如果时钟发生跳跃， Redlock 的安全性就得不到保障，这是他的命门。</p>
<p>但是对于长发哥写时钟跳跃的时候提出的两个例子：</p>
<ul>
<li>运维人员手动修改了系统时钟。</li>
<li>从NTP服务收到了一个大的时钟更新事件。</li>
</ul>
<p>卷发哥进行了回击：</p>
<p>第一点这个运维人员手动修改时钟，属于人为因素，这个我也没办法啊，人家就是要搞你，怎么办？加强管理，不要这样做。</p>
<p>第二点从NTP服务收到一个大的时钟更新，对于这个问题，需要通过运维来保证。需要将大的时间更新到服务器的时候，应当采取少量多次的方式。多次修改，每次更新时间尽量小。</p>
<p>关于这个地方的争论，就看你是信长发哥的时间一定会跳跃，还是信卷发哥的时间跳跃我们也是可以处理的。</p>
<p>关于时钟跳跃，有一篇文章可以看看，也是这次神仙打架导致的产物：</p>
<blockquote>
<p><a href="https://jvns.ca/blog/2016/02/09/til-clock-skew-exists/">https://jvns.ca/blog/2016/02/09/til-clock-skew-exists/</a></p>
</blockquote>
<p>文章得出的最终结论是：时钟跳跃是存在的。</p>
<p><img src="https://s2.loli.net/2024/08/31/9Nhc4OjVCvQMKBF.png"></p>
<p>其实我们大家应该都经历过时钟跳跃的情况，你还记得2016年的最后一天，当时有个“闰秒”的概念吗？导致2017年1月1日出现了07:59:60的奇观。</p>
<h2 id="打架的焦点"><a href="#打架的焦点" class="headerlink" title="打架的焦点"></a>打架的焦点</h2><p><strong>经过这样的一来一回，其实双方打架的焦点就很明确了，就是大延迟对分布式锁带来的影响。</strong></p>
<p>而对于大延迟给Redlock带来的影响，就是长发哥分析的那样，锁到期了，业务还没执行完。卷发哥认为这种影响不单单针对 Redlock ，其他具有自动释放锁的分布式锁也是存在一样的问题。</p>
<p><img src="https://s2.loli.net/2024/08/31/ATc6r8EZeHOjVqh.png"></p>
<p>而关于大延迟的问题，我在某社交平台上找到了两位神仙的下面的对话：</p>
<p><img src="https://s2.loli.net/2024/08/31/XPtsUwmYE1pVIKA.png"></p>
<p>卷发哥问：我想知道，在我发文回复之后，我们能否在一点上达成一致，就是大的消息延迟不会给Redlock的运行造成损害。</p>
<p>长发哥答：对于客户端和锁服务器之间的消息延迟，我同意你的观点。但客户端和被访问资源之间的延迟还是有问题的。</p>
<p>所以通过卷发哥的回击文章和某社交平台的记录，<strong>他是同意大的系统时钟跳跃会造成 Redlock 失效的。在这一点上，他与长发哥的观点的不同在于，他认为在实际系统中是可以通过好的运维方式避免大的时钟跳跃的。</strong></p>
<p>所以到这里，两位神仙好像又达到了一个平衡，实现了争论上的求同存异。</p>
<p><img src="https://s2.loli.net/2024/08/31/Y3fZJgr2PsOpoDn.png"></p>
<h2 id="打架总结"><a href="#打架总结" class="headerlink" title="打架总结"></a>打架总结</h2><p>作为一个互联网行业的从业者，也是分布式系统的使用者，读完他们的文章以及由此文章衍生出来的知识点后，受益良多，于是写下此文作为学习总结，也与大家分享。本文还有很多不足之处，还请各位海涵。</p>
<p>如同文章开篇说的，这场争论没有最后的赢家。很明显卷发哥是没有说服长发哥的，因为在长发哥2017年出版的《数据密集型应用系统设计》一书中，专门有一小节的名称叫做：不可靠的时钟</p>
<p>其实在这场争论的最后，长发哥对这场争论进行了一个非常感性的总结，他说：</p>
<blockquote>
<p>对我来说最重要的一点在于：我并不在乎在这场辩论中谁对谁错 —— 我只关心从其他人的工作中学到的东西，以便我们能够避免重蹈覆辙，并让未来更加美好。前人已经为我们创造出了许多伟大的成果：站在巨人的肩膀上，我们得以构建更棒的软件。<br>对于任何想法，务必要详加检验，通过论证以及检查它们是否经得住别人的详细审查。那是学习过程的一部分。但目标应该是为了获得知识，而不应该是为了说服别人相信你自己是对的。有时候，那只不过意味着停下来，好好地想一想。</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/08/31/5ZvrkFXaJMTIKLV.png"></p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>八股文</tag>
        <tag>Redission</tag>
      </tags>
  </entry>
  <entry>
    <title>千万不要把Request传递到异步线程里面！有坑！</title>
    <url>/2024/09/02/%E5%A4%9A%E7%BA%BF%E7%A8%8B/%E5%8D%83%E4%B8%87%E4%B8%8D%E8%A6%81%E6%8A%8ARequest%E4%BC%A0%E9%80%92%E5%88%B0%E5%BC%82%E6%AD%A5%E7%BA%BF%E7%A8%8B%E9%87%8C%E9%9D%A2%EF%BC%81%E6%9C%89%E5%9D%91!/</url>
    <content><![CDATA[<p>前几天在网上冲浪的时候看到一篇技术文章，讲的是他把一个 request 请求传递到了线程池里面，然后遇到了一个匪夷所思的情况。</p>
<p>他写了这篇文章，把自己针对这个问题的探索过程分享了出来：</p>
<blockquote>
<p>《springboot 中如何正确的在异步线程中使用request》<br>    <a href="https://www.cnblogs.com/mysgk/p/16470336.html">https://www.cnblogs.com/mysgk/p/16470336.html</a></p>
</blockquote>
<p>文章还是挺不错的，把发现问题和解决问题都写的很明白了。</p>
<p>但是，我觉得把探索问题的部分写的太省略了，导致我看完之后都不知道这个问题的根本原因是什么。</p>
<p>而为什么我会对这篇文章特别感兴趣呢？</p>
<p>因为这个“坑”我记得我刚刚入行没两年的也遇到过，我已经不记得自己当时是怎么解决的了，但是我肯定也没有深入的去研究。</p>
<p>因为那个时候遇到问题，就去网上费尽心思的查，粘一个方案过来看能不能用。</p>
<p>如果不能用的话，心里暗骂一句：小可(S)爱(B)，然后接着找。</p>
<p>直到找到一个可以用的。</p>
<p>至于为什么能用？</p>
<p>管它呢，研究这玩意干啥。</p>
<p><img src="https://s2.loli.net/2024/09/01/zwaN4WP3fl8t6oF.png" alt="e30ad49c5395b84ef3a0a178c7a2a58f.png"></p>
<p>主要是当时觉得探索这个玩意到进入到源码里面去，一涉及到源码心里就犯怵，所以就敬而远之。</p>
<p>现在不一样了，现在我看到源码我就觉得兴奋，心里想着：多好的素材啊。</p>
<p>既然这次又让我遇到了，所以我决定把几年前的坑填上，盘一盘它。</p>
<p><img src="https://s2.loli.net/2024/09/01/DbIn3ZWjRo18kdK.png" alt="528b6ed460c024f76a65ec3bb8eaa9f0.png"></p>
<h2 id="搞个demo"><a href="#搞个demo" class="headerlink" title="搞个demo"></a>搞个demo</h2><p>由于这个现象太过匪夷所思，所以写文章的那个老哥认为这个是一个 BUG，还在 Spring 的 github 上提了一个 issues：</p>
<blockquote>
<p><a href="https://github.com/spring-projects/spring-framework/issues/28741">https://github.com/spring-projects/spring-framework/issues/28741</a></p>
</blockquote>
<p>这里面他附上了一个可以复现的 Demo，所以我就直接拿来用了。</p>
<p>确实是可以复现，但是其实他提供的这个 Demo 还是有点臃肿，具有一点点的迷惑性，直接给我迷晕了，让我在这上面稍微花了时间。</p>
<p>先给你看一下他的 Demo 是怎么样的。</p>
<p>主要是两个 Controller 接口。</p>
<p>第一个接口是 get 请求类型的 getParams，代码很简单，先放在这里，等下用：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@GetMapping(&quot;/getParams&quot;)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">getParams</span><span class="params">(String a, <span class="type">int</span> b)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;get success&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@PostMapping(&quot;/postTest&quot;)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">postTest</span><span class="params">(HttpServletRequest request)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">age1</span> <span class="operator">=</span> request.getParameter(<span class="string">&quot;age&quot;</span>);</span><br><span class="line">    <span class="type">String</span> <span class="variable">name1</span> <span class="operator">=</span> request.getParameter(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">    System.out.println(<span class="string">&quot;age1=&quot;</span> + age1 + <span class="string">&quot;,name1=&quot;</span> + name1);</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">age2</span> <span class="operator">=</span> request.getParameter(<span class="string">&quot;age&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">name2</span> <span class="operator">=</span> request.getParameter(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;age2=&quot;</span> + age2 + <span class="string">&quot;,name2=&quot;</span> + name2);</span><br><span class="line">            <span class="comment">//模拟业务请求</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">200</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">            &#125;</span><br><span class="line">            age2 = request.getParameter(<span class="string">&quot;age&quot;</span>);</span><br><span class="line">            name2 = request.getParameter(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;).start();</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;post success&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>主要是里面启动了一个线程，在线程里面有从 request 里面获取参数的动作。</p>
<p>这个方法访问起来是这样的一个情况：</p>
<p><img src="https://s2.loli.net/2024/09/01/DsqoyiFcX2aHQBA.png" alt="684a459612cf469a219ca9c38cd1c4d5.png"></p>
<p>从 age2、name2 输出上看，虽然 request 传入到异步线程里面了，但是还是能从里面获取到对应的参数，没有看出来有什么毛病。</p>
<p>但是接下来，匪夷所思的事情就要出现了。</p>
<p>还记得我们前面的 getParams 接口吗？</p>
<p>你说，就这个接口，我用下面这个链接去访问，在我的认知里面是完全不可能有任何问题的，对吧？</p>
<blockquote>
<p><a href="http://127.0.0.1:8080/getParams?a=1&amp;b=2">http://127.0.0.1:8080/getParams?a=1&amp;b=2</a></p>
</blockquote>
<p>但是，这玩意还真的就打破了我的认知：</p>
<p><img src="https://s2.loli.net/2024/09/01/VWnbAeHa1dFspIz.png" alt="6780602d78c24be8a1804807fdb4546e.png"></p>
<p>在访问 postTest 方法之后，再次访问 getParams 方法，getParams 方法居然抛出异常了？</p>
<p>抛出的异常是说我调用的时候没有传递 b 这个参数。</p>
<p>但是我的链接里面明明就是有 b=2 的啊？</p>
<p>这玩意上哪里说理去？</p>
<p><img src="https://s2.loli.net/2024/09/01/jxWGI98o1Js2RhS.png" alt="73c28841f3cc6e68cbb228ec407e06fc.png"></p>
<p>上面就是那位老哥提供的可复现的 Demo 的主要部分。</p>
<p>但是我前面说了，这个 Demo 有点臃肿，具有一点点迷惑性。</p>
<p>首先如果我再加一个输出语句，那么在一个短暂的 sleep 之后， age2 和 name2 就没了：</p>
<p><img src="https://s2.loli.net/2024/09/01/Sa4Z8OfA31enrpt.png" alt="699d2882a9ff80f5e3827c44c1639f0c.png"></p>
<p>虽然还是感觉有点神奇吧，但是也没有刚刚那个操作让我感到震惊。</p>
<p>因为从输出 null 这个结果，我至少可以知道程序在这个地方就出现问题了，把问题的范围限定在了一次请求中。</p>
<p>刚刚那个操作，好家伙，表现出来到情况是这样的：</p>
<ul>
<li>先发起一个 post 请求，看起来是正常的。</li>
<li>然后再发起一个 get 请求，这个 get 请求挂了。</li>
<li>但是这个 get 请求从发起的角度来看找不到任何毛病。</li>
</ul>
<p>你要基于上面这个情况去分析问题的话，就不好找问题了，毕竟要发起两个毫不相干的请求才能触发问题。</p>
<p><img src="https://s2.loli.net/2024/09/01/kbp3lE5Aca4jOMH.png" alt="f61263e9567852f2dca425bdd07cf0ca.png"></p>
<p>加入一行输出日志，相当于把问题简化了一点。</p>
<p>但是你看到的是我就加了一行输出日志，实际上等我加这行日志的时候，我拿到这个 Demo 已经过去了好几个小时了。</p>
<p>在这期间我也一直以为必须要按照这个流程来操作，才能复现问题。</p>
<p>所以我才说具有一点点迷惑性。</p>
<p>好，现在不管怎么说吧。</p>
<p>我先把 Demo 简化一点，便于继续分析。我的 Demo 可以简化到这个程度：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/getTest&quot;)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">getTest</span><span class="params">(HttpServletRequest request)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> request.getParameter(<span class="string">&quot;age&quot;</span>);</span><br><span class="line">    System.out.println(<span class="string">&quot;age=&quot;</span> + age);</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">200</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">String</span> <span class="variable">age1</span> <span class="operator">=</span> request.getParameter(<span class="string">&quot;age&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;age1=&quot;</span> + age1);</span><br><span class="line">    &#125;).start();</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;success&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>get 和 post 请求都可以，只是我为了方便选择发起 get 请求。</p>
<p>然后只需要传递一个参数就行，核心步骤是要把 request 传递到异步线程里面去，调用 getParameter 再次获取对应入参。</p>
<p>你可以把上面的代码粘到你本地，把项目跑起来，然后调一次下面这个链接：</p>
<p><img src="https://s2.loli.net/2024/09/01/DHdlAJEaqG548iU.png" alt="297d217df5b334f3344e07250d073a29.png"></p>
<p>到这里就复现了前面说的问题。</p>
<p>但是你別着急，你再次发起调用，你会看到控制台的输出是这样的：</p>
<p><img src="https://s2.loli.net/2024/09/01/p8P3bqXaONGLtI5.png" alt="97dccc0b95cb517867b8bc904a712ecc.png"></p>
<p>怎么样，是不是很神奇，很懵逼？</p>
<p>好，现在，你就去泡杯茶，点根烟，慢慢去琢磨，这玩意是不是属于超自然现象。</p>
<p><img src="https://s2.loli.net/2024/09/01/5MKfl4jTV8L6rOJ.png" alt="9152af1dd52c46a9696563fb31a55b65.png"></p>
<h2 id="探索"><a href="#探索" class="headerlink" title="探索"></a>探索</h2><p>其实我看到这个现象的时候并不是特别的震惊，毕竟工作这几年，什么稀奇古怪的现象都遇到过。</p>
<p>所以我只是轻蔑一笑，看向了我排查问题的武器库，很快就看到了一个比较趁手的东西：开启 Debug 日志。</p>
<p>如果是以前，对于这种没有抛出异常的问题跟着，由于没有异常堆栈，我肯定是迫不及待的正向的 Debug 跟了一下源码，扎到源码里面去一顿狂翻，左看右看。</p>
<p>但是结果常常是一头扎进去之后，很快就迷失了，搞了好几个小时才从源码里面爬出来，出来的时候基本上一无所获。</p>
<p>但是我现在不会这么猴急了，现在就成熟了很多。遇到这类问题不会先急着去卷源码会先多从日志里面挖掘一点东西出来。</p>
<p>所以我遇到这个问题的第一反应就是调整日志级别到 Debug：</p>
<blockquote>
<p>logging.level.root=debug</p>
</blockquote>
<p>观察日志这个小技巧我在之前的文章里面也分享过。</p>
<p>当日志调整到 Debug 级别之后，再次发起两次调用，问题复现，同时把日志拿出来做对比。</p>
<p>两次请求的 Debug 日志整体情况是这样的，左边是第一次请求，右边是第二次请求：</p>
<p><img src="https://s2.loli.net/2024/09/01/NIczBSH8yxYMQnT.png" alt="07ee3d6a49095dedd2c00547357c2262.png"></p>
<p>可以看到第一次请求比第二次请求的日志多。</p>
<p>多说明什么问题？</p>
<p>是不是说明第一次请求调用的方法更多一点？</p>
<p>为什么多一点，到底是哪些方法只调用了一次？</p>
<p>我也不知道，但是我能从 Debug 日志里面梳理出来。</p>
<p>比如下面这个图就是梳理出来的第一次请求多打印的日志：</p>
<p><img src="https://s2.loli.net/2024/09/01/BZ74oGSV9Udul8z.png" alt="b68d7c82601fda252392d42eb7f1c756.png"></p>
<p>很快我就从 Debug 日志里面看到了一个我觉得很可疑的地方：</p>
<p><img src="https://s2.loli.net/2024/09/01/Q4BLpshxwfOiHXE.png" alt="7b125e9722c33ad36fa8743eca364b0c.png"></p>
<blockquote>
<p>Start processing with input [age=18]</p>
</blockquote>
<p>这一行日志，只有第一次请求的时候打印了，从日志表达的意思来看，是处理请求里面的 age=18。</p>
<p>为什么第二次不打印呢？</p>
<p>我也不知道，但是我知道了第一个关键断点打在什么位置了。</p>
<p>全局搜索关键字 “Start processing with input” 可以找到配置文件里面的 “parameters.bytes”。</p>
<p>然后全局搜索 “parameters.bytes”，就能找到是在 Parameters.java 文件里面输出的：</p>
<p><img src="https://s2.loli.net/2024/09/01/gbvNph5wxHtBa3L.png" alt="253ab4ac5f08528cedb4773f0f739648.png"></p>
<p>也就是这个地方：</p>
<blockquote>
<p>org.apache.tomcat.util.http.Parameters#processParameters(byte[], int, int, java.nio.charset.Charset)</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/01/vey7C92iRJfkUzo.png" alt="c2ccca85699a98973dc4553e329a2892.png"></p>
<p>找到第一个断点，就找到了突破口，只要好好的拿捏住，之后的事情就基本上就顺风顺水了。</p>
<p><img src="https://s2.loli.net/2024/09/01/1amOwFIKtlWLPxs.png" alt="2053ff3df58045c4315fa4149e391343.png"></p>
<p>首先，重启项目，发起调用，在断点处看调用堆栈：</p>
<p><img src="https://s2.loli.net/2024/09/01/d9fKbkuSn7O6w4h.png" alt="2053ff3df58045c4315fa4149e391343.png"></p>
<p>接下来的思路是什么？</p>
<p>就是我要从堆栈里面找到一个东西。</p>
<p>你想啊，第一次请求走这个地方，第二次请求就不走这个地方了，所以一定有个类似于这样的逻辑：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(满足某个条件)&#123;</span><br><span class="line">    走processParameters方法</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>所以，只需要往回找五个调用栈，我就找到了这一个方法：</p>
<blockquote>
<p>org.apache.catalina.connector.Request#getParameter</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/01/LmRUpSDMQEtlP8r.png" alt="628cd3a353f4045a5852a540f3bd7226.png"></p>
<p>这个时候你看旁边的 parametersParsed 参数是 true，按理来说 true 不应该走进 if 分支呀？</p>
<p>因为这个地方我们是从断点处的堆栈信息往回找，在从 parseParameters 方法到 processParameters 方法之间，肯定有地方修改了 parametersParsed 参数的值为 true。</p>
<p>这一点，从 parametersParsed 的初始值是 false 也能看出来：</p>
<p>因此，我决定把第二个断点打在 getParameter 方法中，再次重启服务，发起调用，parametersParsed 为 false，开始执行 parseParameters() 方法解析参数：</p>
<p><img src="https://s2.loli.net/2024/09/01/IHVP783cxvC9QaT.png" alt="756a8fd971741e234c93a1cc86532e5b.png"></p>
<p>而解析参数的目的之一就是把我的 age=18 放到 paramHashValues 这个 Map 容器里面：</p>
<blockquote>
<p>org.apache.tomcat.util.http.Parameters#addParameter</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/01/hdokQluaPgrpEim.png" alt="756a8fd971741e234c93a1cc86532e5b.png"></p>
<p>parseParameters() 方法执行完成之后，接着从前面的 paramHashValues 容器里面把 age 对应的 18 返回回去：</p>
<p><img src="https://s2.loli.net/2024/09/01/eAkOTmH13oaDyqc.png" alt="b5039ca8eba2752c64a9ad8b219c0cb0.png"></p>
<p>但是，朋友们，注意上面的图片中有个标号为 ① 的地方：</p>
<p><img src="https://s2.loli.net/2024/09/01/SGBOETu5ZpdtxwY.png" alt="ff85f6fb37dd1422b5ce438a57d36e5e.png"></p>
<p>这个方法，在 parseParameters 方法里面也会被调用：</p>
<blockquote>
<p>org.apache.tomcat.util.http.Parameters#handleQueryParameters</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/01/Qd1vUEXl2wYrIPC.png" alt="b44264238da6a363960da58501921c17.png"></p>
<p>好，现在打起精神来听我说。</p>
<p>handleQueryParameters 方法才是真正解析参数的方法，为了防止重复解析它加入了这样的逻辑：</p>
<p><img src="https://s2.loli.net/2024/09/01/xptJk1c4sBozhH7.png" alt="4797f1e359ab2a1ee461948f56dc8f6f.png"></p>
<p><img src="https://s2.loli.net/2024/09/01/efysRdFwHBEUc2b.png" alt="56ad5e2bbf59775fe39fca18aff5ad80.png"></p>
<p>didQueryParameters 初始为 false，随后被设置为 true。</p>
<p>这个很好理解，入参解析一次就行了，解析的产物一个 Map，后续要拿参数对应的值，从 Map 里面获取即可。</p>
<p>比如我把入参修改为这样：</p>
<blockquote>
<p><a href="http://127.0.0.1:8080/getTest?a=1&amp;b=2&amp;c=3&amp;d=4">http://127.0.0.1:8080/getTest?a=1&amp;b=2&amp;c=3&amp;d=4</a></p>
</blockquote>
<p>那么经过解析之后，这个 Map 就变成了这样：</p>
<p><img src="https://s2.loli.net/2024/09/01/fko8sJBZO2hM7r3.png" alt="06d02bfb88420f313ec32e689d8a1738.png"></p>
<p>经过了前面的这一顿折腾之后，现在找到了解析入参的方法。</p>
<p>那么全文的关键点就在 didQueryParameters 这个参数的变化了。</p>
<p>只有是 false 的时候才会去解析入参。</p>
<p>那么我接下来的排查思路就是观察 didQueryParameters 参数的变化，所以在字段上打上断点，重启项目，继续调试。</p>
<p>第一次进入这个方法的时候 didQueryParameters 为 false，入参是 age=18。</p>
<p>而第一次进入这个方法的原因我前面也说了，是因为触发了 parseParameters 的逻辑。</p>
<p>第二次进入这个方法 didQueryParameters 变为 true 了，不用再次解析。</p>
<p>那么第二次进入这个方法的原因是什么？</p>
<p>前面也说了，getParameter 方法的第一行就是触发解析的逻辑：</p>
<p><img src="https://s2.loli.net/2024/09/01/LtSCWTDGbPEFxlO.png" alt="5d96b25404dec755abd41bb05a15316f.png"></p>
<p>接下来，断点停在了这个地方：</p>
<blockquote>
<p>org.apache.tomcat.util.http.Parameters#recycle</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/01/eZPUoGEXQwlOjfA.png" alt="9c1664ad7c0995b04c026d230e97d4df.png"></p>
<p>方法叫做 recycle，表明是循环再利用，在这里面会把存放参数的 Map 清空，把 didQueryParameters 再次设置为了 false。</p>
<p>而当你用同样的手段去观察 parametersParsed 参数，也就是这个参数的时候：</p>
<p><img src="https://s2.loli.net/2024/09/01/7gr54F2d3xpoGXa.png" alt="1dd00f6757f7cf1cd39cd1684532f522.png"></p>
<p>会发现它也有一个 recycle 方法：</p>
<blockquote>
<p>org.apache.catalina.connector.Request#recycle</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/01/gTrBxReuGXdifk3.png" alt="28f6e9c52711f2edbbd48905f426b1b0.png"></p>
<p>这个方法上的注释，也有一个特别扎眼的词：reuse。</p>
<p>注释过来是这样的：释放所有的对象引用，并初始化实例变量，为重新使用这个对象做准备。</p>
<p>种种迹象表明 request 在 tomcat 里面是循环使用的。</p>
<p>虽然在这之前我也知道是循环使用的，但是百闻不如一见嘛。这次是我 Debug 的时候亲眼看到了。</p>
<p>又拿捏一个小细节。</p>
<p>由于我们在异步线程里面还触发了一次 getParameter 方法：</p>
<p><img src="https://s2.loli.net/2024/09/01/2xEdlHIUZp4eGri.png" alt="592bcc30a50d9c8e6ff7324301840951.png"></p>
<p>但是 getTest 方法已经完成了响应，这个时候 Request 可能已经完成了回收。</p>
<p>注意我说的是“可能”，因为这个时候 Request 的回收动作和异步线程谁先谁后还不一定。</p>
<p>虽然 request 传入到异步线程里面了，但是还是能从里面获取到对应的参数。</p>
<p>因为此时 request 的回收动作还没做完，还可以继续获取参数。</p>
<p>为了避免这个“可能”，我把 sleep 的时间调整为 5s，保证 request 完成回收。</p>
<p>然后这异步线程里面继续 Debug，接下来神奇的事情就要开始了。</p>
<p><img src="https://s2.loli.net/2024/09/01/9jCmGYiXNcRJxMr.png" alt="5d20d4761636dac616c5d446e746987f.png"></p>
<p>再次触发 handleQueryParameters 的时候，didQueryParameters 由于被 recycle 了，所以变成了 false。</p>
<p>然后执行解析的逻辑，把 didQueryParameters 设置为 true。</p>
<p>但是，我们可以看到，此时查询的内容却没有了，是个 null：</p>
<p><img src="https://s2.loli.net/2024/09/01/cC6WexOYhLt8Z5P.png" alt="4ebf080662076d7bdc6e5c17e5c0b83d.png"></p>
<p>这个也好理解，肯定是随着调用结束，被 recycle 了嘛：</p>
<p><img src="https://s2.loli.net/2024/09/01/O3UmBhnbXJAISpT.png" alt="208c2071ea20f00fbd904b0ccbb0bf19.png"></p>
<p>所以，到这里我能解答为什么异步线程里面的输出是 null 了。</p>
<p>queryMB 就是我调用的时候传入的 age=18。</p>
<p>通过 Debug 发现异步线程里面调用 getParameter 的时候没有 queryMB ，所以就不会解析出 Map。</p>
<p>没有 Map ，异步线程里面的输出肯定是 null。</p>
<p>为什么没有 queryMB 呢？</p>
<p>因为当前这个请求已经被返回了，执行了 recycle 相关操作，queryMB 就是在这个时候没有的。</p>
<p>那么为什么再次发起调用，会出现这个神奇的现象呢？</p>
<p><img src="https://s2.loli.net/2024/09/02/9WVMBqdbDlYKams.png" alt="97dccc0b95cb517867b8bc904a712ecc.png"></p>
<p>很简单，因为在异步线程里面调用 getParameter 的时候，把 didQueryParameters 设置为 true 了。</p>
<p>但是异步线程里面的调用，超出了 request 的生命周期，所以并不会再次触发 request 的 recycle 相关操作，因此这个 request 拿来复用的时候 didQueryParameters 还是 true。</p>
<p>所以，从 Debug 来看，虽然 queryMB 是有值的，但是没用啊，didQueryParameters 是 true，程序直接 return 了，不会去解析你的入参：</p>
<p><img src="https://s2.loli.net/2024/09/01/Thq9EMFl4CA5jKy.png" alt="9b66e8c606388b779b59b7215cd497d5.png"></p>
<p>问题得到解答。</p>
<p>此时，我们再回到最开始的这个方法中：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.lang.IllegalStateException: Optional <span class="type">int</span> parameter <span class="string">&#x27;b&#x27;</span> is present but cannot be translated into a <span class="literal">null</span> value due to being declared as a primitive type. Consider declaring it as object wrapper <span class="keyword">for</span> the corresponding primitive type</span><br></pre></td></tr></table></figure>

<p>你想想为什么这个方法调用的时候出现异常了？</p>
<p>还是一样的道理呀，由于 request 是复用的，虽然你传入了参数 b，但是由于前一个请求在异步线程里面调用了 getParameter 方法，将 didQueryParameters 设置为了 true，导致程序不会去解析我传入的 a=1&amp;b=2。</p>
<p>从调用链接的角度来说，虽然我们调用的是这个链接：</p>
<blockquote>
<p><a href="http://127.0.0.1:8080/getParams?a=1&amp;b=2">http://127.0.0.1:8080/getParams?a=1&amp;b=2</a></p>
</blockquote>
<p>但是对于程序来说，它等效于这个链接：</p>
<blockquote>
<p><a href="http://127.0.0.1:8080/getParams">http://127.0.0.1:8080/getParams</a></p>
</blockquote>
<p>由于入参 b 是 int 类型的，那可不就是会抛出这个异常吗：</p>
<p>这个异常是说：哥们，你要么把 b 搞成 Integer 类型的，不传值我就给你赋为 null。要么给我传一个值。</p>
<p>你现在用 int 来接受，又不给我值，我这没法处理啊？</p>
<p>我能给你默认赋值一个 0 吗？</p>
<p>肯定不能啊，0 和 null 可不是一个含义，万一你程序出异常了，把锅甩给我怎么办？</p>
<p>算了，我还是抛异常吧，最稳妥了。</p>
<p>所以你看，要是你从这个抛异常的地方去找答案，也许能找到，但是路就走远了一点。</p>
<p>因为这个地方并不是问题的根因。</p>
<p>到这里，你应该清楚这个 BUG 到底是怎么回事了。</p>
<h2 id="request-的生命周期"><a href="#request-的生命周期" class="headerlink" title="request 的生命周期"></a>request 的生命周期</h2><p>在探索这个问题的过程中，我也想到了另外一个问题：</p>
<blockquote>
<p>一个 request 请求的生命周期是怎么样的？</p>
</blockquote>
<p>这题我记得几年前我背过，现在我确实有点想不起来了，但是我知道去哪里找答案。</p>
<p>Java Servlet Specification，这是一份规范，答案就藏在这个规范里面：</p>
<blockquote>
<p><a href="https://javaee.github.io/servlet-spec/downloads/servlet-4.0/servlet-4_0_FINAL.pdf">https://javaee.github.io/servlet-spec/downloads/servlet-4.0/servlet-4_0_FINAL.pdf</a></p>
</blockquote>
<p>在 3.13 小节里面，关于 request 这个 Object 的生命周期，规范是这样说的：<br><img src="https://s2.loli.net/2024/09/01/nox7ZTVkpLjhg34.png" alt="389399dd0641bc11a0d6f5d16d3c5f7b.png"></p>
<p>这寥寥数语，非常关键，所以我一句句的拆解给你看。</p>
<blockquote>
<p>Each request object is valid only within the scope of a servlet’s service method, or within the scope of a filter’s doFilter method，unless the asynchronous processing is enabled for the component and the startAsync method is invoked on the request object.</p>
</blockquote>
<p>一上来就是一个长句，但是根本不要慌。</p>
<p>你知道的，我英语八级半，水平一向是可以的。</p>
<p><img src="https://s2.loli.net/2024/09/01/Y7ZSoraAgDNdvks.png" alt="289f874c35ab450b7ea99d1ec59e4ca8.png"></p>
<p>先把长句拆短一点，我可以先只翻译 unless 之前的部分。</p>
<p>前面这部分说：每个 request 对象只在 servlet 的服务方法的范围内有效，或者在过滤器的 doFilter 方法的范围内有效。</p>
<p>接着它来了一个 unless，表示转折，和 but 差不多。</p>
<p>我们主要关注 unless 后面这句：</p>
<blockquote>
<p>the asynchronous processing is enabled for the component and the startAsync method is invoked on the request object.</p>
</blockquote>
<p>组件的异步处理功能被启用，并且在 request 上调用了 startAsync 方法。</p>
<p>也就是说，request 的生命周期在遇到异步的时候有点特殊，但是这个异步又不是我前面演示的那种异步。</p>
<p>关于异步，规范中提到了 request 里面有个方法：startAsync。</p>
<p>我去看了一眼，果然是有：</p>
<p><img src="https://s2.loli.net/2024/09/01/8AXGxqRc6OhkTF5.png" alt="8624ce3654021349c8146543e8438da2.png"></p>
<p>返回值是一个叫做 AsyncContext 的东西。</p>
<p>但是我先按下不表，接着往下翻译。</p>
<blockquote>
<p>In the case where asynchronous processing occurs, the request object remains valid until complete is invoked on the AsyncContext.</p>
</blockquote>
<p>在发生异步处理的情况下，request 对象的生命周期一直会延续到在 AsyncContext 上调用 complete 方法之前。</p>
<p>这里又提到了一个 complete 方法，这个 complete 方法 invoked on the AsyncContext。</p>
<p>AsyncContext 是什么玩意？</p>
<p>不就是 request.startAsync() 方法的返回值吗？</p>
<p>果然在 AsyncContext 里面有个 complete 方法：</p>
<p><img src="https://s2.loli.net/2024/09/02/a64hrVmY7GWUnHN.png" alt="518f54c0435fe7c58214917659c6321e.png"></p>
<p>不慌，继续按下不表，一会就回收，接着往下看。</p>
<blockquote>
<p>Containers commonly recycle request objects in order to avoid the performance overhead of request object creation.</p>
</blockquote>
<p>容器通常会 recycle 请求对象，以避免创建请求对象的性能开销。</p>
<p>看到这个 recycle 我们就很眼熟了，原来规范里面是建议了容器里面实现 request 的时候尽量复用，而不是回收，目的是节约性能。</p>
<p>这玩意，属于意外收获呀。</p>
<p>最后一句话是这样的：</p>
<blockquote>
<p>The developer must be aware that maintaining references to request objects for which startAsync has not been called outside the scope described above is not recommended as it may have indeterminate results.</p>
</blockquote>
<p>这句话是说：程序员朋友们必须要意识到，我不建议在上述范围之外维护 request 的引用，因为它可能会产生不确定的结果。</p>
<p>看到这个“不确定的结果”时我很开心，因为我前面已经演示过了，确实会产生莫名其妙的结果。</p>
<p>但是规范里面在“scope”之前还加了一个限定词：startAsync has not been called。</p>
<p>反过来说，意思就是如果你有一个调用了 startAsync 方法的 request，那么在上述范围之外，你还可以操作这个 request，也不会有问题。</p>
<p>这一整段话中，我们提炼到了两个关键的方法：</p>
<ul>
<li>request 的 startAsync 方法</li>
<li>AsyncContext 的 complete 方法</li>
</ul>
<p>根据规范来说，这两个方法才是 request 异步编程的正确打开方式。</p>
<h2 id="正确打开方式"><a href="#正确打开方式" class="headerlink" title="正确打开方式"></a>正确打开方式</h2><p>在这之前，假设你完全不知道 startAsync 和 complete 方法。</p>
<p>但是看了规范上的描述，猜也能猜出来代码应该这样写，然后发起多次调用，没有任何毛病：</p>
<p><img src="https://s2.loli.net/2024/09/02/DYd1MkPnCesSgBA.png" alt="30940b092043a6fc49da215b4e80663a.png"></p>
<p>这就是正确的打开方式。</p>
<p>从现象上来说，就是 getTest 请求返回之后，request 线程并没有被调用 recycle 方法进行回收。</p>
<p>为什么这样写就能实现 request 的异步化呢？</p>
<p>用脚指头想也能想到，一定有一个这样的判断逻辑存在：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(调用过request的startAsync方法)&#123;</span><br><span class="line">    先不回收</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>所以，用之前的方法，在 recycle 方法上打断点，并往回找，很快就能找到这个方法：</p>
<p><img src="https://s2.loli.net/2024/09/02/oSZ9neckFu8BpwA.png" alt="22e7b1ca792d35e1148c0563ee55930f.png"></p>
<p>然后，关于 AsyncContext 的 complete 方法我还注意到它有这样的一个描述：</p>
<p><img src="https://s2.loli.net/2024/09/02/8se6KWIOBGy2DRX.png" alt="0ecde912b839f478616fc952963980d4.png"></p>
<p>也就是说在调用 complete 方法之后 response 流才会关闭，那么有意思的就来了。</p>
<p>我不仅在异步线程里面可以操作 request 还可以操作 response。</p>
<p>但是转念一想，既然都是异步编程了，操作 response 的意义肯定比操作 request 的意义更大。</p>
<p>关于 Tomcat 对于异步请求的支持还有很多可以探索的地方，自己慢慢去玩吧。</p>
<p>写到这里的时候我发现标题说的也不对，标题是：千万不要把 Request 传递到异步线程里面！有坑！</p>
<p>而正确的说法应该是：</p>
<blockquote>
<p>千万不要随便把 Request 传递到异步线程里面！有坑！你拿捏不住，得用 startAsync 方法才行。</p>
</blockquote>
<p>好了，就这样吧，本文写到这里就差不多了。</p>
<p>本文主要是分享了一下 request 放到异步线程之后的诡异现象和排查方法，最后也给出了正确的打开方式。</p>
<p>希望你能掌握到这样的一个问题排查方法，不要惧怕问题，要抽丝剥茧的干它。</p>
<p>然后，其实和 BUG 排查比起来，关于 request 的异步编程相关的知识更加重要，本文只是做了一个小小的引子，如果这块知识对你是空白的，希望你有兴趣的话自己去研究一下，很有价值。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>八股文</tag>
      </tags>
  </entry>
  <entry>
    <title>一次关于线程池使用场景的讨论</title>
    <url>/2024/09/03/%E5%A4%9A%E7%BA%BF%E7%A8%8B/%E4%B8%80%E6%AC%A1%E5%85%B3%E4%BA%8E%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E7%9A%84%E8%AE%A8%E8%AE%BA/</url>
    <content><![CDATA[<p>来一起看看一个关于线程池使用场景上的问题，就当是个场景面试题了。</p>
<p>问题是这样的：</p>
<p><img src="https://s2.loli.net/2024/09/02/dMnpSeDbHOiLP1I.png" alt="b3beff3aa3f74eb06ebae610d728070f.png"></p>
<p>字有点多，我直接给你上个图你就懂了：</p>
<p><img src="https://s2.loli.net/2024/09/02/UWAodf7I5jFmuzy.png" alt="33f20d1da850cc83adcb43ae64f2d4ee.png"></p>
<p>前端发起一个生成报表页面的请求，这个页面上的数据由后端多个接口返回，另外由于微服务化了，所以数据散落在每个微服务中，因此需要调用多个下游接口拿到数据进行整合。</p>
<p>调用多个下游接口的时候，由于接口之间不存在数据依赖，所以可以发起异步调用同时请求不同的下游接口。</p>
<p>也就是这里有个线程池：</p>
<p><img src="https://s2.loli.net/2024/09/02/yTDFrMe4pBmhozt.png" alt="8893273b123b0669e64d26328bb90b5a.png"></p>
<p>这个线程池，核心线程数只有 30 个，最大线程数是 100，队列长度是 1000。一个报表页面的请求发过来，为了整合数据，所以会调用下游 20 多个接口获取数据。</p>
<p>针对这个情况，用提问者的原话就是：3 个人同时打开，相应速度就会变慢了，因为任务超过空闲的核心线程数，就被放阻塞队列了。理论确实是这个理论。</p>
<p>该怎么办呢？针对这个场景，大家能想到的一个最直接的一个方案，肯定是扩大核心线程数。</p>
<p>这个方案，提问者也想到了，同时还进行了进一步思考：</p>
<p><img src="https://s2.loli.net/2024/09/02/eYiG28lAQR7skwK.png" alt="67eae919aa740e9d1c4ef13a75e8a027.png"></p>
<p>觉得应该改造一下 Spring 的这个线程池的工作模式，为了让请求尽快的得到处理，可以借鉴 Tomcat 线程池的工作模式。</p>
<p>Spring 这个线程池的工作模式是先启用核心线程，再启用队列，最后启用非核心线程。Tomcat 线程池的工作模式是先启用核心线程，再启用非核心线程，最后启用队列。</p>
<p>思路是不错的，但是吧，我觉得在这个场景下，没啥必要。比如 Tomcat 线程池，你的配置是核心线程数 30，非核心线程数 300，队列长度 1000。</p>
<p>其实你配置 Spring 线程池的时候，核心线程数 300，非核心线程数 300，队列长度 1000，效果和 Tomcat 线程池是一样的。</p>
<p>唯一的一点区别在非核心线程的回收，但是这一点点内存上的占用，微乎其微，我个人觉得是可以忽略不计的。</p>
<p>另外，在线程池配置方面，除了调整核心线程数外，还有一个常用的配置是修改线程池的拒绝策略，采用 CallerRunsPolicy，即在线程池满了的情况下，让任务调用者线程执行该任务。</p>
<p>这个方案在讨论的过程中也有提及到：</p>
<p><img src="https://s2.loli.net/2024/09/02/XvLhZDYwzgTNfxF.png" alt="f69f2d71aeeeefeb76f320aa1f03a4f9.png"></p>
<p>那这个方案可以用吗？</p>
<p>可以，但是需要注意一个暗坑的存在。</p>
<p>在任务提交线程池之后，Tomcat 的线程有两种情况：</p>
<ul>
<li>情况一：请求结束，返给前端，回到 Tomcat 线程池处理新请求。</li>
<li>情况二：等着下游的返回，然后继续执行。</li>
</ul>
<p><img src="https://s2.loli.net/2024/09/02/ksdft35mDRnrHUM.png" alt="cd4cd49ed782b6751321d2abdd176871.png"></p>
<p>我们先看情况一，你想想，在这个场景下，CallerRun，这个 Runner 是谁？</p>
<p>是 Tomcat 容器的线程。</p>
<p>好，现在我们来想象一下这个场景：你有一个自定义线程池，但是由于下游请求中有个慢接口，导致自定义的线程池满了，触发了拒绝策略。</p>
<p>这个时候拒绝策略是 CallerRunsPolicy。</p>
<p>于是 Tomcat 线程池里面的一个线程就需要去调用这个慢接口，导致本来在提交任务到线程池之后就返回的 Tomcat 的线程被拿去调用慢接口了，产生了较长时间占用。</p>
<p>那么会出现一个什么情况？</p>
<p>就是关键资源被长时间霸占，严重的情况下，服务就对外不可用了。</p>
<p>你想想，假设 Tomcat 一共就 200 个线程。</p>
<p>其中 190 个都被你这个慢接口拖着了，只剩下 10 个线程能对外提供服务。</p>
<p>甚至有可能 200 个都被这个慢接口拖着，而你这个服务，对外肯定不只是这一个接口吧？</p>
<p>其他接口会因为，慢接口里面的线程池的拒绝策略是 CallerRunsPolicy，把资源全部占用完了，从而受到影响。</p>
<p>即使你其他功能的一个接口耗时只需要 10ms 也没用，也要去队列里面等着，因为现在没有资源来处理你这个请求。</p>
<p>而对于接口调用方来说，进入队列等待的时候，也算在接口响应耗时里面。</p>
<p>所以，在使用 CallerRunsPolicy 拒绝策略的时候，需要特别注意，分析一下是否会占用关键资源，导致拖慢这个服务。</p>
<p>但是我们这个报表的场景，属于情况二，Tomcat 的线程得等着数据返回。</p>
<p>等着，本来也是一种占用。所以使用 CallerRunsPolicy 没啥问题。</p>
<p>但是，Tomcat 线程属于宝贵资源，如果出现长时间占用，那就是一个性能瓶颈点。</p>
<p>所以，本质上还是不应该有明显的慢接口存在。</p>
<p>关于“尽快释放宝贵资源”这个点，你也可以看 Dubbo 服务段线程模型，这里相当于是一个最佳实践了</p>
<blockquote>
<p><a href="https://cn.dubbo.apache.org/zh-cn/overview/mannual/java-sdk/advanced-features-and-usage/performance/threading-model/provider/">https://cn.dubbo.apache.org/zh-cn/overview/mannual/java-sdk/advanced-features-and-usage/performance/threading-model/provider/</a></p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/02/9SLPvH2KUlDbtx7.png" alt="2a5e654b6f1a51b6e0cb7e9e26b03c3d.png"></p>
<p>Dubbo 协议 Provider 线程模型的默认配置是 AllDispatcher。</p>
<p>针对 AllDispatcher 官方给了一个示意图：</p>
<p><img src="https://s2.loli.net/2024/09/02/WqsMADG6gzEPmiI.png" alt="c0c135e8dc0fe9b58f5226c1b2e044e5.png"></p>
<p>图中有 IO thread pool 和 Dubbo thread pool 这两个线程池。</p>
<p>为什么要搞两个线程池呢？</p>
<p>因为 IO 线程是非常宝贵的资源，它只是应该承担发送请求、发送响应的功能。</p>
<p>搞个 Dubbo 线程池的目的就是为了尽快释放宝贵的 IO 线程资源。</p>
<p>比如 received、connected、disconnected、caught 这些行为都是在 Dubbo 线程上执行的，反序列化的动作也是在 Dubbo 的线程池中做的。</p>
<p>类比到我们前面的例子中，IO 线程池就是 Tomcat 线程池，Dubbo 线程池就是我们项目中的自定义线程池。</p>
<p>模式，就是这个模式。</p>
<p>道理，就是这个道理。</p>
<h2 id="继续挖"><a href="#继续挖" class="headerlink" title="继续挖"></a>继续挖</h2><p>如果这真的是一个面试场景题，增加核心线程数和 CallerRunsPolicy 这个方案，面试官肯定是不会满意的，你还得继续往下挖掘。</p>
<p>比如，为什么下游返回的那么慢？</p>
<p>是不是接口上有可以优化的空间？</p>
<p>是不是有慢 SQL？</p>
<p>是不是多返回了不需要的信息？</p>
<p>是不是有不合理的数据结构？</p>
<p>是不是在接口里面干了一些其他的事情？</p>
<p>是不是下游的下游拉胯了？</p>
<p>…</p>
<p>不要老是从自己身上找原因，也合理指出其他人的问题，对吧？</p>
<p>总之，20 多个异步接口，一定是有相对较慢的那个。</p>
<p>它，就是那块短板，找到它，然后定向分析它。</p>
<p>如果下游说实在是没有优化空间了，那就加点钱嘛，多搞几台机器，横向扩展一下，花不了几个钱的。</p>
<p>这种情况在实际工作中还真的挺常见的，歪师傅就遇到过。</p>
<p>上游服务有 8 台机器，我只有 4 台机器，上游并发量一起来，就说我接口响应慢了。</p>
<p>机器都差了一倍，请求来得又太多，都堆起来了，那可不得慢嘛。</p>
<p>当然了，把锅甩给下游，下游不一定会接，问题还是得靠自己解决。</p>
<p>通过前面的分析，我们知道了可以调大核心线程数，但是面试官直接追问一句，调到多少合适呢？</p>
<p>合适，就是一个很微妙的词了。</p>
<p>一般我们用“动态调整”来应对这个问题。</p>
<p>但是在这个“报表”的场景下，歪师傅觉得还真的可以调到一个合适的值，甚至可以用“精准”来形容这个值。</p>
<p>怎么做呢？</p>
<p>上个图：</p>
<p><img src="https://s2.loli.net/2024/09/02/M9TItnQPcilABCm.png" alt="dca9bb25c3151750f06e4404c5e83c61.png"></p>
<p>在每个接口里面搞个线程池，这个线程池的生命周期和一次请求绑定。</p>
<p>即一次请求结束，这个线程池就 shutdown 掉。</p>
<p>你一个接口背后需要调用下游的多少个异步接口，你在写的时候是知道的。</p>
<p>假设是 15 个，那么你在这个请求里面搞个核心线程数是 15 个的线程池。</p>
<p>我就问你，精不精准？</p>
<p>这种用法，就比较适用于这个较为特殊的场景。</p>
<p>特殊点就在于，需要对数据进行聚合处理，所以需要异步调用多个下游服务，要拿到下游服务的数据返回之后，才能返回给调用方。</p>
<p>但是这里上游服务发起调用具有不确定性，可能是同时来 10 个请求，也可能是同时来 1000 个请求。</p>
<p>这种情况导致怎么去合理的定义一个全局的线程池，是一个令人头疼的问题。</p>
<p>所以，换个思路。</p>
<p>在不确定性中寻找确定性。</p>
<p>不确定性是不知道有多少个请求会过来。确定性是每个前端过来的请求，都会对应固定数量的下游接口。</p>
<p>那就不要用全局的线程池了，给每个请求都单独搞个线程池，及时创建，及时回收。</p>
<p>当然，这个方案的弊端之一在于不存在线程池的复用了，只是为了单纯的异步。</p>
<p>弊端之二就是有可能瞬间产生大量的线程，对内存造成一定的压力，但是理论上这些线程都会被很快的回收，所有这点压力应该是在可以接受的范围内。</p>
<p>但是你想想，你调大核心线程数的根本目的是为了给每个异步任务都分配一个线程。</p>
<p>我上面的这个方案能达到一样的目的，而且，控制更加精准。</p>
<h2 id="接着挖"><a href="#接着挖" class="headerlink" title="接着挖"></a>接着挖</h2><p>其实你有没有发现前面说的调整核心数、一个请求对应一个线程池这些方案都很别扭，感觉都不得劲儿？</p>
<p>是的，我就是有这样的感觉。</p>
<p>所以，我再看看问题：</p>
<p><img src="https://s2.loli.net/2024/09/02/dMnpSeDbHOiLP1I.png" alt="b3beff3aa3f74eb06ebae610d728070f.png"></p>
<p>“类似于报表的系统”。</p>
<p>如果我是刚刚工作三年的时候，我可能会在接到这个需求之后就去思考技术方案。</p>
<p>但是现在随着工作年限的增加，我会带着“质疑”的眼光去看待需求，去判断是否是一个“伪需求”。</p>
<p>在需求和技术落地之间找到一个平衡点，让业务和开发都舒服一点。</p>
<p>比如既然是报表为什么要求要实时响应呢？</p>
<p>前端发起请求，后端收到请求之后先返回前端，给个提示：哥们，收到你的请求了，生成报表需要点时间，请十分钟后到 xx 菜单下访问。</p>
<p>然后你后台慢慢处理，其实五分钟就生成好了，然后你给哥们发个短信提醒：数据已就位。</p>
<p>别人还会觉得：可以啊，挺快的，科技的哥们真厉害。</p>
<p>再说了，报表一般来说不都是 T-1 日的数据展示吗？</p>
<p>既然是 T-1 日的数据，那为什么不在凌晨做个定时任务，先主动把各个系统前一日的数据聚合一下，在本地放一份呢？</p>
<p>这样就不用在前端调用的时候，实时去调用接口聚合了嘛。查本地数据，那不是很快的事情，性能一下就上去了。</p>
<p>或者再往前想一步：为什么你要去调用别的系统的接口去获取数据呢？</p>
<p>因为你自己系统没有数据。</p>
<p>为什么你自己系统没有数据呢？</p>
<p>因为你们是微服务架构，数据散落在各个微服务系统里面。</p>
<p>那在拆分微服务的时候，有没有考虑过各种各样的报表需求？</p>
<p>如果考虑过，是不是就应该建设一个大数据平台，由大数据平台将各个微服务系统的业务数据抽走，然后整合数据，基于这些数据出各种各样的报表。</p>
<p>而微服务系统，只需要关注业务就好了。</p>
<p>如果你们没有大数据平台，你应该给领导充分阐述该平台在当下的必要性，以及未来的重要性。</p>
<p>然后，这个功能就不需要你来做了。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>八股文</tag>
      </tags>
  </entry>
  <entry>
    <title>线程池遇到父子任务，有大坑，要注意</title>
    <url>/2024/09/03/%E5%A4%9A%E7%BA%BF%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%81%87%E5%88%B0%E7%88%B6%E5%AD%90%E4%BB%BB%E5%8A%A1%EF%BC%8C%E6%9C%89%E5%A4%A7%E5%9D%91%EF%BC%8C%E8%A6%81%E6%B3%A8%E6%84%8F/</url>
    <content><![CDATA[<p>最近在使用线程池的时候踩了一个坑，给你分享一下。</p>
<p>在实际业务场景下，涉及到业务代码和不同的微服务，导致问题有点难以定位，但是最终分析出原因之后，发现可以用一个很简单的例子来演示。</p>
<p>所以歪师傅这次先用 Demo 说问题，再说场景，方便吸收。</p>
<p><img src="https://s2.loli.net/2024/09/03/WQtCj3yPwYp9vHh.png" alt="cdfcb8560ec948d0fbb2bf3e8952eba3.png"></p>
<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>老规矩，还是先上个代码：</p>
<p><img src="https://s2.loli.net/2024/09/03/2jfJPEWbdYnpDgK.png" alt="02a091c12e7ce28a5eb76ba68f61989c.png"></p>
<p>这个代码的逻辑非常简单，首先我们搞了一个线程池，然后起一个 for 循环往线程池里面仍了 5 个任务，这是核心逻辑。</p>
<p>对于这几个任务，我们的这个自定义线程池处理起来，不能说得心应手吧，至少也是手拿把掐。</p>
<p>其他的 StopWatch 是为了统计运行时间用的。 至于 CountDownLatch，你可以理解为在业务流程中，需要这五个任务都执行完成之后才能往下走，所以我搞了一个 CountDownLatch。</p>
<p>这个代码运行起来是没有任何问题的，我们在日志中搜索“执行完成”，也能搜到 5 个，这个结果也能证明程序是正常结束的：</p>
<p><img src="https://s2.loli.net/2024/09/03/FuYUoHXOMRiJrwD.png" alt="2ffa8083c59e7c0739c1237c1b76be4e.png"></p>
<p>同时，可以看到运行时间是 4s。</p>
<p>示意图大概是这样的：</p>
<p><img src="https://s2.loli.net/2024/09/03/rBRqi6U4hw1a2oV.png" alt="977faa950e1395f5d8f7729ad98f609d.png"></p>
<p>然后看着这个代码，发现了一个可以优化的地方：</p>
<p><img src="https://s2.loli.net/2024/09/03/H4moCxeRnFJWfkU.png" alt="3dd5fe8d407764879750658ea43a5977.png"></p>
<p>这个地方从数据库捞出来的数据，它们之间是没有依赖关系的，也就是说它们之间也是可以并行执行的。</p>
<p>所以把代码改成了这样：</p>
<p><img src="https://s2.loli.net/2024/09/03/kRovT3JfqeM25P4.png" alt="b7bd836031f27b08ac01ccd94201d9e5.png"></p>
<p>在异步线程里面去处理这部分从数据库中捞出来的数据，并行处理加快响应速度。</p>
<p>对应到图片，大概就是这个意思：</p>
<p><img src="https://s2.loli.net/2024/09/03/C3PzUg4dGmN6Muy.png" alt="7bb84a7512e8a85e1ba8e99065e5e03e.png"></p>
<p>把程序运行起来之后，日志变成了这样：</p>
<p><img src="https://s2.loli.net/2024/09/03/Y3q5viEDergSbFa.png" alt="0966c9d15bfdfed9d0e0d897812f3d53.png"></p>
<p>我们搜索“执行完成”，也能搜到 5 个对应输出。</p>
<p>而且我们就拿“任务2”来说：</p>
<p><img src="https://s2.loli.net/2024/09/03/YUfzGV52lWNcjRZ.png" alt="3f43ab28a81aa96449dde4cbb9e9ac21.png"></p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">当前线程pool<span class="string">-1</span>-thread<span class="string">-3</span>,---【任务2】开始执行--- </span><br><span class="line">当前线程pool<span class="string">-1</span>-thread<span class="string">-3</span>,---【任务2】执行完成--- </span><br><span class="line">当前线程pool<span class="string">-1</span>-thread<span class="string">-1</span>,【任务2】开始处理数据=1 </span><br><span class="line">当前线程pool<span class="string">-1</span>-thread<span class="string">-2</span>,【任务2】开始处理数据=2</span><br></pre></td></tr></table></figure>


<p>从日志输出来看，任务 2 需要处理的两个数据，确实是在不同的异步线程中处理数据，也实现了我的需求。</p>
<p>但是，程序运行直接就是到了 9.9ms：</p>
<p><img src="https://s2.loli.net/2024/09/03/4CaF9MtK1Pkbvhn.png" alt="0e61da6218b726133ab1c40b7d4b384b.png"></p>
<p>这个优化这么牛逼的吗？</p>
<p>从 4s 到了 9.9ms？</p>
<p>稍加分析，你会发现这里面是有问题的。</p>
<p>那么问题就来了，到底是啥问题呢？</p>
<p>问题就是由于转异步了，所以 for 循环里面的任务中的 countDownLatch 很快就减到 0 了。</p>
<p>于是 await 继续执行，所以很快就输出了程序运行时间。</p>
<p>然而实际上子任务还在继续执行，程序并没有真正完成。</p>
<p>9.9ms 只是任务提交到线程池的时间，每个任务的数据处理时间还没算呢：</p>
<p><img src="https://s2.loli.net/2024/09/03/nV9Qc4brgmRILPT.png" alt="e982e80631c5ee58ecefe5f26adf5f02.png"></p>
<p>从日志输出上也可以看出，在输出了 StopWatch 的日志后，各个任务还在处理数据。</p>
<p>这样时间就显得不够真实。</p>
<p>那么我们应该怎么办呢？</p>
<p>很简单嘛，需要子任务真正执行完成后，父任务的 countDownLatch 才能进行 countDown 的动作。</p>
<p>具体实现上就是给子任务再加一个 countDownLatch 栅栏：</p>
<p><img src="https://s2.loli.net/2024/09/03/8XJMVRxNUKCwToh.png" alt="3f80049115376aff07bf5d2483e9c317.png"></p>
<p>我们希望的运行结果应该是这样的：</p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">当前线程pool<span class="string">-1</span>-thread<span class="string">-3</span>,---【任务2】开始执行--- </span><br><span class="line">当前线程pool<span class="string">-1</span>-thread<span class="string">-1</span>,【任务2】开始处理数据=1 </span><br><span class="line">当前线程pool<span class="string">-1</span>-thread<span class="string">-2</span>,【任务2】开始处理数据=2 </span><br><span class="line">当前线程pool<span class="string">-1</span>-thread<span class="string">-3</span>,---【任务2】执行完成---</span><br></pre></td></tr></table></figure>


<p>即子任务全部完成之后，父任务才能算执行完成，这样统计出来的时间才是准确的。</p>
<p>思路清晰，非常完美，再次运行，观察日志我们会发现：</p>
<p><img src="https://s2.loli.net/2024/09/03/VIoXJTivs5LOASa.png" alt="ea23ee882a713f1bbefa751215ae9129.png"></p>
<p>呃，怎么回事，日志怎么不输出了？</p>
<p>是的，就是不输出了。</p>
<p>不输出了，就是踩到这个坑了。</p>
<p>不论你重启多少次，都是这样：日志不输出了，程序就像是卡着了一样。</p>
<p><img src="https://s2.loli.net/2024/09/03/c4BHhfDuOsV7imE.png" alt="67097d515491de337e94c6c03495a263.png"></p>
<h2 id="坑在哪儿"><a href="#坑在哪儿" class="headerlink" title="坑在哪儿"></a>坑在哪儿</h2><p>上面这个 Demo 已经是我基于遇到的生产问题，极力简化后的版本了。</p>
<p>现在，这个坑也已经呈现在你眼前了。</p>
<p>我们一起来分析一波。</p>
<p>首先，我问你：真的在线上遇到这种程序“假死”的问题，你会怎么办？</p>
<p>早几年，歪师傅的习惯是抱着代码慢慢啃，试图从代码中找到端倪。</p>
<p>这样确实是可以，但是通常来说效率不高。</p>
<p>现在我的习惯是直接把现场 dump 下来，分析现场。</p>
<p>比如在这个场景下，我们直观上的感受是“卡住了”，那就 dump 一把线程，管它有枣没枣，打一杆子再说：</p>
<p><img src="https://s2.loli.net/2024/09/03/BEUiPn1TaOqVo4R.png" alt="dbf92c064da303261fc263ba466d74cf.png"></p>
<p>通过 Dump 文件，可以发现线程池的线程都在 MainTest 的第 30 行上 parking ，处于等待状态：</p>
<p><img src="https://s2.loli.net/2024/09/03/spNd8mRrJB5GHMT.png" alt="33a7c22a3d889488db9033f6166a7b16.png"></p>
<p>那么第 30 行是啥玩意？</p>
<p><img src="https://s2.loli.net/2024/09/03/3CSH7RdcJWifwmZ.png" alt="70b146422b8b59b0968132b017f66e18.png"></p>
<p>这行代码在干啥？</p>
<blockquote>
<p>countDownLatchSub.await();</p>
</blockquote>
<p>是父任务在等待子任务执行结束，运行 finally 代码，把 countDownLatchSub 的计数 countDown 到 0，才会继续执行：</p>
<p><img src="https://s2.loli.net/2024/09/03/pMR4fgDHAJv6BTd.png" alt="80c679842aebbf34d460772fb83725b9.png"></p>
<p>所以现在的现象就是子任务的 countDownLatchSub 把父任务的拦住了。</p>
<p>换句话说就是父任务被拦住是因为子任务的 finally 代码中的 countDownLatchSub.countDown() 方法没有被执行。</p>
<p>好，那么最关键的问题就来了：为什么没有执行？</p>
<p>你先别往下看，闭上眼睛在你的小脑瓜子里面推演一下，琢磨一下：finally 为什么没有执行？</p>
<p><img src="https://s2.loli.net/2024/09/03/Q8XZNfd27lirqjs.png" alt="d7ef083a6300f875f100b1d7da30b6ad.png"></p>
<p>或者再换个更加接近真实的问题：子任务为什么没有执行？</p>
<p>这个点，非常简单，可以说一点就破。</p>
<p>琢磨明白了，这个坑的原理摸摸清楚了。</p>
<p>…</p>
<p>…</p>
<p>…</p>
<p>琢磨明白了吗？你就刷刷往下看？</p>
<p><img src="https://s2.loli.net/2024/09/03/5pzlTR6QaADLmsY.png" alt="8d6a12da7c8c6403ec9e19cb3fda33dd.png"></p>
<p>没明白我再给你一个信息：需要结合线程池的参数和运行原理来分析。</p>
<p>什么？</p>
<p>你说线程池的运行原理你不清楚？</p>
<p>请你出门右转好嘛。</p>
<p>…</p>
<p>…</p>
<p>…</p>
<p>好，不管你“恍然大悟”了没有。</p>
<p>让你知道“一点就破”这四个是怎么回事儿。</p>
<p>首先，我们把目光聚焦在线程池这里：</p>
<p><img src="https://s2.loli.net/2024/09/03/m5axC7OkjG6QSUg.png" alt="071ef3a06e1a425f9883ddf1522aa58c.png"></p>
<p>这个线程池核心线程数是 3，但是我们要提交 5 个任务到线程池去。</p>
<p>父任务哐哐哐，就把核心线程数占满了。</p>
<p>接下来子任务也要往这个线程池提交任务怎么办？</p>
<p>当然是进队列等着了。</p>
<p>一进队列，就完犊子。</p>
<p>到这里，我觉得你应该能想明白问题了。</p>
<p>应该给到我一个恍然大悟的表情，并配上“哦哦哦~”这样的内心 OS。</p>
<p><img src="https://s2.loli.net/2024/09/03/iUb65g2V9NpjnEK.png" alt="547761cceb36e0ee84c7f280cd01dc45.png"></p>
<p><strong>你想想，父任务这个时候干啥？</strong></p>
<p>是不是等在 countDownLatchSub.await() 这里。</p>
<p>而 countDownLatchSub.await() 什么时候能继续执行？</p>
<p>是不是要所有子任务都执行 finally 后？</p>
<p>那么子任务现在在干啥？</p>
<p>是不是都在线程池里面的队列等着被执行呢？</p>
<p>那线程池队列里面的任务什么时候才执行？</p>
<p>是不是等着有空闲线程的时候？</p>
<p>那现在有没有空闲线程？</p>
<p>没有，所有的线程都去执行父任务去了。</p>
<p><strong>那你想想，父任务这个时候干啥？</strong></p>
<p>是不是等在 countDownLatchSub.await() 这里。</p>
<p>…</p>
<p>父任务在等子任务执行。</p>
<p>子任务在等线程池调度。</p>
<p>线程池在等父任务释放线程。</p>
<p>闭环了，相互等待了，家人们。</p>
<p>这，就是坑。</p>
<p>现在把坑的原理摸清楚了，我在给你说一下真实的线上场景踩到这个坑是怎么样的呢？</p>
<p><img src="https://s2.loli.net/2024/09/03/ld3hLgPxz2qZWMa.png" alt="729ba8d23d1540c36531f680ff4ee960.png"></p>
<p>上游发起请求到微服务 A 的接口 1，该接口需要调用微服务 B 的接口 2。</p>
<p>但是微服务 B 的接口 2，需要从微服务 A 接口 3 获取数据。</p>
<p>然而在微服务 A 内部，全局使用的是同一个自定义线程池。</p>
<p>更巧的是接口 1 和接口 3 内部都使用了这个自定义线程池做异步并行处理，想着是加快响应速度。</p>
<p>整个情况就变成了这样：</p>
<p>接口 1 收到请求之后，把请求转到自定义线程池中，然后等接口 2 返回。<br>接口 2 调用接口 3，并等待返回。<br>接口 3 里面把请求转到了自定义线程池中，被放入了队列。<br>线程池的线程都被接口 1 给占住了，没有资源去执行队列里面的接口 3 任务。<br>相互等待，一直僵持。<br>我们的 Demo 还是能比较清晰的看到父子任务之间的关系。</p>
<p>但是在这个微服务的场景下，在无形之间，就形成了不易察觉的父子任务关系。</p>
<p>所以就踩到了这个坑。</p>
<h2 id="怎么避免"><a href="#怎么避免" class="headerlink" title="怎么避免"></a>怎么避免</h2><p>找到了坑的原因，解决方案就随之而出了。</p>
<p>父子任务不要共用一个线程池，给子任务也搞一个自定义线程池就可以了：</p>
<p><img src="https://s2.loli.net/2024/09/03/HlYndOUheXMx4Wc.png" alt="7c159cd6f108dc89e1007c2b1e1bb392.png"></p>
<p>运行起来看看日志：</p>
<p><img src="https://s2.loli.net/2024/09/03/AIVlfzNvxqgDQur.png" alt="1e294ad02633583a8d3a906351f9eafd.png"></p>
<p>首先整体运行时间只需要 2s 了，达到了我想要的效果。</p>
<p>另外，我们观察一个具体的任务：</p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">当前线程pool<span class="string">-1</span>-thread<span class="string">-3</span>,---【任务2】开始执行--- </span><br><span class="line">当前线程pool<span class="string">-2</span>-thread<span class="string">-1</span>,【任务2】开始处理数据=1 </span><br><span class="line">当前线程pool<span class="string">-2</span>-thread<span class="string">-4</span>,【任务2】开始处理数据=2 </span><br><span class="line">当前线程pool<span class="string">-1</span>-thread<span class="string">-3</span>,---【任务2】执行完成---</span><br></pre></td></tr></table></figure>

<p>日志输出符合我们前面分析的，所有子任务执行完成后，父任务才打印执行完成，且子任务在不同的线程中执行。</p>
<p>而使用不同的线程池，换一个高大上的说法就叫做：线程池隔离。</p>
<p>而且在一个项目中，公用一个线程池，也是一个埋坑的逻辑。</p>
<p>至少给你觉得关键的逻辑，单独分配一个线程池吧。</p>
<p>避免出现线程池的线程都在执行非核心逻辑了，反而重要的任务在队列里面排队去了。</p>
<p>这就有点不合理了。</p>
<p>最后，一句话总结这个问题：</p>
<blockquote>
<p>如果线程池的任务之间存在父子关系，那么请不要使用同一个线程池。如果使用了同一个线程池，可能会因为子任务进了队列，导致父任务一直等待，出现假死现象。</p>
</blockquote>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>八股文</tag>
      </tags>
  </entry>
  <entry>
    <title>一个 SpringBoot 项目能同时处理多少请求？</title>
    <url>/2024/09/07/%E4%B8%80%E4%B8%AASpring%20Boot%E5%8F%AF%E4%BB%A5%E5%A4%84%E7%90%86%E5%A4%9A%E5%B0%91%E4%B8%AA%E8%AF%B7%E6%B1%82%EF%BC%9F/</url>
    <content><![CDATA[<p>一个 SpringBoot 项目能同时处理多少请求？</p>
<p>不知道你听到这个问题之后的第一反应是什么。</p>
<p>我大概知道他要问的是哪个方向，但是对于这种只有一句话的面试题，我的第一反应是：会不会有坑？</p>
<p>所以并不会贸然答题，先追问一些消息，比如：这个项目具体是干什么的？项目大概进行了哪些参数配置？使用的 web 容器是什么？部署的服务器配置如何？有哪些接口？接口响应平均时间大概是多少？</p>
<p>这样，在几个问题的拉扯之后，至少在面试题考察的方向方面能基本和面试官达成了一致。</p>
<p>比如前面的面试问题，经过几次拉扯之后，面试官可能会修改为：</p>
<blockquote>
<p>一个 SpringBoot 项目，未进行任何特殊配置，全部采用默认设置，这个项目同一时刻，最多能同时处理多少请求？</p>
</blockquote>
<p>能处理多少呢？</p>
<p>我也不知道，但是当问题变成上面这样之后，我找到了探索答案的角度。</p>
<p>既然“未进行任何特殊配置”，那我自己搞个 Demo 出来，压一把不就完事了吗？</p>
<p>坐稳扶好，准备发车。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716173852.png" alt="img"></p>
<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a><strong>Demo</strong></h2><p>小手一抖，先搞个 Demo 出来。</p>
<p>这个 Demo 非常的简单，就是通过 idea 创建一个全新的 SpringBoot 项目就行。</p>
<p><strong>我的 SpringBoot 版本使用的是 2.7.13。</strong></p>
<p>整个项目只有这两个依赖：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716105209.png" alt="img"></p>
<p>整个项目也只有两个类，要得就是一个空空如也，一清二白。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716104148.png" alt="img"></p>
<p>项目中的 TestController，里面只有一个 getTest 方法，用来测试，方法里面接受到请求之后直接 sleep 一小时。</p>
<p>目的就是直接把当前请求线程占着，这样我们才能知道项目中一共有多少个线程可以使用：</p>
<figure class="highlight less"><table><tr><td class="code"><pre><span class="line"><span class="variable">@Slf4j</span></span><br><span class="line"><span class="variable">@RestController</span></span><br><span class="line">public class TestController &#123;</span><br><span class="line"></span><br><span class="line">    <span class="variable">@GetMapping</span>(<span class="string">&quot;/getTest&quot;</span>)</span><br><span class="line">    public void <span class="built_in">getTest</span>(int num) throws Exception &#123;</span><br><span class="line">        <span class="selector-tag">log</span><span class="selector-class">.info</span>(<span class="string">&quot;&#123;&#125; 接受到请求:num=&#123;&#125;&quot;</span>, Thread.<span class="built_in">currentThread</span>().<span class="built_in">getName</span>(), num);</span><br><span class="line">        <span class="selector-tag">TimeUnit</span><span class="selector-class">.HOURS</span><span class="selector-class">.sleep</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>项目中的 application.properties 文件也是空的：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716104407.png" alt="img"></p>
<p>这样，一个“未进行任何特殊配置”的 SpringBoot 不就有了吗？</p>
<p>基于这个 Demo，前面的面试题就要变成了：我短时间内不断的调用这个 Demo 的 getTest 方法，最多能调用多少次？</p>
<p>问题是不是又变得更加简单了一点？</p>
<p>那么前面这个“短时间内不断的调用”，用代码怎么表示呢？</p>
<p>很简单，就是在循环中不断的进行接口调用就行了。</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span>(<span class="params">String[] args</span>)</span> &#123;</span><br><span class="line">        RestTemplate restTemplate = <span class="keyword">new</span> RestTemplate();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">            <span class="built_in">int</span> finalI = i;</span><br><span class="line">            <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                restTemplate.getForObject(<span class="string">&quot;http://127.0.0.1:8080/getTest?num=&quot;</span> + finalI, Integer.<span class="keyword">class</span>);</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//阻塞主线程</span></span><br><span class="line">        Thread.<span class="keyword">yield</span>();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>当然了，这个地方你用一些压测工具，比如 jmeter 啥的，会显得逼格更高，更专业。我这里就偷个懒，直接上代码了。</p>
<h2 id="答案"><a href="#答案" class="headerlink" title="答案"></a><strong>答案</strong></h2><p>经过前面的准备工作，Demo 和测试代码都就绪了。</p>
<p>接下来就是先把 Demo 跑起来：</p>
<p><img src="https://s2.loli.net/2024/09/07/YtPoiNdFWc3jSTC.png" alt="image-20240907193556440"></p>
<p>然后跑一把 MainTest。</p>
<p>当 MainTest 跑起来之后，Demo 这边就会快速的、大量的输出这样的日志：</p>
<p><img src="https://s2.loli.net/2024/09/07/I16NuhVc3oBfWzk.png" alt="image-20240907194156820"></p>
<p>也就是我前面 getTest 方法中写的日志：</p>
<p><img src="https://s2.loli.net/2024/09/07/UyuIOjo7tNg4cRP.png" alt="image-20240907194212826"></p>
<p>好，现在我们回到这个问题：</p>
<blockquote>
<p>我短时间内不断的调用这个 Demo 的 getTest 方法，最多能调用多少次？</p>
</blockquote>
<p>来，请你告诉我怎么得到这个问题的答案？</p>
<p>我这里就是一个大力出奇迹，直接统计“接受到请求”关键字在日志中出现的次数就行了：</p>
<p><img src="E:/blog/images/springboot%E9%A1%B9%E7%9B%AE%E5%8F%AF%E4%BB%A5%E6%8E%A5%E5%8F%97%E5%A4%9A%E5%B0%91%E8%AF%B7%E6%B1%82/20240907-3.png" alt="image-20240907200114910"></p>
<p>很显然，答案就是：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716174117.png" alt="img"></p>
<p>所以，当面试官问你：一个 SpringBoot 项目能同时处理多少请求？</p>
<p>你装作仔细思考之后，笃定的说：200 次。</p>
<p>面试官微微点头，并等着你继续说下去。</p>
<p>你也暗自欢喜，背了个答案。然后等着面试官继续问其他问题。</p>
<p>气氛突然就尴尬了起来。</p>
<p>接着，你就回家等通知了。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716174231.png" alt="img"></p>
<p>200 次，这个回答是对的，但是你只说 200 次，这个回答就显得有点尬了。</p>
<p>重要的是，这个值是怎么来的？</p>
<p>所以，下面这一部分，你也要背下来。</p>
<h2 id="怎么来的？"><a href="#怎么来的？" class="headerlink" title="怎么来的？"></a><strong>怎么来的？</strong></h2><p>在开始探索怎么来的之前，我先问你一个问题，这个 200 个线程，是谁的线程，或者说是谁在管理这个线程？</p>
<p>是 SpringBoot 吗？</p>
<p>肯定不是，SpringBoot 并不是一个 web 容器。</p>
<p>应该是 Tomcat 在管理这 200 个线程。</p>
<p>这一点，我们通过线程 Dump 也能进行验证：</p>
<p><img src="https://s2.loli.net/2024/09/07/8Zh4nIFHKdAUyTS.png" alt="image-20240907200341230"></p>
<p><img src="https://s2.loli.net/2024/09/07/J74KNC8kDqj6zET.png" alt="image-20240907201353030"></p>
<p>通过线程 Dump 文件，我们可以知道，大量的线程都在 sleep 状态。而点击这些线程，查看其堆栈消息，可以看到 Tomcat、threads、ThreadPoolExecutor 等关键字：</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="built_in">at</span> <span class="keyword">org.apache.Tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1791)</span></span><br><span class="line"><span class="keyword"></span><span class="built_in">at</span> <span class="keyword">org.apache.Tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)</span></span><br><span class="line"><span class="keyword"></span><span class="built_in">at</span> <span class="keyword">org.apache.Tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)</span></span><br><span class="line"><span class="keyword"></span><span class="built_in">at</span> <span class="keyword">org.apache.Tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)</span></span><br><span class="line"><span class="keyword"></span><span class="built_in">at</span> <span class="keyword">org.apache.Tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)</span></span><br></pre></td></tr></table></figure>

<p>基于“短时间内有 200 个请求被立马处理的”这个现象，结合你背的滚瓜烂熟的、非常扎实的线程池知识，你先大胆的猜一个：Tomcat 默认核心线程数是 200。</p>
<p>接下来，我们就是要去源码里面验证这个猜测是否正确了。</p>
<p>教你一个不用打断点也能获取到调用栈的方法。</p>
<p>在前面已经展示过了，就是线程 Dump。</p>
<p>右边就是一个线程完整的调用栈：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716113346.png" alt="img"></p>
<p>从这个调用栈中，由于我们要找的是 Tomcat 线程池相关的源码，所以第一次出现相关关键字的地方就是这一行：</p>
<blockquote>
<p>org.apache.Tomcat.util.threads.ThreadPoolExecutor.Worker#run</p>
</blockquote>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716120846.png" alt="img"></p>
<p>然后我们在这一行打上断点。</p>
<p>重启项目，开始调试。</p>
<p>进入 runWorker 之后，这部分代码看起来就非常眼熟了：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716132249.png" alt="img"></p>
<p>简直和 JDK 里面的线程池源码一模一样。</p>
<p>如果你熟悉 JDK 线程池源码的话，调试 Tomcat 的线程池，那个感觉，就像是回家一样。</p>
<p>如果你不熟悉的话，我建议你尽快去熟悉熟悉。</p>
<p>随着断点往下走，在 getTask 方法里面，可以看到关于线程池的几个关键参数：</p>
<blockquote>
<p>org.apache.Tomcat.util.threads.ThreadPoolExecutor#getTask</p>
</blockquote>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716132830.png" alt="img"></p>
<p>corePoolSize，核心线程数，值为 10。</p>
<p>maximumPoolSize，最大线程数，值为 200。</p>
<p>而且基于 maximumPoolSize 这个参数，你往前翻代码，会发现这个默认值就是 200：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716164409.png" alt="img"></p>
<p>好，到这里，你发现你之前猜测的“Tomcat 默认核心线程数是 200”是不对的。</p>
<p>但是你一点也不慌，再次结合你背的滚瓜烂熟的、非常扎实的线程池知识。</p>
<p>并在心里又默念了一次：当线程池接受到任务之后，先启用核心线程数，再使用队列长度，最后启用最大线程数。</p>
<p>因为我们前面验证了，Tomcat 可以同时间处理 200 个请求，而它的线程池核心线程数只有 10，最大线程数是 200。</p>
<p>这说明，我前面这个测试用例，把队列给塞满了，从而导致 Tomcat 线程池启用了最大线程数：</p>
<p><img src="https://s2.loli.net/2024/09/07/QmX28j75gzANbdr.png" alt="image-20240907202222717"></p>
<p>嗯，一定是这样的！</p>
<p>那么，现在的关键问题就是：Tomcat 线程池默认的队列长度是多少呢？</p>
<p>在当前的这个 Debug 模式下，队列长度可以通过 Alt+F8 进行查看：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716133352.png" alt="img"></p>
<p>wc，这个值是 Integer.MAX_VALUE，这么大？</p>
<p>我一共也才 1000 个任务，不可能被占满啊？</p>
<p>一个线程池：</p>
<ul>
<li>核心线程数，值为 10。</li>
<li>最大线程数，值为 200。</li>
<li>队列长度，值为 Integer.MAX_VALUE。</li>
</ul>
<p>1000 个比较耗时的任务过来之后，应该是只有 10 个线程在工作，然后剩下的 990 个进队列才对啊？</p>
<p>难道我八股文背错了？</p>
<p>这个时候不要慌，嗦根辣条冷静一下。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716174538.png" alt="img"></p>
<p>目前已知的是核心线程数，值为 10。这 10 个线程的工作流程是符合我们认知的。</p>
<p>但是第 11 个任务过来的时候，本应该进入队列去排队。</p>
<p>现在看起来，是直接启用最大线程数了。</p>
<p>所以，我们先把测试用例修改一下：</p>
<p><img src="https://s2.loli.net/2024/09/07/ae2EQNXmABFIpL7.png" alt="image-20240907202320321"></p>
<p>那么问题就来了：最后一个请求到底是怎么提交到线程池里面的？</p>
<p>前面说了，Tomcat 的线程池源码和 JDK 的基本一样。</p>
<p>往线程池里面提交任务的时候，会执行 execute 这个方法：</p>
<blockquote>
<p>org.apache.Tomcat.util.threads.ThreadPoolExecutor#execute(java.lang.Runnable)</p>
</blockquote>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716141941.png" alt="img"></p>
<p>对于 Tomcat 它会调用到 executeInternal 这个方法：</p>
<blockquote>
<p>org.apache.Tomcat.util.threads.ThreadPoolExecutor#executeInternal</p>
</blockquote>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716141541.png" alt="img"></p>
<p>这个方法里面，标号为 ① 的地方，就是判断当前工作线程数是否小于核心线程数，小于则直接调用 addWorker 方法，创建线程。</p>
<p>标号为 ② 的地方主要是调用了 offer 方法，看看队列里面是否还能继续添加任务。</p>
<p>如果不能继续添加，说明队列满了，则来到标号为 ③ 的地方，看看是否能执行 addWorker 方法，创建非核心线程，即启用最大线程数。</p>
<p>把这个逻辑捋顺之后，接下来我们应该去看哪部分的代码，就很清晰了。</p>
<p>主要就是去看 workQueue.offer(command) 这个逻辑。</p>
<p>如果返回 true 则表示加入到队列，返回 false 则表示启用最大线程数嘛。</p>
<p>这个 workQueue 是 TaskQueue，看起来一点也不眼熟：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716142645.png" alt="img"></p>
<p>当然不眼熟了，因为这个是 Tomcat 自己基于 LinkedBlockingQueue 搞的一个队列。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716142935.png" alt="img"></p>
<p>问题的答案就藏在 TaskQueue 的 offer 方法里面。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716174728.png" alt="img"></p>
<p>所以我重点带你盘一下这个 offer 方法：</p>
<blockquote>
<p>org.apache.Tomcat.util.threads.TaskQueue#offer</p>
</blockquote>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716143324.png" alt="img"></p>
<p>标号为 ① 的地方，判断了 parent 是否为 null，如果是则直接调用父类的 offer 方法。说明要启用这个逻辑，我们的 parent 不能为 null。</p>
<p>那么这个 parent 是什么玩意，从哪里来的呢？</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716143607.png" alt="img"></p>
<p>parent 就是 Tomcat 线程池，通过其 set 方法可以知道，是在线程池完成初始化之后，进行了赋值。</p>
<p>也就是说，你可以理解为，在 Tomcat 的场景下，parent 不会为空。</p>
<p>标号为 ② 的地方，调用了 getPoolSizeNoLock 方法：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716144049.png" alt="img"></p>
<p>这个方法是获取当前线程池中有多个线程。</p>
<p>所以如果这个表达式为 true：</p>
<blockquote>
<p>parent.getPoolSizeNoLock() == parent.getMaximumPoolSize()</p>
</blockquote>
<p>就表明当前线程池的线程数已经是配置的最大线程数了，那就调用 offer 方法，把当前请求放到到队列里面去。</p>
<p>标号为 ③ 的地方，是判断已经提交到线程池里面待执行或者正在执行的任务个数，是否比当前线程池的线程数还少。</p>
<p>如果是，则说明当前线程池有空闲线程可以执行任务，则把任务放到队列里面去，就会被空闲线程给取走执行。</p>
<p>然后，关键的来了，标号为 ④ 的地方。</p>
<p>如果当前线程池的线程数比线程池配置的最大线程数还少，则返回 false。</p>
<p>前面说了，offer 方法返回 false，会出现什么情况？</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716141541.png" alt="img"></p>
<p>是不是直接开始到上图中标号为 ③ 的地方，去尝试添加非核心线程了？</p>
<p>也就是启用最大线程数这个配置了。</p>
<p>所以，朋友们，这个是什么情况？</p>
<p>这个情况确实就和我们背的线程池的八股文不一样了啊。</p>
<p>JDK 的线程池，是先使用核心线程数配置，接着使用队列长度，最后再使用最大线程配置。</p>
<p>Tomcat 的线程池，就是先使用核心线程数配置，再使用最大线程配置，最后才使用队列长度。</p>
<p>所以，以后当面试官给你说：我们聊聊线程池的工作机制吧？</p>
<p>你就先追问一句：你是说的 JDK 的线程池呢还是 Tomcat 的线程池呢，因为这两个在运行机制上有一点差异。</p>
<p>然后，你就看他的表情。</p>
<p>如果透露出一丝丝迟疑，然后轻描淡写的说一句：那就对比着说一下吧。</p>
<p>那么恭喜你，在这个题目上开始掌握了一点主动权。</p>
<p>最后，为了让你更加深刻的理解到 Tomcat 线程池和 JDK 线程池的不一样，我给你搞一个直接复制过去就能运行的代码。</p>
<p>当你把 taskqueue.setParent(executor) 这行代码注释掉的时候，它的运行机制就是 JDK 的线程池。</p>
<p>当存在这行代码的时候，它的运行机制就变成了 Tomcat 的线程池。</p>
<p>玩去吧。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.tomcat.util.threads.TaskQueue;</span><br><span class="line"><span class="keyword">import</span> org.apache.tomcat.util.threads.TaskThreadFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.tomcat.util.threads.ThreadPoolExecutor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TomcatThreadPoolExecutorTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">namePrefix</span> <span class="operator">=</span> <span class="string">&quot;歪歪歪-exec-&quot;</span>;</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">daemon</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="type">TaskQueue</span> <span class="variable">taskqueue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueue</span>(<span class="number">300</span>);</span><br><span class="line">        <span class="type">TaskThreadFactory</span> <span class="variable">tf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskThreadFactory</span>(namePrefix, daemon, Thread.NORM_PRIORITY);</span><br><span class="line">        <span class="type">ThreadPoolExecutor</span> <span class="variable">executor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(<span class="number">5</span>,</span><br><span class="line">                <span class="number">150</span>, <span class="number">60000</span>, TimeUnit.MILLISECONDS, taskqueue, tf);</span><br><span class="line">        taskqueue.setParent(executor);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">300</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                executor.execute(() -&gt; &#123;</span><br><span class="line">                    logStatus(executor, <span class="string">&quot;创建任务&quot;</span>);</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        TimeUnit.SECONDS.sleep(<span class="number">2</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        Thread.currentThread().join();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">logStatus</span><span class="params">(ThreadPoolExecutor executor, String name)</span> &#123;</span><br><span class="line">        <span class="type">TaskQueue</span> <span class="variable">queue</span> <span class="operator">=</span> (TaskQueue) executor.getQueue();</span><br><span class="line">        System.out.println(Thread.currentThread().getName() + <span class="string">&quot;-&quot;</span> + name + <span class="string">&quot;-:&quot;</span> +</span><br><span class="line">                <span class="string">&quot;核心线程数:&quot;</span> + executor.getCorePoolSize() +</span><br><span class="line">                <span class="string">&quot;\t活动线程数:&quot;</span> + executor.getActiveCount() +</span><br><span class="line">                <span class="string">&quot;\t最大线程数:&quot;</span> + executor.getMaximumPoolSize() +</span><br><span class="line">                <span class="string">&quot;\t总任务数:&quot;</span> + executor.getTaskCount() +</span><br><span class="line">                <span class="string">&quot;\t当前排队线程数:&quot;</span> + queue.size() +</span><br><span class="line">                <span class="string">&quot;\t队列剩余大小:&quot;</span> + queue.remainingCapacity());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="等等"><a href="#等等" class="headerlink" title="等等"></a><strong>等等</strong></h2><p>如果你之前确实没了解过 Tomcat 线程池的工作机制，那么看到这里的时候也许你会觉得确实是有一点点收获。</p>
<p>但是，注意我要说但是了。</p>
<p>还记得最开始的时候面试官的问题吗？</p>
<p>面试官的原问题就是：一个 SpringBoot 项目能同时处理多少请求？</p>
<p>那么请问，前面我讲了这么大一坨 Tomcat 线程池运行原理，这个回答，和这个问题匹配吗？</p>
<p>是的，除了最开始提出的 200 这个数值之外，并不匹配，甚至在面试官的眼里完全是答非所问了。</p>
<p>所以，为了把这两个“并不匹配”的东西比较顺畅的链接起来，你必须要先回答面试官的问题，然后再开始扩展。</p>
<p>比如这样答：一个未进行任何特殊配置，全部采用默认设置的 SpringBoot 项目，这个项目同一时刻最多能同时处理多少请求，取决于我们使用的 web 容器，而 SpringBoot 默认使用的是 Tomcat。</p>
<p>Tomcat 的默认核心线程数是 10，最大线程数 200，队列长度是无限长。但是由于其运行机制和 JDK 线程池不一样，在核心线程数满了之后，会直接启用最大线程数。所以，在默认的配置下，同一时刻，可以处理 200 个请求。</p>
<p>在实际使用过程中，应该基于服务实际情况和服务器配置等相关消息，对该参数进行评估设置。</p>
<p>这个回答就算是差不多了。</p>
<p>但是，如果很不幸，如果你遇到了我，为了验证你是真的自己去摸索过，还是仅仅只是看了几篇文章，我可能还会追问一下：</p>
<p>那么其他什么都不动，如果我仅仅加入 server.tomcat.max-connections=10 这个配置呢，那么这个时候最多能处理多少个请求？</p>
<p>你可能就要猜了：10 个。</p>
<p>是的，我重新提交 1000 个任务过来，在控制台输出的确实是 10 个，</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716154330.png" alt="img"></p>
<p>那么 max-connections 这个参数它怎么也能控制请求个数呢？</p>
<p>为什么在前面的分析过程中我们并没有注意到这个参数呢？</p>
<p>首先我们看一下它的默认值：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716160608.png" alt="img"></p>
<p>因为它的默认值是 8192，比最大线程数 200 大，这个参数并没有限制到我们，所以我们没有关注到它。</p>
<p>当我们把它调整为 10 的时候，小于最大线程数 200，它就开始变成限制项了。</p>
<p>那么 max-connections 这个参数到底是干啥的呢？</p>
<p>你先自己去摸索摸索吧。</p>
<p>同时，还有这样的一个参数，默认是 100：</p>
<blockquote>
<p>server.tomcat.accept-count=100</p>
</blockquote>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716161005.png" alt="img"></p>
<p>它又是干什么的呢？</p>
<p>“和连接数有关”，我只能提示到这里了，自己去摸索吧。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716180537.png" alt="img"></p>
<h2 id="再等等"><a href="#再等等" class="headerlink" title="再等等"></a><strong>再等等</strong></h2><p>通过前面的分析，我们知道了，要回答“一个 SpringBoot 项目默认能处理的任务数”，这个问题，得先明确其使用的 web 容器。</p>
<p>那么问题又来了：SpringBoot 内置了哪些容器呢？</p>
<blockquote>
<p>Tomcat、Jetty、Netty、Undertow</p>
</blockquote>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716163334.png" alt="img"></p>
<p>前面我们都是基于 Tomcat 分析的，如果我们换一个容器呢？</p>
<p>比如换成 Undertow，这个玩意我只是听过，没有实际使用过，它对我来说就是一个黑盒。</p>
<p>管它的，先换了再说。</p>
<p>从 Tomcat 换成 Undertow，只需要修改 Maven 依赖即可，其他什么都不需要动：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716163620.png" alt="img"></p>
<p>再次启动项目，从日志可以发现已经修改为了 Undertow 容器：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716163826.png" alt="img"></p>
<p>此时我再次执行 MainTest 方法，还是提交 1000 个请求：</p>
<p><img src="https://s2.loli.net/2024/09/07/NUzx4mE1WL9dpou.png" alt="image-20240907205124756"></p>
<p>从日志来看，发现只有 48 个请求被处理了。</p>
<p>就很懵逼，48 是怎么回事儿，怎么都不是一个整数呢，这让强迫症很难受啊。</p>
<p>这个时候你的想法是什么，是不是想要看看 48 这个数字到底是从哪里来的？</p>
<p>怎么看？</p>
<p>之前找 Tomcat 的 200 的时候不是才教了你的嘛，直接往 Undertow 上套就行了嘛。</p>
<p>打线程 Dump，然后看堆栈消息：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716165004.png" alt="img"></p>
<p>发现 EnhancedQueueExecutor 这个线程池，接着在这个类里面去找构建线程池时的参数。</p>
<p>很容易就找到了这个构造方法：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716170419.png" alt="img"></p>
<p>所以，在这里打上断点，重启项目。</p>
<p>通过 Debug 可以知道，关键参数都是从 builder 里面来的。</p>
<p>而 builder 里面，coreSize 和 maxSize 都是 48，队列长度是 Integer.MAX_VALUE。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716170701.png" alt="img"></p>
<p>所以看一下 Builder 里面的 coreSize 是怎么来的。</p>
<p>点过来发现 coreSize 的默认值是 16：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716170808.png" alt="img"></p>
<p>不要慌，再打断点，再重启项目。</p>
<p>然后你会在它的 setCorePoolSize 方法处停下来，而这个方法的入参就是我们要找的 48：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716170937.png" alt="img"></p>
<p>顺藤摸瓜，重复几次打断点、重启的动作之后，你会找到 48 是一个名为 WORKER_TASK_CORE_THREADS 的变量，是从这里来的：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716171232.png" alt="img"></p>
<p>而 WORKER_TASK_CORE_THREADS 这个变量设置的地方是这样的：</p>
<blockquote>
<p>io.undertow.Undertow#start</p>
</blockquote>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716171424.png" alt="img"></p>
<p>而这里的 workerThreads 取值是这样的：</p>
<blockquote>
<p>io.undertow.Undertow.Builder#Builder</p>
</blockquote>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716171520.png" alt="img"></p>
<p>取的是机器的 CPU 个数乘以 8。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716171629.png" alt="img"></p>
<p>所以我这里是 6*8=48。</p>
<p>哦，真相大白，原来 48 是这样来的。</p>
<p>没意思。</p>
<p>确实没意思，但是既然都已经替换为 Undertow 了，那么你去研究一下它的 NIO ByteBuffer、NIO Channel、BufferPool、XNIO Worker、IO 线程池、Worker 线程池…</p>
<p>然后再和 Tomcat 对比着学，</p>
<p>就开始有点意思了。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/79/20230716180859.png" alt="img"></p>
<h2 id="最后再等等"><a href="#最后再等等" class="headerlink" title="最后再等等"></a><strong>最后再等等</strong></h2><p>这篇文章是基于“一个 SpringBoot 项目能同时处理多少请求？”这个面试题出发的。</p>
<p>但是经过我们前面简单的分析，你也知道，这个问题如果在没有加一些特定的前提条件的情况下，答案是各不一样的。</p>
<p>比如我再给你举一个例子，还是我们的 Demo，只是使用一下 @Async 注解，其他什么都不变：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20230716210625.png" alt="img"></p>
<p>再次启动项目，发起访问，日志输出变成了这样：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20230716212906.png" alt="img"></p>
<p>同时能处理的请求，直接从 Tomcat 的默认 200 个变成了 8 个？</p>
<p>因为 @Async 注解对应的线程池，默认的核心线程数是 8。</p>
<p>所以你看，稍微一变化，答案看起来又不一样了，同时这个请求在内部流转的过程也不一样了，又是一个可以铺开谈的点。</p>
<p>在面试过程中也是这样的，不要急于答题，当你觉得面试官问题描述的不清楚的地方，你可以先试探性的问一下，看看能不能挖掘出一点他没有说出来的默认条件。</p>
<p>当“默认条件”挖掘的越多，你的回答就会更容易被面试官接受。而这个挖掘的过程，也是面试过程中一个重要的表现环节。</p>
<p>而且，有时候，面试官就喜欢给出这样的“模糊”的问题，因为问题越模糊，坑就越多，当面试者跳进自己挖好的坑里面的时候，就是结束一次交锋的时候；当面试者看出来自己挖好的坑，并绕过去的时候，也是结束一轮交锋的时候。</p>
<p>所以，不要急于答题，多想，多问。不管是对于面试者还是面试官，一个好的面试体验，一定不是没有互动的一问一答，而是一个相互拉锯的过程。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>八股文</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql</title>
    <url>/2021/04/07/mysql/Mysql/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天不整那些花里胡哨、虚头巴脑的前言了，直接进入正题怼起来。</p>
<span id="more"></span>
<blockquote>
<p>常见的索引类型有哪些？</p>
</blockquote>
<p>常见的索引类型有：hash、b树、b+树。</p>
<p>hash：底层就是 hash 表。进行查找时，根据 key 调用hash 函数获得对应的 hashcode，根据 hashcode 找到对应的数据行地址，根据地址拿到对应的数据。</p>
<p>B树：B树是一种多路搜索树，n 路搜索树代表每个节点最多有 n 个子节点。每个节点存储 key + 指向下一层节点的指针+ 指向 key 数据记录的地址。查找时，从根结点向下进行查找，直到找到对应的key。</p>
<p>B+树：B+树是b树的变种，主要区别在于：B+树的非叶子节点只存储 key + 指向下一层节点的指针。另外，B+树的叶子节点之间通过指针来连接，构成一个有序链表，因此对整棵树的遍历只需要一次线性遍历叶子结点即可。</p>
<blockquote>
<p>为什么MySQL数据库要用B+树存储索引？而不用红黑树、Hash、B树？</p>
</blockquote>
<p>红黑树：如果在内存中，红黑树的查找效率比B树更高，但是涉及到磁盘操作，B树就更优了。因为红黑树是二叉树，数据量大时树的层数很高，从树的根结点向下寻找的过程，每读1个节点，都相当于一次IO操作，因此红黑树的I/O操作会比B树多的多。</p>
<p>hash 索引：如果只查询单个值的话，hash 索引的效率非常高。但是 hash 索引有几个问题：1）不支持范围查询；2）不支持索引值的排序操作；3）不支持联合索引的最左匹配规则。</p>
<p>B树索引：B树索相比于B+树，在进行范围查询时，需要做局部的中序遍历，可能要跨层访问，跨层访问代表着要进行额外的磁盘I/O操作；另外，B树的非叶子节点存放了数据记录的地址，会导致存放的节点更少，树的层数变高</p>
<blockquote>
<p>MySQL 中的索引叶子节点存放的是什么？</p>
</blockquote>
<p>MyISAM和InnoDB都是采用的B+树作为索引结构，但是叶子节点的存储上有些不同。</p>
<p>MyISAM：主键索引和辅助索引（普通索引）的叶子节点都是存放 key 和 key 对应数据行的地址。在MyISAM 中，主键索引和辅助索引没有任何区别。</p>
<p>InnoDB：主键索引存放的是 key 和 key 对应的数据行。辅助索引存放的是 key 和 key 对应的主键值。因此在使用辅助索引时，通常需要检索两次索引，首先检索辅助索引获得主键值，然后用主键值到主键索引中检索获得记录。</p>
<blockquote>
<p>什么是聚簇索引（聚集索引）？</p>
</blockquote>
<p>聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。聚簇索引将索引和数据行放到了一块，找到索引也就找到了数据。因为无需进行回表操作，所以效率很高。</p>
<p>InnoDB 中必然会有，且只会有一个聚簇索引。通常是主键，如果没有主键，则优先选择非空的唯一索引，如果唯一索引也没有，则会创建一个隐藏的row_id 作为聚簇索引。至于为啥会只有一个聚簇索引，其实很简单，因为我们的数据只会存储一份。</p>
<p>而非聚簇索引则将数据存储和索引分开，找到索引后，需要通过对应的地址找到对应的数据行。MyISAM 的索引方式就是非聚簇索引。</p>
<blockquote>
<p>什么是回表查询？</p>
</blockquote>
<p>InnoDB 中，对于主键索引，只需要走一遍主键索引的查询就能在叶子节点拿到数据。</p>
<p>而对于普通索引，叶子节点存储的是 key + 主键值，因此需要再走一次主键索引，通过主键索引找到行记录，这就是所谓的回表查询，先定位主键值，再定位行记录。</p>
<blockquote>
<p>走普通索引，一定会出现回表查询吗？</p>
</blockquote>
<p>不一定，如果查询语句所要求的字段全部命中了索引，那么就不必再进行回表查询。</p>
<p>很容易理解，有一个 user 表，主键为 id，name 为普通索引，则再执行：select id, name from user where name = ‘joonwhee’ 时，通过name 的索引就能拿到 id 和 name了，因此无需再回表去查数据行了。</p>
<blockquote>
<p>什么是覆盖索引（索引覆盖）吗？</p>
</blockquote>
<p>覆盖索引是 SQL-Server 中的一种说法，上面讲的例子其实就实现了覆盖索引。具体的：当索引上包含了查询语句中的所有列时，我们无需进行回表查询就能拿到所有的请求数据，因此速度会很快。</p>
<p>当explain的输出结果Extra字段为Using index时，则代表触发覆盖索引。以上面的例子为例：<br><img src="https://i.loli.net/2021/04/07/jglpJaW9k7oQSh1.png" alt="mysql1"></p>
<blockquote>
<p>联合索引（复合索引）的底层实现？最佳左前缀原则？</p>
</blockquote>
<p>联合索引底层还是使用B+树索引，并且还是只有一棵树，只是此时的排序会：首先按照第一个索引排序，在第一个索引相同的情况下，再按第二个索引排序，依次类推。</p>
<p>这也是为什么有“最佳左前缀原则”的原因，因为右边（后面）的索引都是在左边（前面）的索引排序的基础上进行排序的，如果没有左边的索引，单独看右边的索引，其实是无序的。</p>
<p>还是以字典为例，我们如果要查第2个字母为 k 的，通过目录是无法快速找的，因为首字母 A - Z 里面都可能包含第2个字母为 k 的。</p>
<p>联合索引的索引字段中有一个值为null，则将其放在叶子节点的最前面；可以认为null值是最小的。<br><img src="https://i.loli.net/2021/04/07/71NCPRvTEgWlIib.png" alt="mysql2"></p>
<blockquote>
<p>union 和 union all 的区别</p>
</blockquote>
<p>union all：对两个结果集直接进行并集操作，记录可能有重复，不会进行排序。</p>
<p>union：对两个结果集进行并集操作，会进行去重，记录不会重复，按字段的默认规则排序。</p>
<p>因此，从效率上说，UNION ALL 要比 UNION 更快。</p>
<blockquote>
<p>B+树中一个节点到底多大合适？</p>
</blockquote>
<p>1页或页的倍数最为合适。因为如果一个节点的大小小于1页，那么读取这个节点的时候其实也会读出1页，造成资源的浪费。所以为了不造成浪费，所以最后把一个节点的大小控制在1页、2页、3页等倍数页大小最为合适。</p>
<p>这里说的“页”是 MySQL 自定义的单位（和操作系统类似），MySQL 的 Innodb 引擎中1页的默认大小是16k，可以使用命令SHOW GLOBAL STATUS LIKE ‘Innodb_page_size’ 查看。<br><img src="https://i.loli.net/2021/04/07/JC3QLf28KgiUmV7.png" alt="mysql3"></p>
<blockquote>
<p>MySQL 中B+树的一个节点大小为多大呢？</p>
</blockquote>
<p>在 MySQL 中 B+ 树的一个节点大小为“1页”，也就是16k。</p>
<p>Innodb中，B+树中的一个节点存储的内容是：<br>非叶子节点：key + 指针<br>叶子节点：数据行（key 通常是数据的主键）</p>
<p>对于叶子节点：我们假设1行数据大小为1k（对于普通业务绝对够了），那么1页能存16条数据。</p>
<p>对于非叶子节点：key 使用 bigint 则为8字节，指针在 MySQL 中为6字节，一共是14字节，则16k能存放 16 * 1024 / 14 = 1170个。那么一颗高度为3的B+树能存储的数据为：1170 * 1170 * 16 = 21902400（千万级）。</p>
<p>所以在 InnoDB 中B+树高度一般为3层时，就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO，所以通过主键索引查询通常只需要1-3次 IO 操作即可查找到数据。千万级别对于一般的业务来说已经足够了，所以一个节点为1页，也就是16k是比较合理的。</p>
<blockquote>
<p>什么是 Buffer Pool？</p>
</blockquote>
<p>Buffer Pool 是 InnoDB 维护的一个缓存区域，用来缓存数据和索引在内存中，主要用来加速数据的读写，如果 Buffer Pool 越大，那么 MySQL 就越像一个内存数据库，默认大小为 128M。</p>
<p>InnoDB 会将那些热点数据和一些 InnoDB 认为即将访问到的数据存在 Buffer Pool 中，以提升数据的读取性能。</p>
<p>InnoDB 在修改数据时，如果数据的页在 Buffer Pool 中，则会直接修改 Buffer Pool，此时我们称这个页为脏页，InnoDB 会以一定的频率将脏页刷新到磁盘，这样可以尽量减少磁盘I/O，提升性能。</p>
<blockquote>
<p>InnoDB 四大特性</p>
</blockquote>
<p>插入缓冲（insert buffer）：<br>索引是存储在磁盘上的，所以对于索引的操作需要涉及磁盘操作。如果我们使用自增主键，那么在插入主键索引（聚簇索引）时，只需不断追加即可，不需要磁盘的随机 I/O。但是如果我们使用的是普通索引，大概率是无序的，此时就涉及到磁盘的随机 I/O，而随机I/O的性能是比较差的（Kafka 官方数据：磁盘顺序I/O的性能是磁盘随机I/O的4000~5000倍）。</p>
<p>因此，InnoDB 存储引擎设计了 Insert Buffer ，对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池（Buffer pool）中，若在，则直接插入；若不在，则先放入到一个 Insert Buffer 对象中，然后再以一定的频率和情况进行 Insert Buffer 和辅助索引页子节点的 merge（合并）操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中），这就大大提高了对于非聚集索引插入的性能。</p>
<p>插入缓冲的使用需要满足以下两个条件：1）索引是辅助索引；2）索引不是唯一的。</p>
<p>二次写（double write）：<br>脏页刷盘风险：InnoDB 的 page size一般是16KB，操作系统写文件是以4KB作为单位，那么每写一个 InnoDB 的 page 到磁盘上，操作系统需要写4个块。于是可能出现16K的数据，写入4K 时，发生了系统断电或系统崩溃，只有一部分写是成功的，这就是 partial page write（部分页写入）问题。这时会出现数据不完整的问题。</p>
<p>这时是无法通过 redo log 恢复的，因为 redo log 记录的是对页的物理修改，如果页本身已经损坏，重做日志也无能为力。</p>
<p>doublewrite 就是用来解决该问题的。doublewrite 由两部分组成，一部分为内存中的 doublewrite buffer，其大小为2MB，另一部分是磁盘上共享表空间中连续的128个页，即2个区(extent)，大小也是2M。</p>
<p>为了解决 partial page write 问题，当 MySQL 将脏数据刷新到磁盘的时候，会进行以下操作：</p>
<p>1）先将脏数据复制到内存中的 doublewrite buffer</p>
<p>2）之后通过 doublewrite buffer 再分2次，每次1MB写入到共享表空间的磁盘上（顺序写，性能很高）</p>
<p>3）完成第二步之后，马上调用 fsync 函数，将doublewrite buffer中的脏页数据写入实际的各个表空间文件（离散写）。</p>
<p>如果操作系统在将页写入磁盘的过程中发生崩溃，InnoDB 再次启动后，发现了一个 page 数据已经损坏，InnoDB 存储引擎可以从共享表空间的 doublewrite 中找到该页的一个最近的副本，用于进行数据恢复了。</p>
<p>自适应哈希索引(adaptive hash index):<br>哈希（hash）是一种非常快的查找方法，一般情况下查找的时间复杂度为 O(1)。但是由于不支持范围查询等条件的限制，InnoDB 并没有采用 hash 索引，但是如果能在一些特殊场景下使用 hash 索引，则可能是一个不错的补充，而 InnoDB 正是这么做的。</p>
<p>具体的，InnoDB 会监控对表上索引的查找，如果观察到某些索引被频繁访问，索引成为热数据，建立哈希索引可以带来速度的提升，则建立哈希索引，所以称之为自适应（adaptive）的。自适应哈希索引通过缓冲池的 B+ 树构造而来，因此建立的速度很快。而且不需要将整个表都建哈希索引，InnoDB 会自动根据访问的频率和模式来为某些页建立哈希索引。</p>
<p>预读（read ahead）：<br>InnoDB 在 I/O 的优化上有个比较重要的特性为预读，当 InnoDB 预计某些 page 可能很快就会需要用到时，它会异步地将这些 page 提前读取到缓冲池（buffer pool）中，这其实有点像空间局部性的概念。</p>
<p>空间局部性（spatial locality）：如果一个数据项被访问，那么与他地址相邻的数据项也可能很快被访问。</p>
<p>InnoDB使用两种预读算法来提高I/O性能：线性预读（linear read-ahead）和随机预读（randomread-ahead）。</p>
<p>其中，线性预读以 extent（块，1个 extent 等于64个 page）为单位，而随机预读放到以 extent 中的 page 为单位。线性预读着眼于将下一个extent 提前读取到 buffer pool 中，而随机预读着眼于将当前 extent 中的剩余的 page 提前读取到 buffer pool 中。</p>
<p>线性预读（Linear read-ahead）：线性预读方式有一个很重要的变量 innodb_read_ahead_threshold，可以控制 Innodb 执行预读操作的触发阈值。如果一个 extent 中的被顺序读取的 page 超过或者等于该参数变量时，Innodb将会异步的将下一个 extent 读取到 buffer pool中，innodb_read_ahead_threshold 可以设置为0-64（一个 extend 上限就是64页）的任何值，默认值为56，值越高，访问模式检查越严格。<br> <br>随机预读（Random read-ahead）: 随机预读方式则是表示当同一个 extent 中的一些 page 在 buffer pool 中发现时，Innodb 会将该 extent 中的剩余 page 一并读到 buffer pool中，由于随机预读方式给 Innodb code 带来了一些不必要的复杂性，同时在性能也存在不稳定性，在5.5中已经将这种预读方式废弃。要启用此功能，请将配置变量设置 innodb_random_read_ahead 为ON</p>
<blockquote>
<p>共享锁和排他锁？</p>
</blockquote>
<p>共享锁又称为读锁，简称S锁，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。<br> <br>排他锁又称为写锁，简称X锁，顾名思义，排他锁就是不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务可以对数据就行读取和修改。</p>
<p>常见的几种 SQL 语句的加锁情况如下：</p>
<p>select * from table：不加锁</p>
<p>update/insert/delete：排他锁</p>
<p>select * from table where id = 1 for update：id为索引，加排他锁</p>
<p>select * from table where id = 1 lock in share mode：id为索引，加共享锁</p>
<blockquote>
<p>数据库的行锁和表锁</p>
</blockquote>
<p>行锁：操作时只锁某一（些）行，不对其它行有影响。开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高。</p>
<p>表锁：即使操作一条记录也会锁住整个表。开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突概率高，并发度最低。</p>
<p>页锁：操作时锁住一页数据（16kb）。开销和加锁速度介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和行锁之间，并发度一般。</p>
<p>InnoDB 有行锁和表锁，MyIsam 只有表锁。</p>
<blockquote>
<p>InnoDB 的行锁是怎么实现的？</p>
</blockquote>
<p>InnoDB 行锁是通过索引上的索引项来实现的。意味者：只有通过索引条件检索数据，InnoDB 才会使用行级锁，否则，InnoDB将使用表锁！</p>
<p>对于主键索引：直接锁住锁住主键索引即可。</p>
<p>对于普通索引：先锁住普通索引，接着锁住主键索引，这是因为一张表的索引可能存在多个，通过主键索引才能确保锁是唯一的，不然如果同时有2个事务对同1条数据的不同索引分别加锁，那就可能存在2个事务同时操作一条数据了。</p>
<blockquote>
<p>InnoDB 锁的算法有哪几种？</p>
</blockquote>
<p>Record lock：记录锁，单条索引记录上加锁，锁住的永远是索引，而非记录本身。</p>
<p>Gap lock：间隙锁，在索引记录之间的间隙中加锁，或者是在某一条索引记录之前或者之后加锁，并不包括该索引记录本身。</p>
<p>Next-key lock：Record lock 和 Gap lock 的结合，即除了锁住记录本身，也锁住索引之间的间隙。</p>
<blockquote>
<p>MySQL 如何实现悲观锁和乐观锁？</p>
</blockquote>
<p>乐观锁：更新时带上版本号（cas更新）</p>
<p>悲观锁：使用共享锁和排它锁，select…lock in share mode，select…for update。</p>
<blockquote>
<p>存储引擎的选择？</p>
</blockquote>
<p>没有特殊情况，使用 InnoDB 即可。如果表中绝大多数都只是读查询，可以考虑 MyISAM</p>
<blockquote>
<p>如何做慢 SQL 优化？</p>
</blockquote>
<p>首先要搞明白慢的原因是什么：是查询条件没有命中索引？还是 load 了不需要的数据列？还是数据量太大？所以优化也是针对这三个方向来的。</p>
<p>首先用 explain 分析语句的执行计划，查看使用索引的情况，是不是查询没走索引，如果可以加索引解决，优先采用加索引解决。</p>
<p>分析语句，看看是否存在一些导致索引失效的用法，是否 load 了额外的数据，是否加载了许多结果中并不需要的列，对语句进行分析以及重写。</p>
<p>如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行垂直拆分或者水平拆分。</p>
<blockquote>
<p>说说 MySQL 的主从复制？</p>
</blockquote>
<p>MySQL主从复制涉及到三个线程，一个运行在主节点（Log Dump Thread），其余两个（I/O Thread，SQL Thread）运行在从节点，如下图所示<br><img src="https://i.loli.net/2021/04/07/2RsFWgJEc1qIXMt.jpg" alt="mysql4"></p>
<p>主从复制默认是异步的模式，具体过程如下。</p>
<p>1）从节点上的I/O 线程连接主节点，并请求从指定日志文件（bin log file）的指定位置（bin log position，或者从最开始的日志）之后的日志内容；</p>
<p>2）主节点接收到来自从节点的 I/O请求后，读取指定文件的指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的 bin-log file 以及 bin-log position；从节点的 I/O 进程接收到内容后，将接收到的日志内容更新到 relay log 中，并将读取到的 bin log file（文件名）和position（位置）保存到 master-info 文件中，以便在下一次读取的时候能够清楚的告诉 Master “我需要从某个bin-log 的哪个位置开始往后的日志内容”；</p>
<p>3）从节点的 SQL 线程检测到 relay-log 中新增加了内容后，会解析 relay-log 的内容，并在本数据库中执行。</p>
<blockquote>
<p>异步复制，主库宕机后，数据可能丢失？</p>
</blockquote>
<p>可以使用半同步复制或全同步复制。</p>
<p>半同步复制：</p>
<p>修改语句写入bin log后，不会立即给客户端返回结果。而是首先通过log dump 线程将 binlog 发送给从节点，从节点的 I/O 线程收到 binlog 后，写入到 relay log，然后返回 ACK 给主节点，主节点 收到 ACK 后，再返回给客户端成功。<br><img src="https://i.loli.net/2021/04/07/BtCMYiDuhXUSyGx.jpg" alt="mysql5"></p>
<p>半同步复制的特点：</p>
<p>确保事务提交后 binlog 至少传输到一个从库</p>
<p>不保证从库应用完这个事务的 binlog</p>
<p>性能有一定的降低，响应时间会更长</p>
<p>网络异常或从库宕机，卡主主库，直到超时或从库恢复</p>
<p>全同步复制：主节点和所有从节点全部执行了该事务并确认才会向客户端返回成功。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。</p>
<blockquote>
<p>主库写压力大，从库复制很可能出现延迟？</p>
</blockquote>
<p>可以使用并行复制（并行是指从库多个SQL线程并行执行 relay log），解决从库复制延迟的问题。</p>
<p>MySQL 5.7 中引入基于组提交的并行复制，其核心思想：一个组提交的事务都是可以并行回放，因为这些事务都已进入到事务的 prepare 阶段，则说明事务之间没有任何冲突（否则就不可能提交）。</p>
<p>判断事务是否处于一个组是通过 last_committed 变量，last_committed 表示事务提交的时候，上次事务提交的编号，如果事务具有相同的 last_committed，则表示这些事务都在一组内，可以进行并行的回放。</p>
<blockquote>
<p>MySQL 的事务隔离级别有哪些？分别用于解决什么问题？</p>
</blockquote>
<p>主要用于解决脏读、不可重复读、幻读。</p>
<p>脏读：一个事务读取到另一个事务还未提交的数据。</p>
<p>不可重复读：在一个事务中多次读取同一个数据时，结果出现不一致。</p>
<p>幻读：在一个事务中使用相同的 SQL 两次读取，第二次读取到了其他事务新插入的行。</p>
<p>不可重复读注重于数据的修改，而幻读注重于数据的插入。<br><img src="https://i.loli.net/2021/04/07/SiyrkGcJj2ZChFa.png" alt="mysql5"></p>
<blockquote>
<p>MySQL 的可重复读怎么实现的？</p>
</blockquote>
<p>使用 MVCC 实现的，即 Mutil-Version Concurrency Control，多版本并发控制。关于 MVCC，比较常见的说法如下，包括《高性能 MySQL》也是这么介绍的。</p>
<p>InnoDB 在每行记录后面保存两个隐藏的列，分别保存了数据行的创建版本号和删除版本号。每开始一个新的事务，系统版本号都会递增。事务开始时刻的版本号会作为事务的版本号，用来和查询到的每行记录的版本号对比。在可重复读级别下，MVCC是如何操作的：</p>
<p>SELECT：必须同时满足以下两个条件，才能查询到。1）只查版本号早于当前版本的数据行；2）行的删除版本要么未定义，要么大于当前事务版本号。</p>
<p>INSERT：为插入的每一行保存当前系统版本号作为创建版本号。</p>
<p>DELETE：为删除的每一行保存当前系统版本号作为删除版本号。</p>
<p>UPDATE：插入一条新数据，保存当前系统版本号作为创建版本号。同时保存当前系统版本号作为原来的数据行删除版本号。</p>
<p>MVCC 只作用于 RC（Read Committed）和 RR（Repeatable Read）级别，因为 RU（Read Uncommitted）总是读取最新的数据版本，而不是符合当前事务版本的数据行。而 Serializable 则会对所有读取的行都加锁。这两种级别都不需要 MVCC 的帮助。</p>
<p>实际上，InnoDB 会在每行记录后面增加三个隐藏字段：</p>
<p>DB_ROW_ID：行ID，随着插入新行而单调递增，如果有主键，则不会包含该列。</p>
<p>DB_TRX_ID：记录插入或更新该行的事务的事务ID。</p>
<p>DB_ROLL_PTR：回滚指针，指向 undo log 记录。每次对某条记录进行改动时，该列会存一个指针，可以通过这个指针找到该记录修改前的信息 。当某条记录被多次修改时，该行记录会存在多个版本，通过DB_ROLL_PTR 链接形成一个类似版本链的概念。<br><img src="https://i.loli.net/2021/04/07/njgr1FOEfkw5A9e.png" alt="mysql6"></p>
<p>接下来进入正题，以 RR 级别为例：每开启一个事务时，系统会给该事务会分配一个事务 Id，在该事务执行第一个 select 语句的时候，会生成一个当前时间点的事务快照 ReadView，主要包含以下几个属性：</p>
<p>trx_ids：生成 ReadView 时当前系统中活跃的事务 Id 列表，就是还未执行事务提交的。</p>
<p>up_limit_id：低水位，取 trx_ids 中最小的那个，trx_id 小于该值都能看到。</p>
<p>low_limit_id：高水位，生成 ReadView 时系统将要分配给下一个事务的id值，trx_id 大于等于该值都不能看到。</p>
<p>creator_trx_id：生成该 ReadView 的事务的事务 Id。</p>
<p>有了这个ReadView，这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见：</p>
<p>1）如果被访问版本的trx_id与ReadView中的creator_trx_id值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。</p>
<p>2）如果被访问版本的trx_id小于ReadView中的up_limit_id值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。</p>
<p>3）如果被访问版本的trx_id大于ReadView中的low_limit_id值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。</p>
<p>4）如果被访问版本的trx_id属性值在ReadView的up_limit_id和low_limit_id之间，那就需要判断一下trx_id属性值是不是在trx_ids列表中。如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。</p>
<p>在进行判断时，首先会拿记录的最新版本来比较，如果该版本无法被当前事务看到，则通过记录的 DB_ROLL_PTR 找到上一个版本，重新进行比较，直到找到一个能被当前事务看到的版本。</p>
<p>而对于删除，其实就是一种特殊的更新，InnoDB 用一个额外的标记位 delete_bit 标识是否删除。当我们在进行判断时，会检查下 delete_bit 是否被标记，如果是，则跳过该版本，通过 DB_ROLL_PTR 拿到下一个版本进行判断。</p>
<p>以上内容是对于 RR 级别来说，而对于 RC 级别，其实整个过程几乎一样，唯一不同的是生成 ReadView 的时机，RR 级别只在事务开始时生成一次，之后一直使用该 ReadView。而 RC 级别则在每次 select 时，都会生成一个 ReadView。</p>
<blockquote>
<p>那 MVCC 解决了幻读了没有？</p>
</blockquote>
<p>对于快照读，MVCC 因为因为从 ReadView 读取，所以必然不会看到新插入的行，所以天然就解决了幻读的问题。</p>
<p>而对于当前读的幻读，MVCC 是无法解决的。需要使用 Gap Lock 或 Next-Key Lock（Gap Lock + Record Lock）来解决。</p>
<p>其实原理也很简单，用上面的例子稍微修改下以触发当前读：select * from user where id &lt; 10 for update，当使用了 Gap Lock 时，Gap 锁会锁住 id &lt; 10 的整个范围，因此其他事务无法插入 id &lt; 10 的数据，从而防止了幻读。</p>
<blockquote>
<p>那经常有人说 Repeatable Read 解决了幻读是什么情况？</p>
</blockquote>
<p>SQL 标准中规定的 RR 并不能消除幻读，但是 MySQL 的 RR 可以，靠的就是 Gap 锁。在 RR 级别下，Gap 锁是默认开启的，而在 RC 级别下，Gap 锁是关闭的。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>来啊，分页啊</title>
    <url>/2024/09/07/mysql/%E6%9D%A5%E5%95%8A%EF%BC%8C%E5%88%86%E9%A1%B5%E5%95%8A/</url>
    <content><![CDATA[<p>前段时间踩到一个比较无语的生产 BUG，严格来说其实也不能算是 BUG，只能说开发同事对于业务同事的需求理解没有到位。</p>
<p>这个 BUG 其实和分页没有任何关系，但是当我去排查问题的时候，我看了一眼 SQL ，大概是这样的：</p>
<blockquote>
<p>select * from table order by priority limit 1;</p>
</blockquote>
<p>priority，就是优先级的意思。</p>
<p>按照优先级 order by 然后 limit 取优先级最高（数字越小，优先级越高）的第一条 ，结合业务背景和数据库里面的数据，我立马就意识到了问题所在。</p>
<p>想起了我当年在写分页逻辑的时候，虽然场景和这个完全不一样，但是踩过到底层原理一模一样的坑，这玩意印象深刻，所以立马就识别出来了。</p>
<p>借着这个问题，也盘点一下我遇到过的三个关于分页查询有意思的坑。</p>
<h2 id="职业生涯的第一个生产-BUG"><a href="#职业生涯的第一个生产-BUG" class="headerlink" title="职业生涯的第一个生产 BUG"></a>职业生涯的第一个生产 BUG</h2><p>职业生涯的第一个生产 BUG 就是一个小小的分页查询。</p>
<p>当时还在做支付系统，接手的一个需求也很简单就是做一个定时任务，定时把数据库里面状态为初始化的订单查询出来，调用另一个服务提供的接口查询订单的状态并更新。</p>
<p>由于流程上有数据强校验，不用考虑数据不存在的情况。所以该接口可能返回的状态只有三种：成功，失败，处理中。</p>
<p>很简单，很常规的一个需求对吧，我分分钟就能写出伪代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//获取订单状态为初始化的数据(0:初始化 1:处理中 2:成功 3:失败)</span></span><br><span class="line"><span class="comment">//select * from order where order_status=0;</span></span><br><span class="line"><span class="type">ArrayList</span> <span class="variable">initOrderInfoList</span> <span class="operator">=</span> queryInitOrderInfoList();</span><br><span class="line"><span class="comment">//循环处理这批数据</span></span><br><span class="line"><span class="keyword">for</span>(OrderInfo orderInfo : initOrderInfoList)&#123;</span><br><span class="line">    <span class="comment">//捕获异常以免一条数据错误导致循环结束</span></span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        <span class="comment">//发起rpc调用</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">orderStatus</span> <span class="operator">=</span> queryOrderStatus(orderInfo.getOrderId);</span><br><span class="line">        <span class="comment">//更新订单状态</span></span><br><span class="line">        updateOrderInfo(orderInfo.getOrderId,orderStatus);    </span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">        <span class="comment">//打印异常</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>来，你说上面这个程序有什么问题？</p>
<p><img src="https://s2.loli.net/2024/09/07/U5k2Vz3DOIJyhvs.png" alt="3554b7005e5beb8318661912d874b4c4.png"></p>
<p>其实在绝大部分情况下都没啥大问题，数据量不多的情况下程序跑起来没有任何毛病。</p>
<p>但是，如果数据量多起来了，一次性把所有初始化状态的订单都拿出来，是不是有点不合理了，万一把内存给你撑爆了怎么办？</p>
<p>所以，在我已知数据量会很大的情况下，我采取了分批次获取数据的模式，假设一次性取 100 条数据出来玩。</p>
<p>那么 SQL 就是这样的：</p>
<p>select * from order where order_status=0 order by create_time limit 100;</p>
<p>所以上面的伪代码会变成这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">    <span class="comment">//获取订单状态为初始化的数据(0:初始化 1:处理中 2:成功 3:失败)</span></span><br><span class="line">    <span class="comment">//select * from order where order_status=0 order by create_time limit 100;</span></span><br><span class="line">    <span class="type">ArrayList</span> <span class="variable">initOrderInfoList</span> <span class="operator">=</span> queryInitOrderInfoList();</span><br><span class="line">    <span class="comment">//循环处理这批数据</span></span><br><span class="line">    <span class="keyword">for</span>(OrderInfo orderInfo : initOrderInfoList)&#123;</span><br><span class="line">        <span class="comment">//捕获异常以免一条数据错误导致循环结束</span></span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">//发起rpc调用</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">orderStatus</span> <span class="operator">=</span> queryOrderStatus(orderInfo.getOrderId);</span><br><span class="line">            <span class="comment">//更新订单状态</span></span><br><span class="line">            updateOrderInfo(orderInfo.getOrderId,orderStatus);    </span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            <span class="comment">//打印异常</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>来，你又来告诉我上面这一段逻辑有什么问题？</p>
<p><img src="https://s2.loli.net/2024/09/07/xYMkIG7nNe3zVUD.png" alt="19a79b96894403661988ac3cc9b0165e.png"></p>
<p>作为程序员，我们看到 while(true) 这样的写法立马就要警报拉满，看看有没有死循环的风险。</p>
<p>那你说上面这段代码在什么时候退不出来？</p>
<p>当有任何一条数据的状态没有从初始化变成成功、失败或者处理中的时候，就会导致一直循环。</p>
<p>而虽然发起 RPC 调用的地方，服务提供方能确保返回的状态一定是成功、失败、处理中这三者之中的一个，但是这个有一个前提是接口调用正常的情况下。</p>
<p>如果接口调用一旦异常，那么按照上面的写法，在抛出异常后，状态并未发生变化，还会是停留在“初始化”，从而导致死循环。</p>
<p>当年，测试同学在测试阶段直接就测出了这个问题，然后我对其进行了修改。</p>
<p>我改变了思路，把每次分批次查询 100 条数据，修改为了分页查询，引入了 PageHelper 插件：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//是否是最后一页</span></span><br><span class="line"><span class="keyword">while</span>(pageInfo.isLastPage)&#123;</span><br><span class="line">    pageNum=pageNum+<span class="number">1</span>;</span><br><span class="line">    <span class="comment">//获取订单状态为初始化的数据(0:初始化 1:处理中 2:成功 3:失败)</span></span><br><span class="line">    <span class="comment">//select * from order where order_status=0 order by create_time limit pageNum*100,100;</span></span><br><span class="line">    PageHelper.startPage(pageNum,<span class="number">100</span>);</span><br><span class="line">    <span class="type">ArrayList</span> <span class="variable">initOrderInfoList</span> <span class="operator">=</span> queryInitOrderInfoList();</span><br><span class="line">    pageInfo = <span class="keyword">new</span> <span class="title class_">PageInfo</span>(initOrderInfoList);</span><br><span class="line">    <span class="comment">//循环处理这批数据</span></span><br><span class="line">    <span class="keyword">for</span>(OrderInfo orderInfo : initOrderInfoList)&#123;</span><br><span class="line">        <span class="comment">//捕获异常以免一条数据错误导致循环结束</span></span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">//发起rpc调用</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">orderStatus</span> <span class="operator">=</span> queryOrderStatus(orderInfo.getOrderId);</span><br><span class="line">            <span class="comment">//更新订单状态</span></span><br><span class="line">            updateOrderInfo(orderInfo.getOrderId,orderStatus);    </span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            <span class="comment">//打印异常</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>跳出循环的条件为判断当前页是否是最后一页。</p>
<p>由于每循环一次，当前页就加一，那么理论上讲一定会是翻到最后一页的，没有任何毛病，对不对？</p>
<p>我们可以分析一下上面的代码逻辑。</p>
<p>假设，我们有 120 条 order_status=0 的数据。</p>
<p>那么第一页，取出了 100 条数据：</p>
<blockquote>
<p>SELECT * from order_info WHERE order_status=0 LIMIT 0,100;</p>
</blockquote>
<p>这 100 条处理完成之后，第二页还有数据吗？</p>
<p>第二页对应的 sql 为：</p>
<blockquote>
<p>SELECT * from order_info WHERE order_status=0 LIMIT 100,100;</p>
</blockquote>
<p>但是这个时候，状态为 0 的数据，只有 20 条了，而分页要从第 100 条开始，是不是获取不到数据，导致遗漏数据了？</p>
<p>确实一定会翻到最后一页，解决了死循环的问题，但又有大量的数据遗漏怎么办呢？</p>
<p><img src="https://s2.loli.net/2024/09/07/qLim248NEdbJDyF.png" alt="b8403afbd878e718ff318ac80bf80774.png"></p>
<p>当时我苦思冥想，想到一个办法：导致数据遗漏的原因是因为我在翻页的时候，数据状态在变化，导致总体数据在变化。</p>
<p>那么如果我每次都从后往前取数据，每次都固定取最后一页，能取到数据就代表还有数据要处理，循环结束条件修改为“当前页即是第一页，也是最后一页时”就结束，这样不就不会遗漏数据了？</p>
<p>我再给你分析一下。</p>
<p>假设，我们有 120 条 order_status=0 的数据，从后往前取了 100 天出来进行出来，有 90 条处理成功，10 条的状态还是停留在“处理中”。</p>
<p>第二次再取的时候，会把剩下的 20 条和这次“处理中”的 10 条，共计 30 条再次取出来进行处理。</p>
<p>确保没有数据遗漏。</p>
<p>后来测试环节验收通过了，这个方案上线之后，也确实没有遗漏过数据了。</p>
<p>直到后来又一天，提供 queryOrderStatus 接口的服务异常了，我发过去的请求超时了。</p>
<p>导致我取出来的数据，每一条都会抛出异常，都不会更新状态。从而导致我每次从后往前取数据，都取到的是同一批数据。</p>
<p>从程序上的表现上看，日志疯狂的打印，但是其实一直在处理同一批，就是死循环了。</p>
<p>好在我当时还在新手保护期，领导帮我扛下来了。</p>
<p>最后随着业务的发展，这块逻辑也完全发生了变化，逻辑由我们主动去调用 RPC 接口查询状态变成了，下游状态变化后进行 MQ 主动通知，所以我这一坨骚代码也就随之光荣下岗。</p>
<p>我现在想了一下，其实这个场景，用分页的思想去取数据真的不好做。</p>
<p>还不如用最开始的分批次的思想，只不过在会变化的“状态”之外，再加上另外一个不会改变的限定条件，比如常见的创建时间：</p>
<blockquote>
<p>select * from order where order_status=0 and create_time&gt;xxx order by create_time limit 100;</p>
</blockquote>
<p>最好不要基于状态去做分页，如果一定要基于状态去做分页，那么要确保状态在分页逻辑里面会扭转下去。</p>
<p>这就是我职业生涯的第一个生产 BUG，一个低级的分页逻辑错误。</p>
<h2 id="还是分页，又踩到坑"><a href="#还是分页，又踩到坑" class="headerlink" title="还是分页，又踩到坑"></a>还是分页，又踩到坑</h2><p>这也是在工作的前两年遇到的一个关于分页的坑。</p>
<p>最开始在学校的时候，大家肯定都手撸过分页逻辑，自己去算总页数，当前页，页面大小啥的。</p>
<p>当时功力尚浅，觉得这部分逻辑写起来是真复杂，但是扣扣脑袋也还是可以写出来。</p>
<p>后来参加工作了之后，在项目里面看到了 PageHelper 这个玩意，了解之后发了“斯国一”的惊叹：有了这玩意，谁还手写分页啊。</p>
<p><img src="https://s2.loli.net/2024/09/07/c7Q9jVrTCs5MNAX.png" alt="fc2d639d2ab7ed6589fcf15aa3bcb2ee.png"></p>
<p>但是我在使用 PageHelper 的时候，也踩到过一个经典的“坑”。</p>
<p>最开始的时候，代码是这样的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PageHelper.startPage(pageNum,<span class="number">100</span>);</span><br><span class="line">List&lt;OrderInfo&gt; list = orderInfoMapper.select(param1);</span><br><span class="line">后来为了避免不带 where 条件的全表查询，我把代码修改成了这样：</span><br><span class="line"></span><br><span class="line">PageHelper.startPage(pageNum,<span class="number">100</span>);</span><br><span class="line"><span class="keyword">if</span>(param != <span class="literal">null</span>)&#123;</span><br><span class="line">    List&lt;OrderInfo&gt; list = orderInfoMapper.select(param);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后，随着程序的迭代，就出 BUG 了。因为有的业务场景下，param 参数一路传递进来之后就变成了 null。</p>
<p>但是这个时候 PageHelper 已经在当前线程的 ThreadLocal 里面设置了分页参数了，但是没有被消费，这个参数就会一直保留在这个线程上，也就是放在线程的 ThreadLocal 里面。</p>
<p>当这个线程继续往后跑，或者被复用的时候，遇到一条 SQL 语句时，就可能导致不该分页的方法去消费这个分页参数，产生了莫名其妙的分页。</p>
<p>所以，上面这个代码，应该写成下面这个样子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(param != <span class="literal">null</span>)&#123;</span><br><span class="line">    PageHelper.startPage(pageNum,<span class="number">100</span>);</span><br><span class="line">    List&lt;OrderInfo&gt; list = orderInfoMapper.select(param);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>也是这次踩坑之后，我翻阅了 PageHelper 的源码，了解了底层原理，并总结了一句话：需要保证在 PageHelper 方法调用后紧跟 MyBatis 查询方法，否则会污染线程。</p>
<p>在正确使用 PageHelper 的情况下，其插件内部，会在 finally 代码段中自动清除了在 ThreadLocal 中存储的对象。</p>
<p>这样就不会留坑。</p>
<p>这次翻页源码的过程影响也是比较深刻的，虽然那个时候经验不多，但是得益于 MyBatis 的源码和 PageHelper 的源码写的都非常的符合正常人的思维，阅读起来门槛不高，再加上我有具体的疑问，所以那是一次古早时期，尚在新手村时，为数不多的，阅读源码之后，感觉收获满满的经历。</p>
<h2 id="分页丢数据"><a href="#分页丢数据" class="headerlink" title="分页丢数据"></a>分页丢数据</h2><p>关于这个 BUG 可以说是印象深刻了。</p>
<p>当年遇到这个坑的时候排查了很长时间没啥头绪，最后还是组里的大佬指了条路。</p>
<p>业务需求很简单，就是在管理页面上可以查询订单列表，查询结果按照订单的创建时间倒序排序。</p>
<p>对应的分页 SQL 很简单，很常规，没有任何问题：</p>
<blockquote>
<p>select * from table order by create_time desc limit 0,10;</p>
</blockquote>
<p>但是当年在页面上的表现大概是这样的：</p>
<p><img src="https://s2.loli.net/2024/09/07/klutvw35YPyLn7H.png" alt="68450750f60bb606e3367ea0a9a9cf7d.png"></p>
<p>订单编号为 5 的这条数据，会同时出现在了第一页和第二页。</p>
<p>甚至有的数据在第二页出现了之后，在第五页又出现一次。</p>
<p>后来定位到产生这个问题的原因是因为有一批数量不小的订单数据是通过线下执行 SQL 的方式导入的。</p>
<p>而导入的这一批数据，写 SQL 的同学为了方便，就把 create_time 都设置为了同一个值，比如都设置为了 2023-09-10 12:34:56 这个时间。</p>
<p>由于 create_time 又是我作为 order by 的字段，当这个字段的值大量都是同一个值的时候，就会导致上面的一条数据在不同的页面上多次出现的情况。</p>
<p>针对这个现象，当时组里的大佬分析明白之后，扔给我一个链接：</p>
<blockquote>
<p>tps://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html</p>
</blockquote>
<p>这是 MySQL 官方文档，这一章节叫做“对 Limit 查询的优化”。</p>
<p>开篇的时候人家就是这样说的：</p>
<p><img src="https://s2.loli.net/2024/09/07/DqnUfNQEZsgcka1.png" alt="1d097f852416aada73d2d8cc8977175a.png"></p>
<p>如果将 LIMIT row_count 和 ORDER BY 组合在一起，那么 MySQL 在找到排序结果的第一行 count 行时就停止排序，而不是对整个结果进行排序。</p>
<p>然后给了这一段补充说明：</p>
<p><img src="https://s2.loli.net/2024/09/07/t4jy1pCUPQX6FYn.png" alt="0e4d174aa81fa64dae80186235c193b8.png"></p>
<p>如果多条记录的 ORDER BY 列中有相同的值，服务器可以自由地按任何顺序返回这些记录，并可能根据整体执行计划的不同而采取不同的方式。</p>
<p>换句话说，相对于未排序列，这些记录的排序顺序是 nondeterministic 的：</p>
<p><img src="https://s2.loli.net/2024/09/07/Q6VxDXU5YnhGELJ.png" alt="75168cf00066e77f6bf69b2bc5beba8c.png"></p>
<p>然后官方给了一个示例。</p>
<p>首先，不带 limit 的时候查询结果是这样的：</p>
<p><img src="https://s2.loli.net/2024/09/07/p3mI5tvMJEdskS4.png" alt="146ac942069c1b688ae88e7a46430098.png"></p>
<p>基于这个结果，如果我要取前五条数据，对应的 id 应该是 1,5,3,4,6。</p>
<p>但是当我们带着 limit 的时候查询结果可能是这样的：</p>
<p><img src="https://s2.loli.net/2024/09/07/bWrjN69BqMcESmA.png" alt="6f119329722d3eb8ef823293df548f3d.png"></p>
<p>对应的 id 实际是 1,5,4,3,6。</p>
<p>这就是前面说的：如果多条记录的 ORDER BY 列中有相同的值，服务器可以自由地按任何顺序返回这些记录，并可能根据整体执行计划的不同而采取不同的方式。</p>
<p>从程序上的表现上来看，结果就是 nondeterministic。</p>
<p>所以看到这里，我们大概可以知道我前面遇到的分页问题的原因是因为那一批手动插入的数据对应的 create_time 字段都是一样的，而 MySQL 这边又对 Limit 参数做了优化，运行结果出现了不确定性，从而页面上出现了重复的数据。</p>
<p>而回到文章最开始的这个 SQL，也就是我一眼看出问题的这个 SQL：</p>
<blockquote>
<p>select * from table order by priority limit 1;</p>
</blockquote>
<p>因为在我们的界面上，只是约定了数字越小优先级越高，数字必须大于 0。</p>
<p>所以当大家在输入优先级的时候，大部分情况下都默认自己编辑的数据对应的优先级最高，也就是设置为 1，从而导致数据库里面有大量的优先级为 1 的数据。</p>
<p>而程序每次处理，又只会按照优先级排序只会，取一条数据出来进行处理。</p>
<p>经过前面的分析我们可以知道，这样取出来的数据，不一定每次都一样。</p>
<p>所以由于有这段代码的存在，导致业务上的表现就很奇怪，明明是一模一样的请求参数，但是最终返回的结果可能不相同。</p>
<p>好，现在，我问你，你说在前面，我给出的这样的分页查询的 SQL 语句有没有毛病？</p>
<blockquote>
<p>select * from table order by create_time desc limit 0,10;</p>
</blockquote>
<p>没有任何毛病嘛，执行结果也没有任何毛病？</p>
<p>有没有给你按照 create_time 排序？</p>
<p>摸着良心说，是有的。</p>
<p>有没有给你取出排序后的 10 条数据？</p>
<p>也是有的。</p>
<p>所以，针对这种现象，官方的态度是：我没错！在我的概念里面，没有“分页”这样的玩意，你通过组合我提供的功能，搞出了“分页”这种业务场景，现在业务场景出问题了，你反过来说我底层有问题？</p>
<p>这不是欺负老实人吗？我没错！</p>
<p><img src="https://s2.loli.net/2024/09/07/8eLazSxNowjrk7s.png" alt="d0b04ec8a2c260f9c220dee3a8cdcd6e.png"></p>
<p>所以，官方把这两种案例都拿出来，并且强调：</p>
<blockquote>
<p>在每种情况下，查询结果都是按 ORDER BY 的列进行排序的，这样的结果是符合 SQL 标准的。</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/07/KqxCb7wR8mBHjiV.png" alt="8d179bc87580a706a7122820193e9148.png"></p>
<p>虽然我没错，但是我还是可以给你指个路。</p>
<p>如果你非常在意执行结果的顺序，那么在 ORDER BY 子句中包含一个额外的列，以确保顺序具有确定性。</p>
<p>例如，如果 id 值是唯一的，你可以通过这样的排序使给定类别值的行按 id 顺序出现。</p>
<p>你这样去写，排序的时候加个 id 字段，就稳了：</p>
<p><img src="https://s2.loli.net/2024/09/07/zbA9ups1SECxdmJ.png" alt="81071450aea9b1d81a33f509527842ba.png"></p>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring IoC 核心流程介绍</title>
    <url>/2024/09/08/mysql/%E6%88%91%E8%AF%95%E5%9B%BE%E6%89%AF%E6%8E%89%E8%BF%99%E6%9D%A1%20SQL%20%E7%9A%84%E5%BA%95%E8%A3%A4/</url>
    <content><![CDATA[<p><img src="https://s2.loli.net/2024/09/08/Qdfk2t5bcg4Mlse.png" alt="img"></p>
<p>这次带大家盘一个我觉得有点意思的东西，也是之前写《来啊，分页啊》这篇文章时，遇到的一个神奇的现象，但是当时忙着做文章搞定这个主线任务，就没有去深究这个支线任务。</p>
<p>现在我们一起把这个支线任务盘一下。</p>
<h2 id="啥支线任务？"><a href="#啥支线任务？" class="headerlink" title="啥支线任务？"></a><strong>啥支线任务？</strong></h2><p>之前不是写分页嘛，分页肯定就要说到 limit 关键字嘛。</p>
<p>然后我啪的一下扔了一个链接出来：</p>
<blockquote>
<p><a href="https://dev.mysql.com/doc/refman/8.0/en/limit-optimization.html">https://dev.mysql.com/doc/refman/8.0/en/limit-optimization.html</a></p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/08/1MEVRbcC9QpI6zS.png" alt="img"></p>
<p>这个链接就是 MySQL 官方文档，这一章节叫做“对 Limit 查询的优化”，针对 limit 和 order by 组合的场景进行了较为详细的说明。</p>
<p>链接里面有这样的一个示例。</p>
<p>首先，针对一张叫做 ratings 的表给了一个不带 limit 的查询结果：</p>
<p><img src="https://s2.loli.net/2024/09/08/o1hKUHJzMfRQgFA.png" alt="img"></p>
<p>可以看到，一共有 7 条数据，确实按照 category 字段进行了排序。</p>
<p>但是当我们带着 limit 的时候，官方文档上给出的查询结果是这样的：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231014210214.png" alt="img"></p>
<p>为了让你更加直观的看出差异，我把两个结果给你放在一起：</p>
<p><img src="https://s2.loli.net/2024/09/08/rFPswJ9pgyUctXu.png" alt="img"></p>
<p>没排序之前，前五条对应的 ID 是 1,5,3,4,6。</p>
<p>排序之后，前五条对应的 ID 是 1,5,4,3,6。</p>
<p>这就是官方的案例，非常直观的体现了 order by 和 limit 一起使用时带来的 nondeterministic。</p>
<p>这个单词，我们前一篇文章中才学过，现在又可以温习了一下了：</p>
<p><img src="https://s2.loli.net/2024/09/08/bdNGloEf5D8qwJg.png" alt="img"></p>
<p>你知道的，歪师傅一向是比较严谨的，所以我也想着在本地复现一下官网的这个案例。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015222426.png" alt="img"></p>
<p><strong>我本地的 MySQL 版本是 8.0.22，以下 SQL 均是基于这个版本执行的。</strong></p>
<p>首先，按照官网上的字段，先“咔”的一下整出表结构：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `ratings` (</span><br><span class="line">  `id` <span class="type">int</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `category` <span class="type">int</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `rating` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br></pre></td></tr></table></figure>

<p>然后“唰”的一下插入 7 条数据：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">1</span>, <span class="number">1</span>, <span class="string">&#x27;4.5&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">2</span>, <span class="number">3</span>, <span class="string">&#x27;5.0&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">3</span>, <span class="number">2</span>, <span class="string">&#x27;3.7&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">4</span>, <span class="number">2</span>, <span class="string">&#x27;3.5&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">5</span>, <span class="number">1</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">6</span>, <span class="number">2</span>, <span class="string">&#x27;3.5&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">7</span>, <span class="number">3</span>, <span class="string">&#x27;2.7&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>接着“啪”的一声执行一下不带 limit 的 SQL，发现运行结果和官网一致：</p>
<blockquote>
<p>SELECT * FROM ratings ORDER BY category;</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/08/RIkytsadLm3xXJY.png" alt="img"></p>
<p>然后“咻”的声执行一下带 limit 的 SQL：</p>
<blockquote>
<p>SELECT * FROM ratings ORDER BY category LIMIT 5;</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/09/08/Ox7DuUJmEgyPKeQ.png" alt="img"></p>
<p>等等，运行结果不一样了？</p>
<p>你把表结构拿过去，然后分别执行对应的 SQL，大概率你也会发现：怎么和官网上的运行结果不一样呢？</p>
<p><img src="https://s2.loli.net/2024/09/08/sLzTaSU1JwWxgPQ.png" alt="img"></p>
<p>为什么运行结果不一样了呢？</p>
<p>这就是我当时遇到的支线任务。</p>
<h2 id="大力出奇迹"><a href="#大力出奇迹" class="headerlink" title="大力出奇迹"></a><strong>大力出奇迹</strong></h2><p>当我遇到这个问题的时候，其实我非常自信。</p>
<p>我自信的知道，肯定是我错了，官方文档不可能有问题，只是它在展示这个案例的时候，隐去了一些信息而已。</p>
<p>巧了，我也恰好知道怎么去触发 order by 和 limit 组合在一起时的“数据紊乱”的情况：当 order by 的字段重复率特别高的时候，带着 limit 查询，就会出现官网中的现象。</p>
<p>我直接先插入了 20 条这样的数据：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231014221522.png" alt="img"></p>
<p>（实际上我第一次运行的时候，插入了 100 条这样的数据，所以，这一小结的名字叫做：大力出奇迹。）</p>
<p>这样在表中就有大量的 category 为 2 的数据。</p>
<p>同样的 SQL，运行结果就变成了这样：</p>
<p><img src="https://s2.loli.net/2024/09/08/B2KVSXrcRnLGEvA.png" alt="img"></p>
<p>可以看到前五条数据的 ID 还是 1,5,3,4,6。</p>
<p>但是，当我运行这个 SQL 的时候，情况就不一样了：</p>
<p><img src="https://s2.loli.net/2024/09/08/Bjq2OmY6vzJudFC.png" alt="img"></p>
<p>确实出现了官网中类似的情况，ID 为 27 的数据突然冲到了前面。</p>
<p>好，现在算是一定程度上复现了官网上的案例。</p>
<p>你知道当我复现这个案例之后，随之而来的另一个问题是什么吗？</p>
<p>那就是如果我开始的不插入 20 条 category 为 2 的数据，只是插入 10 条呢，或者是 5 条呢？</p>
<p>就是有没有一个临界值的存在，让两个 SQL 运行结果不一样呢？</p>
<p>你猜怎么着？</p>
<p>我以二分查找大法为抓手，为运行结果赋能，沉淀出了一套寻找临界值的打发，最终通过精准下钻，找到了临界值，就是 ID 为 16 的这条数据。</p>
<p><img src="https://s2.loli.net/2024/09/08/Kxig7G6zDI9pLjc.png" alt="img"></p>
<p>你先把这一批数据插入到表中：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">8</span>, <span class="number">2</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">9</span>, <span class="number">2</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">10</span>, <span class="number">2</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">11</span>, <span class="number">2</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">12</span>, <span class="number">2</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">13</span>, <span class="number">2</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">14</span>, <span class="number">2</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">15</span>, <span class="number">2</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>然后分别执行这两个 SQL，运行结果是符合预期的：</p>
<p><img src="https://s2.loli.net/2024/09/08/FGBz5QqhkK4n6Mj.png" alt="img"></p>
<p>但是，一旦再插入这样的一条数据：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">16</span>, <span class="number">2</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>情况就不一样了：</p>
<p><img src="https://s2.loli.net/2024/09/08/RBvuyT3XtL8CzOf.png" alt="img"></p>
<p>limit 语句查询出来的 id 就是 1,5,16,3,4 了。</p>
<p>16 就冒出来了。</p>
<p>很好，越来越有意思了。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015223402.png" alt="img"></p>
<p>为什么当表里面有 15 条数据的运行结果和 16 条数据时不一样呢？</p>
<p>我也不知道，所以我试图从执行计划中寻找答案。</p>
<p>但是，这两种情况对应的执行计划一模一样：</p>
<p><img src="https://s2.loli.net/2024/09/08/Wsd9F2yiU73MCcG.png" alt="img"></p>
<p>为什么会这样呢？</p>
<p>因为官网上还有这样一句话：</p>
<p><img src="https://s2.loli.net/2024/09/08/RIDJth64KdfGSV1.png" alt="img"></p>
<p>使用 EXPLAIN 不会区分优化器是否在内存中执行文件排序。</p>
<p>但是在优化器的 optimizer trace 的输出中的 filesort_priority_queue_optimization 字段，可以看到内存中文件排序的相关情况。</p>
<p>所以，这个时候得掏出另外一个武器了：optimizer_trace。</p>
<p>使用 optimizer_trace 可以跟踪 SQL 语句的解析优化执行的全过程。</p>
<p>这两张情况的执行结果不一样，那么它们的 optimizer_trace 结果也必然是不一样的。</p>
<p>于是我分别在 15 条数据和 16 条数据的情况下执行了这样的语句：</p>
<figure class="highlight vbnet"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> optimizer_trace=<span class="comment">&#x27;enabled=on&#x27;;</span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> ratings <span class="keyword">order</span> <span class="keyword">by</span> category limit <span class="number">5</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> `information_schema`.`OPTIMIZER_TRACE`;</span><br><span class="line"><span class="keyword">SET</span> optimizer_trace=<span class="comment">&#x27;enabled=off&#x27;;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://s2.loli.net/2024/09/08/n3ZHNstBCfSwcK9.png" alt="img"></p>
<p>然后取出 optimizer_trace 结果中的 TRACE 数据，左边是 15 条数据的情况，右边是 16 条数据的情况：</p>
<p><img src="https://s2.loli.net/2024/09/08/azShoWuCXT4l6P7.png" alt="img"></p>
<p>主要关注我框起来的部分，也就是前面提到的 filesort_priority_queue_optimization 字段。</p>
<p>这个字段主要是表明这个 SQL 是否使用优先级队列的方式进行排序。</p>
<p>在只有 15 条数据的情况下，它的 chosen 是 false，即不使用优先级队列。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;filesort_priority_queue_optimization&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;limit&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;chosen&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;cause&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sort_is_cheaper&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>同时它也给了不使用的原因：sort_is_cheaper。</p>
<p>它认为直接进行排序的成本更低。</p>
<p>而我们也知道，大部分正常情况下 MySQL 就两种排序方式。如果 sort_buffer_size 够用，那么就在内存中使用快速排序完成排序。</p>
<p>如果 sort_buffer_size 不够用，那就借助临时文件进行归并排序。</p>
<p>但是你要注意，我前面说的是“大部分正常情况下”。</p>
<p>当我们程序中这种案例，order by + limit 的情况，MySQL 就掏出了优先级队列。</p>
<p>这个逻辑其实很简单嘛，limit 语句，不就是找 TOP N 吗？</p>
<p>那你说说，提到 TOP N 你是不是就能立马联想到优先级队列，想到堆排序？</p>
<p>翻出八股文一看：哦，原来堆排序不是稳定的排序算法。</p>
<p>那么不稳定会带来什么问题呢？</p>
<p>我们先按下不表，插个眼在这里，等会儿回收。</p>
<p><img src="https://s2.loli.net/2024/09/08/VkWuit2g6rLapqO.png" alt="img"></p>
<p>继续回到 15 条数据和 16 条数据的情况，当时我找到这个临界值之后，我就在想：为什么临界值在这个地方呢？</p>
<p>一定是有原因的，我想知道答案。</p>
<p>答案在哪里？</p>
<p>我先在网上搜了一圈，发现可能是我冲浪的姿势不对，一直没找到能说服我的答案。</p>
<p>直到我有一天我干饭的时候，脑海里面突然蹦出了一句话：朋友，源码之下无秘密。</p>
<p>于是我桌子一掀，就起来了。</p>
<p><img src="https://s2.loli.net/2024/09/08/put6zlwGvWJ4TUH.png" alt="img"></p>
<h2 id="找源码"><a href="#找源码" class="headerlink" title="找源码"></a><strong>找源码</strong></h2><p>找源码这步，歪师傅就遭老罪了。</p>
<p>因为 MySQL 这玩意主要是用 C++ 写的：</p>
<p><img src="https://s2.loli.net/2024/09/08/VDl71BROYrvwTsy.png" alt="img"></p>
<p>虽然我经常也在说语言是相通的，但是我也确实很久没写 C++ 了。</p>
<p>一路坎坎坷坷终于找到了这个地方：</p>
<blockquote>
<p><a href="https://github.com/mysql/mysql-server/blob/trunk/sql/filesort.cc">https://github.com/mysql/mysql-server/blob/trunk/sql/filesort.cc</a></p>
</blockquote>
<p>这个里面有前面出现过的 sort_is_cheaper：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015000102.png" alt="img"></p>
<p>找到这里，就算是找到突破口了，就开始无限的接近真相了。</p>
<p>在 filesort.cc 这个文件里面，有一个方法叫做 check_if_pq_applicable：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015133440.png" alt="img"></p>
<p>先关注一下这个方法上的描述：</p>
<blockquote>
<p>Test whether priority queue is worth using to get top elements of an ordered result set.</p>
</blockquote>
<p>翻译过来大概是说，看看是否值得使用优先级队列去获取有序结果级中的 Top 元素。</p>
<p>也就是这个方法主要就是评判“是否值得”这件事的。</p>
<p>如果值得呢？</p>
<blockquote>
<p>If it is, then allocates buffer for required amount of records</p>
</blockquote>
<p>如果值得，就为所需数量的记录分配对应的缓存区。</p>
<p>同时在描述部分还给出了一个对应的 SQL：</p>
<blockquote>
<p>SELECT … FROM t ORDER BY a1,…,an LIMIT max_rows;</p>
</blockquote>
<p>这 SQL 样例不就是对应我们前面研究的 SQL 吗。</p>
<p>所以这里面一定能解决我的问题：</p>
<blockquote>
<p>为什么临界值在 16 条数据这个地方呢？</p>
</blockquote>
<p>瞟一眼源码，可以发现它大概是分为了 6 大坨判断：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015134233.png" alt="img"></p>
<p>首先第一坨：</p>
<p><img src="https://s2.loli.net/2024/09/08/I374hE1zxXZYUqL.png" alt="img"></p>
<p>很明显，判断了 SQL 中是否有 limit 关键词。</p>
<p>如果 limit 都没有，那肯定不能用优先级队列了。</p>
<p>这一点，我们也可以通过 optimizer_trace 中的结果来验证：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015134942.png" alt="img"></p>
<p>这个 SQL 对应的结果是这样的：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015135057.png" alt="img"></p>
<p>这不就和源码中的 “not applicable (no LIMIT)” 呼应上了吗？</p>
<p>然后看第二坨 if 判断：</p>
<p><img src="https://s2.loli.net/2024/09/08/STPnXhq4QgwxvLZ.png" alt="img"></p>
<p>如果 SQL 里面有去重的操作，则不支持。</p>
<p>第三坨和第四坨：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015140640.png" alt="img"></p>
<p>分别是说，limit 的值需要小于 UINT_MAX - 2，以及记录的最大长度需要小于 0xFFFFFFFF，不能太长。</p>
<p>UINT_MAX - 2 指的是 priority queue 的最大容量。</p>
<p>然后我们先看最后一坨 if 判断：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015141146.png" alt="img"></p>
<p>也很好理解，要看看针对 limit 这部分的数据，内存够不够，放不放的下。放得下才能使用优先级队列。</p>
<p>主要看这坨：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015141913.png" alt="img"></p>
<p>看这个判断条件：</p>
<blockquote>
<p>if (param-&gt;max_rows &lt; num_rows / PQ_slowness)</p>
</blockquote>
<p>如果满足，就使用优先级队列。</p>
<p>如果不满足，就 “sort_is_cheaper”。</p>
<p>其中 max_rows 就是 limit 的条数，num_rows 就是数据库里面符合条件的总条数。</p>
<p>PQ_slowness 是什么玩意？</p>
<p><img src="https://s2.loli.net/2024/09/08/oXNlfqxJE5K8T3z.png" alt="img"></p>
<p>PQ_slowness 是一个常量，值为 3。</p>
<p>从这个值的描述上看，MySQL 官方认为快速排序的速度是堆排序的 3 倍，这个值也不是拍脑袋拍出来，是通过测试跑出来。</p>
<p>知道了每个字段的含义，那么这个表达式什么时候为 true 就很清晰了。</p>
<blockquote>
<p>if (param-&gt;max_rows &lt; num_rows / PQ_slowness)</p>
</blockquote>
<p>已知，PQ_slowness=3，max_rows=5。</p>
<p>那么当 num_rows &lt;=15 时，表达式为 false。num_rows&gt;16 时，表达式为 true。</p>
<p>为 true ，则使用优先级队列进行排序。</p>
<p>临界值就是这样来的。</p>
<p>所以，那句话是怎么说的来着？</p>
<p>源码之下，无秘密。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015223745.png" alt="img"></p>
<h2 id="再回首"><a href="#再回首" class="headerlink" title="再回首"></a><strong>再回首</strong></h2><p>前面盘完了 optimizer_trace 中的 filesort_priority_queue_optimization 字段。</p>
<p>接着再回首，看看结果文件中的这个 sort_mode 玩意。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015144927.png" alt="img"></p>
<p>关于 sort_mode 官网上也有专门的介绍：</p>
<blockquote>
<p><a href="https://dev.mysql.com/doc/refman/8.0/en/order-by-optimization.html">https://dev.mysql.com/doc/refman/8.0/en/order-by-optimization.html</a></p>
</blockquote>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015152017.png" alt="img"></p>
<p>sort_mode 一共有三种模式。</p>
<p>第一种，&lt;sort_key, rowid&gt; 模式。</p>
<blockquote>
<p>This indicates that sort buffer tuples are pairs that contain the sort key value and row ID of the original table row. Tuples are sorted by sort key value and the row ID is used to read the row from the table.</p>
</blockquote>
<p>这种模式的工作逻辑就是把需要排序的字段按照 order by 在 sort buff 里面排好序。</p>
<p>sort buff 里面放的是排序字段和这个字段对应的 ID。排序字段和 ID 是以键值对的形式存在的。</p>
<p>如果 sort buff 不够放，那就让临时文件帮帮忙。</p>
<p>反正最后把所有数据都过一遍，完成排序任务。接着再拿着 ID 进行回表操作，取出完整的数据，写进结果文件。</p>
<p>第二种，&lt;sort_key, additional_fields&gt; 模式：</p>
<blockquote>
<p>This indicates that sort buffer tuples contain the sort key value and columns referenced by the query. Tuples are sorted by sort key value and column values are read directly from the tuple.</p>
</blockquote>
<p>这种模式和回表不一样，就是直接一梭子把整个用户需要查询的字段放在存入 sort buffer 中。</p>
<p>当然，还是会先按照排序的字段 order by ，在 sort buff 里面排好序。</p>
<p>这样全部数据读取完毕之后，就不需要回表了，可以直接往结果文件里面写。</p>
<p>其实我理解，第一种和第二种就是是否回表的区别。第二种模式应该是第一种模式的迭代优化。</p>
<p>因为不管怎么样，用第一种模式都能完成排序并获取数据任务。</p>
<p>至于怎么决策使用哪种方案，MySQL 内部肯定也是有一套自己的逻辑。</p>
<p>第三种模式是 &lt;sort_key, packed_additional_fields&gt;:</p>
<blockquote>
<p>Like the previous variant, but the additional columns are packed tightly together instead of using a fixed-length encoding.</p>
</blockquote>
<p>这种模式是第二种模式的优化。描述中说用 packed tightly together 代替了 fixed-length encoding。</p>
<p>啥意思呢？</p>
<p>比如我们的表结构中 rating 字段的类型是 varchar(255):</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015161243.png" alt="img"></p>
<p>如果我只是在里面存储一个 why，那么它的实际长度应该是 “why” 这 3 个字符的内存空间，加 2 个字节的字段长度，而不是真正的 255 这么长。</p>
<p>这就是 “packed tightly together”，字段紧密的排列在一起，不浪费空间。</p>
<p>sort buffer 就这么点大，肯定不能太浪费了。</p>
<p>我之前确实不知道这个东西，所以趁这次查漏补缺了一下，属于又拿捏了一个小细节。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015223916.png" alt="img"></p>
<h2 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a><strong>堆排序</strong></h2><p>既然都提到堆排序了，那我们就按照堆排序的逻辑盘一盘数据库里面的数据。</p>
<p>目前数据库里面全部的数据是这样的：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015211224.png" alt="img"></p>
<p>因为是 limit 5，所以先把前五条拿出来：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015211448.png" alt="img"></p>
<p>我们先按照 category 构建小顶堆，只是用不同的颜色来表示不同的 ID。</p>
<p>那么前五条数据构建出来的小顶堆是这样的：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015211631.png" alt="img"></p>
<p>接着，下一条数据是 id 为 6，category 为 2 的数据：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015211802.png" alt="img"></p>
<p>把这条数据放到小顶堆之后变成了这样：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015212201.png" alt="img"></p>
<p>再下一条数据为 id 为 7，category 为 3 的数据。</p>
<p>由于 3 大于 2，所以不满足放入小顶堆的条件。</p>
<p>再下一条数据为 id 为 8，category 为 2 的数据，所以会把小顶堆变成这样：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015213404.png" alt="img">再来 id 为 9，category 为 2 的数据，小顶堆会变成这样：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015213456.png" alt="img"></p>
<p>以此类推，最后一条处理完成之后，小顶堆里面的数据是这样的：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015213150.png" alt="img"></p>
<p>然后，我们将上述小顶堆，进行出堆操作。</p>
<p>翻开八股文一看，哦，原来出堆无外乎就三个动作：</p>
<ol>
<li>堆顶元素出堆</li>
<li>最后一个元素放入堆顶</li>
<li>调整堆</li>
</ol>
<p>所以第一个出堆的节点是这样：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015215035.png" alt="img"></p>
<p>第二个出堆的节点是这样的：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015215152.png" alt="img"></p>
<p>第三个出堆的节点是这样的：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015215230.png" alt="img"></p>
<p>那么最终的出堆顺序就是这样的：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015215319.png" alt="img"></p>
<p>接下来，别忘了，我们的颜色是有含义的，代表的是 ID，我们在看看最开始的五条数据：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015215406.png" alt="img"></p>
<p>所以，我们按照颜色把出堆顺序补上 ID：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015215544.png" alt="img"></p>
<p>1,5,16,3,4。</p>
<p>朋友们，这串数字是否有点眼熟？</p>
<p>是否在午夜梦回的时候梦到过一段？</p>
<p>再给你看一个神奇的东西：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015215710.png" alt="img"></p>
<p>你看看这个 limit 5 取出来的 id 是什么？</p>
<p>1,5,16,3,4。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015224033.png" alt="img"></p>
<p>这玩意就这样呼应上了，掌声可以响起来了，今晚高低得用这串数字搞个彩票。</p>
<p>然后，再提醒一下，我们都知道堆排序是一个不稳定的排序算法。</p>
<p>它的不稳定体现在哪里？</p>
<p>翻开八股文一看，哦，原来是“位置变了”。</p>
<p>就拿我们的这个例子来说，排序之前，3 和 4 这两条数据在 16 之前：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015221934.png" alt="img"></p>
<p>排完序之后，16 这条数据跑到 3 前面去了。</p>
<p>虽然他们对应的 category 值都是 2，但是相对位置发生了变化，这就是不稳定的表现。</p>
<p>好了，现在我再问你一个问题，当我再插入一条数据</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">INSERT INTO <span class="string">`ratings`</span>(<span class="string">`id`</span>, <span class="string">`category`</span>, <span class="string">`rating`</span>) VALUES (<span class="number">17</span>, <span class="number">2</span>, <span class="string">&#x27;3.2&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>你说取前五条，运行结果是什么？</p>
<p>肯定是 1,5,17,3,4。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015220002.png" alt="img"></p>
<p>哪怕我插入个 10000，运行结果我也猜得出来，肯定是 1,5,10000,3,4。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015220111.png" alt="img"></p>
<p>但是你说，我要是再插入个 10w 条 category=2 的数据呢？</p>
<p>这玩意我就没实验了，但是我猜，可能不会启用优先级队列，也就是不会走这一套逻辑。</p>
<p>为什么，你问为什么？</p>
<p>要不你再想想使用优先级队列的那几坨 if 判断？</p>
<h2 id="最后说一句"><a href="#最后说一句" class="headerlink" title="最后说一句"></a><strong>最后说一句</strong></h2><p>好了，写到这里文章也就进入尾声了，到了我拿手的上价值环节了。</p>
<p>你现在回过头想想，其实这篇文章真的没有教会你什么特别有价值的东西。如果让我来总结这篇文章，我只会取走文章开头的这个链接：</p>
<blockquote>
<p><a href="https://dev.mysql.com/doc/refman/8.0/en/limit-optimization.html">https://dev.mysql.com/doc/refman/8.0/en/limit-optimization.html</a></p>
</blockquote>
<p>这是官方文档，当你打开这个链接之后，我不相信你不会被侧边栏中的 Optimization 这个单词给吸引住，然后仔细一看，这一章节下有这么多的 xxx Optimization，我不信你没有点开看一眼的欲望：</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015220616.png" alt="img"></p>
<p>如果你没有这一眼欲望，你抵抗的一定不是技术，因为如果你抵抗技术，你根本就不会打开这个链接。</p>
<p>如果你没有这一眼欲望，说明你抵抗的是纯英文。但是我的朋友，要克服好吗。一点点啃，这才是一手资料的地方，而我不过是一个拙劣的倒卖一手资料的二手贩子而已。</p>
<p>你在看的过程中，除了英文的问题外，肯定有很多其他的问题。这个时候你带着问题去搜索答案，收获将会是巨大的。</p>
<p>这就是我们常常说的：从官方文档开始学。</p>
<p>我这篇文章的起点，就是官方文档，然后从文档发散，我看了很多其他的文章。</p>
<p>如果有一天你看官方文档的时候，看到 limit ptimization 这一章节的时候，有看不懂的地方，然后带着问题在网上搜到了我这篇文章。</p>
<p>朋友，这就很爽了。</p>
<p>这是你的收获，是我的荣幸。</p>
<p>好了，上完价值，打完收工。</p>
<p><img src="https://why-image-1300252878.cos.ap-chengdu.myqcloud.com/img/20220716/20231015221426.png" alt="img"></p>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
</search>
